{"cells":[{"cell_type":"markdown","metadata":{"id":"dq4czARnSH82"},"source":["# üöÄ Clasificaci√≥n Multivariable con Transformer + Features Num√©ricas/Categ√≥ricas\n","\n","---\n","\n","## üìã Descripci√≥n\n","Script robusto para clasificaci√≥n combinando:\n","- **Texto** procesado con Transformer (BETO o XLM-RoBERTa)\n","- **Features num√©ricas** (edad)\n","- **Features categ√≥ricas** (nivel educativo, desempe√±o)\n","\n","### üéØ Variables de Entrada:\n","1. **texto_final** (texto): Procesado con Transformer\n","2. **p208a** (edad): Variable num√©rica\n","3. **p301a** (nivel_educativo): Variable categ√≥rica (ya num√©rica)\n","4. **p507** (desempe√±o): Variable categ√≥rica (ya num√©rica)\n","\n","### üéØ Variable Objetivo:\n","- **p505r4**: Clasificaci√≥n de ocupaci√≥n\n","\n","### ‚ú® Caracter√≠sticas:\n","- ‚úÖ Arquitectura h√≠brida: Transformer + Dense Layers\n","- ‚úÖ Normalizaci√≥n de features num√©ricas\n","- ‚úÖ Embeddings para features categ√≥ricas\n","- ‚úÖ M√©tricas completas (macro, micro, weighted)\n","- ‚úÖ Compatible con BETO y XLM-RoBERTa\n","\n","---\n"],"id":"dq4czARnSH82"},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nKpLZy4USKMm","executionInfo":{"status":"ok","timestamp":1762759898205,"user_tz":300,"elapsed":2386,"user":{"displayName":"Brayan Poma Huaman","userId":"00419443262019466393"}},"outputId":"323793a5-39b8-43a3-b9d0-8ca37df500bb"},"id":"nKpLZy4USKMm","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aDSSruw0SH86","executionInfo":{"status":"ok","timestamp":1762759898205,"user_tz":300,"elapsed":7,"user":{"displayName":"Brayan Poma Huaman","userId":"00419443262019466393"}},"outputId":"d544cec1-a9c0-4da9-8bb0-925e4abafc94"},"source":["# ============================================================================\n","# INSTALACI√ìN DE DEPENDENCIAS\n","# ============================================================================\n","\n","# Descomenta si necesitas instalar\n","# !pip install transformers==4.36.0 datasets==2.15.0 scikit-learn==1.3.2\n","# !pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n","# !pip install accelerate sentencepiece\n","\n","print(\"‚úÖ Si las librer√≠as ya est√°n instaladas, contin√∫a\")\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["‚úÖ Si las librer√≠as ya est√°n instaladas, contin√∫a\n"]}],"id":"aDSSruw0SH86"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"z314EKIHSH88","executionInfo":{"status":"ok","timestamp":1762759898209,"user_tz":300,"elapsed":6,"user":{"displayName":"Brayan Poma Huaman","userId":"00419443262019466393"}},"outputId":"e85d84b2-d351-4d46-9c99-faa83c656363"},"source":["# ============================================================================\n","# IMPORTACIONES Y VERIFICACI√ìN DEL ENTORNO\n","# ============================================================================\n","\n","import sys\n","import os\n","import warnings\n","import logging\n","from datetime import datetime\n","from pathlib import Path\n","\n","# Data & ML\n","import pandas as pd\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.metrics import (\n","    accuracy_score,\n","    precision_recall_fscore_support,\n","    classification_report,\n","    confusion_matrix\n",")\n","\n","# Transformers\n","from transformers import (\n","    AutoTokenizer,\n","    AutoModel,\n","    AutoConfig,\n","    TrainingArguments,\n","    Trainer,\n","    EarlyStoppingCallback\n",")\n","\n","# Utilities\n","from tqdm.auto import tqdm\n","import pickle\n","import json\n","\n","warnings.filterwarnings('ignore')\n","\n","# ============================================================================\n","# VERIFICACI√ìN DE GPU\n","# ============================================================================\n","\n","print(\"\\n\" + \"=\"*80)\n","print(\"üîç VERIFICACI√ìN DEL ENTORNO\")\n","print(\"=\"*80)\n","\n","print(f\"\\nüì¶ Versiones:\")\n","print(f\"   Python: {sys.version.split()[0]}\")\n","print(f\"   PyTorch: {torch.__version__}\")\n","print(f\"   CUDA disponible: {torch.cuda.is_available()}\")\n","\n","if torch.cuda.is_available():\n","    print(f\"\\nüéÆ GPU Detectada:\")\n","    print(f\"   Dispositivo: {torch.cuda.get_device_name(0)}\")\n","    print(f\"   Memoria total: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n","else:\n","    print(\"\\n‚ö†Ô∏è  GPU no detectada - El entrenamiento ser√° lento\")\n","\n","print(\"\\n\" + \"=\"*80)\n","print(\"‚úÖ Importaciones completadas correctamente\")\n","print(\"=\"*80 + \"\\n\")\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","================================================================================\n","üîç VERIFICACI√ìN DEL ENTORNO\n","================================================================================\n","\n","üì¶ Versiones:\n","   Python: 3.12.12\n","   PyTorch: 2.8.0+cu126\n","   CUDA disponible: True\n","\n","üéÆ GPU Detectada:\n","   Dispositivo: Tesla T4\n","   Memoria total: 15.83 GB\n","\n","================================================================================\n","‚úÖ Importaciones completadas correctamente\n","================================================================================\n","\n"]}],"id":"z314EKIHSH88"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":521},"id":"tzBthC5lSH8-","executionInfo":{"status":"ok","timestamp":1762759898251,"user_tz":300,"elapsed":41,"user":{"displayName":"Brayan Poma Huaman","userId":"00419443262019466393"}},"outputId":"3aabb7b3-d193-496a-e853-78597174d74b"},"source":["# ============================================================================\n","# ‚öôÔ∏è  CONFIGURACI√ìN PRINCIPAL - MODIFICA AQU√ç\n","# ============================================================================\n","\n","class MultimodalConfig:\n","    \"\"\"\n","    Configuraci√≥n para clasificaci√≥n multivariable:\n","    Transformer (texto) + Features num√©ricas + Features categ√≥ricas\n","    \"\"\"\n","\n","    # ========================================================================\n","    # üéØ SELECCI√ìN DEL MODELO - CAMBIA SOLO ESTA L√çNEA\n","    # ========================================================================\n","\n","    MODEL_NAME = \"FacebookAI/xlm-roberta-base\"  # Opci√≥n 1: XLM-RoBERTa\n","    # MODEL_NAME = \"dccuchile/bert-base-spanish-wwm-cased\"  # Opci√≥n 2: BETO\n","\n","    # ========================================================================\n","    # üìÇ RUTAS DE DATOS\n","    # ========================================================================\n","\n","    DATA_PATH = \"/content/drive/MyDrive/classification_coding_open_ended_occupational_responses_ENAHO/CLEAN_DATA/BASE_LIMPIA_VF.parquet\"  # Cambia esta ruta\n","    BASE_OUTPUT_DIR = \"/content/drive/MyDrive/classification_coding_open_ended_occupational_responses_ENAHO/05_XLM_ROBERTA/res_modelo_2\"\n","\n","    # ========================================================================\n","    # üìä COLUMNAS DEL DATASET\n","    # ========================================================================\n","\n","    # Variable objetivo\n","    TARGET_COLUMN = \"p505r4\"\n","\n","    # Variable de texto\n","    TEXT_COLUMN = \"texto_final\"\n","\n","    # Variables num√©ricas\n","    NUMERIC_FEATURES = [\"p208a\"]  # edad\n","\n","    # Variables categ√≥ricas (ya en formato num√©rico)\n","    CATEGORICAL_FEATURES = [\n","        \"p301a\",  # nivel_educativo\n","        \"p507\"    # desempe√±o\n","    ]\n","\n","    # N√∫mero de categor√≠as √∫nicas\n","    # Se calcular√° autom√°ticamente si se deja en None\n","    CATEGORICAL_CARDINALITIES = {\n","        \"p301a\": None,  # Se calcular√° autom√°ticamente\n","        \"p507\": None    # Se calcular√° autom√°ticamente\n","    }\n","\n","    # ========================================================================\n","    # üéõÔ∏è  HIPERPAR√ÅMETROS DEL MODELO\n","    # ========================================================================\n","\n","    # Tokenizaci√≥n\n","    MAX_LENGTH = 128\n","\n","    # Dimensiones de embeddings para categ√≥ricas\n","    CATEGORICAL_EMBEDDING_DIM = 16  # Dimensi√≥n de los embeddings categ√≥ricos\n","\n","    # Arquitectura de la capa de fusi√≥n\n","    FUSION_HIDDEN_DIM = 256  # Dimensi√≥n oculta para fusionar features\n","    DROPOUT_RATE = 0.3       # Dropout para regularizaci√≥n\n","\n","    # Entrenamiento\n","    BATCH_SIZE = 16\n","    LEARNING_RATE = 2e-5\n","    NUM_EPOCHS = 3\n","    WARMUP_STEPS = 500\n","    WEIGHT_DECAY = 0.01\n","\n","    # Divisi√≥n de datos\n","    TEST_SIZE = 0.15\n","    VAL_SIZE = 0.15\n","    RANDOM_STATE = 2025\n","\n","    # Filtrado\n","    MIN_SAMPLES_PER_CLASS = 10\n","\n","    # Early stopping\n","    EARLY_STOPPING_PATIENCE = 3\n","\n","    # ========================================================================\n","    # üîß CONFIGURACI√ìN AUTOM√ÅTICA\n","    # ========================================================================\n","\n","    def __init__(self):\n","        \"\"\"Inicializa configuraci√≥n\"\"\"\n","        # Detectar tipo de modelo\n","        if \"roberta\" in self.MODEL_NAME.lower():\n","            self.model_type = \"xlm-roberta\"\n","        elif \"bert\" in self.MODEL_NAME.lower():\n","            self.model_type = \"bert\"\n","        else:\n","            self.model_type = \"transformer\"\n","\n","        # Crear nombre del experimento\n","        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n","        model_short_name = self.MODEL_NAME.split('/')[-1]\n","        self.experiment_name = f\"{model_short_name}_multimodal_{timestamp}\"\n","\n","        # Configurar directorios\n","        self.OUTPUT_DIR = os.path.join(self.BASE_OUTPUT_DIR, self.experiment_name)\n","        self.MODEL_SAVE_DIR = os.path.join(self.OUTPUT_DIR, \"final_model\")\n","        self.CHECKPOINT_DIR = os.path.join(self.OUTPUT_DIR, \"checkpoints\")\n","\n","        # Crear directorios\n","        for dir_path in [self.OUTPUT_DIR, self.MODEL_SAVE_DIR, self.CHECKPOINT_DIR]:\n","            os.makedirs(dir_path, exist_ok=True)\n","\n","        # Device\n","        self.DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","\n","        # Configurar logging\n","        self.logger = self._setup_logging()\n","        self.logger.info(f\"Experimento iniciado: {self.experiment_name}\")\n","        self.logger.info(f\"Modelo seleccionado: {self.MODEL_NAME}\")\n","        self.logger.info(f\"Dispositivo: {self.DEVICE}\")\n","\n","    def _setup_logging(self):\n","        \"\"\"Configura logging\"\"\"\n","        log_file = os.path.join(\n","            self.OUTPUT_DIR,\n","            f'training_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.log'\n","        )\n","\n","        logging.basicConfig(\n","            level=logging.INFO,\n","            format='%(asctime)s - %(levelname)s - %(message)s',\n","            handlers=[\n","                logging.FileHandler(log_file, encoding='utf-8'),\n","                logging.StreamHandler(sys.stdout)\n","            ]\n","        )\n","        return logging.getLogger(__name__)\n","\n","    def display_config(self):\n","        \"\"\"Muestra la configuraci√≥n\"\"\"\n","        print(\"\\n\" + \"=\"*80)\n","        print(\"‚öôÔ∏è  CONFIGURACI√ìN DEL MODELO MULTIMODAL\")\n","        print(\"=\"*80)\n","        print(f\"\\nü§ñ Modelo base: {self.MODEL_NAME}\")\n","        print(f\"   Experimento: {self.experiment_name}\")\n","        print(f\"\\nüìä Variables de entrada:\")\n","        print(f\"   Texto: {self.TEXT_COLUMN}\")\n","        print(f\"   Num√©ricas: {', '.join(self.NUMERIC_FEATURES)}\")\n","        print(f\"   Categ√≥ricas: {', '.join(self.CATEGORICAL_FEATURES)}\")\n","        print(f\"\\nüéØ Variable objetivo: {self.TARGET_COLUMN}\")\n","        print(f\"\\nüèóÔ∏è  Arquitectura:\")\n","        print(f\"   Embedding categ√≥rico: {self.CATEGORICAL_EMBEDDING_DIM}D\")\n","        print(f\"   Capa de fusi√≥n: {self.FUSION_HIDDEN_DIM}D\")\n","        print(f\"   Dropout: {self.DROPOUT_RATE}\")\n","        print(f\"\\nüéõÔ∏è  Entrenamiento:\")\n","        print(f\"   Batch size: {self.BATCH_SIZE}\")\n","        print(f\"   Learning rate: {self.LEARNING_RATE}\")\n","        print(f\"   Epochs: {self.NUM_EPOCHS}\")\n","        print(\"\\n\" + \"=\"*80 + \"\\n\")\n","\n","    def save_config(self):\n","        \"\"\"Guarda la configuraci√≥n\"\"\"\n","        config_dict = {\n","            'model_name': self.MODEL_NAME,\n","            'model_type': self.model_type,\n","            'experiment_name': self.experiment_name,\n","            'text_column': self.TEXT_COLUMN,\n","            'numeric_features': self.NUMERIC_FEATURES,\n","            'categorical_features': self.CATEGORICAL_FEATURES,\n","            'target_column': self.TARGET_COLUMN,\n","            'max_length': self.MAX_LENGTH,\n","            'categorical_embedding_dim': self.CATEGORICAL_EMBEDDING_DIM,\n","            'fusion_hidden_dim': self.FUSION_HIDDEN_DIM,\n","            'dropout_rate': self.DROPOUT_RATE,\n","            'batch_size': self.BATCH_SIZE,\n","            'learning_rate': self.LEARNING_RATE,\n","            'num_epochs': self.NUM_EPOCHS,\n","            'device': self.DEVICE,\n","            'timestamp': datetime.now().isoformat()\n","        }\n","\n","        config_path = os.path.join(self.OUTPUT_DIR, 'config.json')\n","        with open(config_path, 'w', encoding='utf-8') as f:\n","            json.dump(config_dict, f, indent=2, ensure_ascii=False)\n","\n","        self.logger.info(f\"Configuraci√≥n guardada en: {config_path}\")\n","        return config_path\n","\n","\n","# Inicializar configuraci√≥n\n","config = MultimodalConfig()\n","config.display_config()\n","config.save_config()\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","================================================================================\n","‚öôÔ∏è  CONFIGURACI√ìN DEL MODELO MULTIMODAL\n","================================================================================\n","\n","ü§ñ Modelo base: FacebookAI/xlm-roberta-base\n","   Experimento: xlm-roberta-base_multimodal_20251110_073138\n","\n","üìä Variables de entrada:\n","   Texto: texto_final\n","   Num√©ricas: p208a\n","   Categ√≥ricas: p301a, p507\n","\n","üéØ Variable objetivo: p505r4\n","\n","üèóÔ∏è  Arquitectura:\n","   Embedding categ√≥rico: 16D\n","   Capa de fusi√≥n: 256D\n","   Dropout: 0.3\n","\n","üéõÔ∏è  Entrenamiento:\n","   Batch size: 16\n","   Learning rate: 2e-05\n","   Epochs: 3\n","\n","================================================================================\n","\n"]},{"output_type":"execute_result","data":{"text/plain":["'/content/drive/MyDrive/classification_coding_open_ended_occupational_responses_ENAHO/05_XLM_ROBERTA/res_modelo_2/xlm-roberta-base_multimodal_20251110_073138/config.json'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":30}],"id":"tzBthC5lSH8-"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b_Bi8gwGSH9A","executionInfo":{"status":"ok","timestamp":1762759901143,"user_tz":300,"elapsed":2890,"user":{"displayName":"Brayan Poma Huaman","userId":"00419443262019466393"}},"outputId":"9c77b8d5-5665-431e-d5c3-a3ab77c7f8e3"},"source":["# ============================================================================\n","# üìÇ CARGA Y PREPARACI√ìN DE DATOS MULTIVARIABLES\n","# ============================================================================\n","\n","class MultimodalDataLoader:\n","    \"\"\"Cargador de datos para entrada multivariable\"\"\"\n","\n","    def __init__(self, config):\n","        self.config = config\n","        self.logger = config.logger\n","        self.scaler = StandardScaler()\n","\n","    def load_data(self):\n","        \"\"\"Carga datos desde archivo\"\"\"\n","        try:\n","            self.logger.info(f\"Cargando datos desde: {self.config.DATA_PATH}\")\n","\n","            if not os.path.exists(self.config.DATA_PATH):\n","                raise FileNotFoundError(\n","                    f\"‚ùå El archivo no existe: {self.config.DATA_PATH}\"\n","                )\n","\n","            # Cargar seg√∫n extensi√≥n\n","            file_ext = os.path.splitext(self.config.DATA_PATH)[1].lower()\n","\n","            if file_ext == '.parquet':\n","                df = pd.read_parquet(self.config.DATA_PATH)\n","            elif file_ext == '.csv':\n","                df = pd.read_csv(self.config.DATA_PATH)\n","            elif file_ext in ['.xlsx', '.xls']:\n","                df = pd.read_excel(self.config.DATA_PATH)\n","            else:\n","                raise ValueError(f\"‚ùå Formato no soportado: {file_ext}\")\n","\n","            self.logger.info(f\"‚úÖ Datos cargados: {df.shape[0]:,} filas x {df.shape[1]} columnas\")\n","            return df\n","\n","        except Exception as e:\n","            self.logger.error(f\"‚ùå Error al cargar datos: {str(e)}\")\n","            raise\n","\n","    def validate_data(self, df):\n","        \"\"\"Valida que los datos tengan todas las columnas necesarias\"\"\"\n","        self.logger.info(\"Validando estructura de datos...\")\n","\n","        # Verificar columnas requeridas\n","        required_cols = (\n","            [self.config.TEXT_COLUMN, self.config.TARGET_COLUMN] +\n","            self.config.NUMERIC_FEATURES +\n","            self.config.CATEGORICAL_FEATURES\n","        )\n","\n","        missing_cols = [col for col in required_cols if col not in df.columns]\n","\n","        if missing_cols:\n","            available_cols = list(df.columns)\n","            raise ValueError(\n","                f\"‚ùå Columnas faltantes: {missing_cols}\\n\"\n","                f\"   Columnas disponibles: {available_cols}\\n\"\n","                f\"   Verifica la configuraci√≥n en MultimodalConfig\"\n","            )\n","\n","        # Validar datos nulos\n","        for col in required_cols:\n","            null_count = df[col].isna().sum()\n","            if null_count > 0:\n","                self.logger.warning(f\"   ‚ö†Ô∏è  {col}: {null_count:,} valores nulos\")\n","\n","        self.logger.info(\"‚úÖ Validaci√≥n completada\")\n","\n","    def filter_valid_records(self, df):\n","        \"\"\"Filtra registros v√°lidos\"\"\"\n","        self.logger.info(\"Filtrando registros v√°lidos...\")\n","\n","        initial_count = len(df)\n","\n","        # Crear m√°scara de validez\n","        valid_mask = (\n","            df[self.config.TEXT_COLUMN].notna() &\n","            df[self.config.TARGET_COLUMN].notna() &\n","            (df[self.config.TEXT_COLUMN].str.strip() != '')\n","        )\n","\n","        # Validar num√©ricas\n","        for col in self.config.NUMERIC_FEATURES:\n","            valid_mask &= df[col].notna()\n","\n","        # Validar categ√≥ricas\n","        for col in self.config.CATEGORICAL_FEATURES:\n","            valid_mask &= df[col].notna()\n","\n","        df_clean = df[valid_mask].copy()\n","\n","        final_count = len(df_clean)\n","        removed = initial_count - final_count\n","\n","        self.logger.info(\n","            f\"   Registros iniciales: {initial_count:,}\\n\"\n","            f\"   Registros v√°lidos: {final_count:,}\\n\"\n","            f\"   Removidos: {removed:,} ({removed/initial_count*100:.2f}%)\"\n","        )\n","\n","        if final_count == 0:\n","            raise ValueError(\"‚ùå No quedan registros v√°lidos\")\n","\n","        return df_clean\n","\n","    def calculate_categorical_cardinalities(self, df):\n","        \"\"\"Calcula la cardinalidad de variables categ√≥ricas\"\"\"\n","        self.logger.info(\"Calculando cardinalidad de variables categ√≥ricas...\")\n","\n","        for col in self.config.CATEGORICAL_FEATURES:\n","            unique_values = df[col].nunique()\n","            self.config.CATEGORICAL_CARDINALITIES[col] = unique_values\n","            self.logger.info(f\"   {col}: {unique_values} categor√≠as √∫nicas\")\n","\n","    def filter_rare_classes(self, df):\n","        \"\"\"Filtra clases con pocas muestras\"\"\"\n","        self.logger.info(\n","            f\"Filtrando clases con < {self.config.MIN_SAMPLES_PER_CLASS} muestras...\"\n","        )\n","\n","        class_counts = df[self.config.TARGET_COLUMN].value_counts()\n","        valid_classes = class_counts[class_counts >= self.config.MIN_SAMPLES_PER_CLASS].index\n","        df_filtered = df[df[self.config.TARGET_COLUMN].isin(valid_classes)].copy()\n","\n","        self.logger.info(\n","            f\"   Clases originales: {len(class_counts):,}\\n\"\n","            f\"   Clases mantenidas: {len(valid_classes):,}\\n\"\n","            f\"   Registros despu√©s: {len(df_filtered):,}\"\n","        )\n","\n","        return df_filtered\n","\n","    def create_label_mapping(self, df):\n","        \"\"\"Crea mapeo de etiquetas\"\"\"\n","        self.logger.info(\"Creando mapeo de etiquetas...\")\n","\n","        unique_labels = sorted(df[self.config.TARGET_COLUMN].unique())\n","        label2id = {label: idx for idx, label in enumerate(unique_labels)}\n","        id2label = {idx: label for label, idx in label2id.items()}\n","\n","        df['label_id'] = df[self.config.TARGET_COLUMN].map(label2id)\n","\n","        self.logger.info(\n","            f\"‚úÖ Mapeo creado: {len(label2id)} clases (√≠ndices 0-{len(label2id)-1})\"\n","        )\n","\n","        return df, label2id, id2label\n","\n","    def normalize_numeric_features(self, train_df, val_df, test_df):\n","        \"\"\"\n","        Normaliza features num√©ricas usando StandardScaler\n","        Fit en train, transform en val y test\n","        \"\"\"\n","        self.logger.info(\"Normalizando features num√©ricas...\")\n","\n","        if not self.config.NUMERIC_FEATURES:\n","            return train_df, val_df, test_df\n","\n","        # Fit en train\n","        self.scaler.fit(train_df[self.config.NUMERIC_FEATURES])\n","\n","        # Transform en todos\n","        for df_split, name in [(train_df, 'train'), (val_df, 'val'), (test_df, 'test')]:\n","            normalized = self.scaler.transform(df_split[self.config.NUMERIC_FEATURES])\n","\n","            for i, col in enumerate(self.config.NUMERIC_FEATURES):\n","                df_split[f\"{col}_normalized\"] = normalized[:, i]\n","\n","        self.logger.info(\"‚úÖ Features num√©ricas normalizadas\")\n","\n","        return train_df, val_df, test_df\n","\n","    def split_data(self, df):\n","        \"\"\"Divide datos en train, val, test\"\"\"\n","        self.logger.info(\"Dividiendo datos...\")\n","\n","        try:\n","            # Primero separar test\n","            train_val, test = train_test_split(\n","                df,\n","                test_size=self.config.TEST_SIZE,\n","                random_state=self.config.RANDOM_STATE,\n","                stratify=df['label_id']\n","            )\n","\n","            # Luego separar train y val\n","            val_size_adjusted = self.config.VAL_SIZE / (1 - self.config.TEST_SIZE)\n","            train, val = train_test_split(\n","                train_val,\n","                test_size=val_size_adjusted,\n","                random_state=self.config.RANDOM_STATE,\n","                stratify=train_val['label_id']\n","            )\n","\n","            self.logger.info(\n","                f\"‚úÖ Divisi√≥n completada:\\n\"\n","                f\"   Train: {len(train):,}\\n\"\n","                f\"   Validation: {len(val):,}\\n\"\n","                f\"   Test: {len(test):,}\"\n","            )\n","\n","            return train, val, test\n","\n","        except ValueError as e:\n","            self.logger.error(f\"‚ùå Error al dividir datos: {str(e)}\")\n","            raise\n","\n","\n","# ============================================================================\n","# EJECUTAR CARGA DE DATOS\n","# ============================================================================\n","\n","print(\"\\n\" + \"=\"*80)\n","print(\"üìÇ CARGANDO Y PREPARANDO DATOS\")\n","print(\"=\"*80 + \"\\n\")\n","\n","try:\n","    data_loader = MultimodalDataLoader(config)\n","\n","    # Cargar\n","    df_raw = data_loader.load_data()\n","\n","    # Validar\n","    data_loader.validate_data(df_raw)\n","\n","    # Filtrar v√°lidos\n","    df_valid = data_loader.filter_valid_records(df_raw)\n","\n","    # Calcular cardinalidades\n","    data_loader.calculate_categorical_cardinalities(df_valid)\n","\n","    # Filtrar clases raras\n","    df_filtered = data_loader.filter_rare_classes(df_valid)\n","\n","    # Crear mapeo\n","    df_final, label2id, id2label = data_loader.create_label_mapping(df_filtered)\n","\n","    # Dividir\n","    train_df, val_df, test_df = data_loader.split_data(df_final)\n","\n","    # Normalizar features num√©ricas\n","    train_df, val_df, test_df = data_loader.normalize_numeric_features(\n","        train_df, val_df, test_df\n","    )\n","\n","    print(\"\\n\" + \"=\"*80)\n","    print(\"‚úÖ DATOS PREPARADOS EXITOSAMENTE\")\n","    print(\"=\"*80 + \"\\n\")\n","\n","except Exception as e:\n","    print(\"\\n\" + \"=\"*80)\n","    print(\"‚ùå ERROR EN LA CARGA DE DATOS\")\n","    print(\"=\"*80)\n","    print(f\"\\n{str(e)}\\n\")\n","    raise\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","================================================================================\n","üìÇ CARGANDO Y PREPARANDO DATOS\n","================================================================================\n","\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:__main__:   ‚ö†Ô∏è  p301a: 79 valores nulos\n"]},{"output_type":"stream","name":"stdout","text":["\n","================================================================================\n","‚úÖ DATOS PREPARADOS EXITOSAMENTE\n","================================================================================\n","\n"]}],"id":"b_Bi8gwGSH9A"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_nFtne7jSH9C","executionInfo":{"status":"ok","timestamp":1762759901155,"user_tz":300,"elapsed":9,"user":{"displayName":"Brayan Poma Huaman","userId":"00419443262019466393"}},"outputId":"17cada13-d3ea-48ad-f6df-120e04ce5c86"},"source":["# ============================================================================\n","# üî§ DATASET MULTIMODAL\n","# ============================================================================\n","\n","class MultimodalDataset(Dataset):\n","    \"\"\"\n","    Dataset que combina:\n","    - Texto tokenizado\n","    - Features num√©ricas normalizadas\n","    - Features categ√≥ricas\n","    \"\"\"\n","\n","    def __init__(self, dataframe, tokenizer, config, is_train=False):\n","        \"\"\"\n","        Args:\n","            dataframe: DataFrame con todos los datos\n","            tokenizer: Tokenizer de HuggingFace\n","            config: Configuraci√≥n del modelo\n","            is_train: Si es True, puede aplicar augmentation\n","        \"\"\"\n","        self.df = dataframe.reset_index(drop=True)\n","        self.tokenizer = tokenizer\n","        self.config = config\n","        self.is_train = is_train\n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    def __getitem__(self, idx):\n","        row = self.df.iloc[idx]\n","\n","        # 1. TEXTO - Tokenizar\n","        text = str(row[self.config.TEXT_COLUMN])\n","        encoding = self.tokenizer(\n","            text,\n","            max_length=self.config.MAX_LENGTH,\n","            padding='max_length',\n","            truncation=True,\n","            return_tensors='pt'\n","        )\n","\n","        # 2. FEATURES NUM√âRICAS - Normalizadas\n","        numeric_features = []\n","        for col in self.config.NUMERIC_FEATURES:\n","            normalized_col = f\"{col}_normalized\"\n","            value = row[normalized_col] if normalized_col in row else row[col]\n","            numeric_features.append(float(value))\n","\n","        # 3. FEATURES CATEG√ìRICAS - Como √≠ndices\n","        categorical_features = []\n","        for col in self.config.CATEGORICAL_FEATURES:\n","            value = int(row[col])\n","            categorical_features.append(value)\n","\n","        # 4. LABEL\n","        label = int(row['label_id'])\n","\n","        return {\n","            # Texto\n","            'input_ids': encoding['input_ids'].flatten(),\n","            'attention_mask': encoding['attention_mask'].flatten(),\n","\n","            # Features num√©ricas\n","            'numeric_features': torch.tensor(numeric_features, dtype=torch.float),\n","\n","            # Features categ√≥ricas\n","            'categorical_features': torch.tensor(categorical_features, dtype=torch.long),\n","\n","            # Label\n","            'labels': torch.tensor(label, dtype=torch.long)\n","        }\n","\n","\n","print(\"‚úÖ Clase MultimodalDataset definida\")\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["‚úÖ Clase MultimodalDataset definida\n"]}],"id":"_nFtne7jSH9C"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ko1ndUfoSH9D","executionInfo":{"status":"ok","timestamp":1762759901169,"user_tz":300,"elapsed":13,"user":{"displayName":"Brayan Poma Huaman","userId":"00419443262019466393"}},"outputId":"3aba95bd-22b3-4981-a125-f68ab17ae272"},"source":["# ============================================================================\n","# üèóÔ∏è  MODELO MULTIMODAL: TRANSFORMER + NUMERIC + CATEGORICAL\n","# ============================================================================\n","\n","class MultimodalTransformerClassifier(nn.Module):\n","    \"\"\"\n","    Arquitectura h√≠brida que combina:\n","    1. Transformer pre-entrenado para texto\n","    2. Embeddings para features categ√≥ricas\n","    3. Features num√©ricas directas\n","    4. Capa de fusi√≥n para combinar todo\n","    \"\"\"\n","\n","    def __init__(self, config, model_name, num_labels, categorical_cardinalities):\n","        super().__init__()\n","\n","        self.config = config\n","        self.num_labels = num_labels\n","\n","        # 1. TRANSFORMER BASE (solo encoder)\n","        self.transformer = AutoModel.from_pretrained(model_name)\n","        self.transformer_dim = self.transformer.config.hidden_size\n","\n","        # 2. EMBEDDINGS PARA CATEG√ìRICAS\n","        self.categorical_embeddings = nn.ModuleList([\n","            nn.Embedding(\n","                num_embeddings=categorical_cardinalities[cat_name] + 1,  # +1 por seguridad\n","                embedding_dim=config.CATEGORICAL_EMBEDDING_DIM\n","            )\n","            for cat_name in config.CATEGORICAL_FEATURES\n","        ])\n","\n","        # 3. DIMENSIONES\n","        self.num_numeric = len(config.NUMERIC_FEATURES)\n","        self.num_categorical = len(config.CATEGORICAL_FEATURES)\n","        self.total_categorical_dim = self.num_categorical * config.CATEGORICAL_EMBEDDING_DIM\n","\n","        # Dimensi√≥n total de entrada a la capa de fusi√≥n\n","        self.fusion_input_dim = (\n","            self.transformer_dim +      # Del transformer\n","            self.num_numeric +          # Features num√©ricas\n","            self.total_categorical_dim  # Embeddings categ√≥ricos\n","        )\n","\n","        # 4. CAPAS DE FUSI√ìN\n","        self.fusion_layers = nn.Sequential(\n","            nn.Linear(self.fusion_input_dim, config.FUSION_HIDDEN_DIM),\n","            nn.LayerNorm(config.FUSION_HIDDEN_DIM),\n","            nn.ReLU(),\n","            nn.Dropout(config.DROPOUT_RATE),\n","\n","            nn.Linear(config.FUSION_HIDDEN_DIM, config.FUSION_HIDDEN_DIM // 2),\n","            nn.LayerNorm(config.FUSION_HIDDEN_DIM // 2),\n","            nn.ReLU(),\n","            nn.Dropout(config.DROPOUT_RATE),\n","        )\n","\n","        # 5. CLASIFICADOR\n","        self.classifier = nn.Linear(config.FUSION_HIDDEN_DIM // 2, num_labels)\n","\n","        # 6. DROPOUT\n","        self.dropout = nn.Dropout(config.DROPOUT_RATE)\n","\n","    def forward(self, input_ids, attention_mask, numeric_features,\n","                categorical_features, labels=None):\n","        \"\"\"\n","        Forward pass\n","\n","        Args:\n","            input_ids: [batch_size, seq_len]\n","            attention_mask: [batch_size, seq_len]\n","            numeric_features: [batch_size, num_numeric]\n","            categorical_features: [batch_size, num_categorical]\n","            labels: [batch_size] (opcional)\n","        \"\"\"\n","        # 1. PROCESAR TEXTO CON TRANSFORMER\n","        transformer_outputs = self.transformer(\n","            input_ids=input_ids,\n","            attention_mask=attention_mask\n","        )\n","\n","        # Usar [CLS] token (primer token) como representaci√≥n del texto\n","        text_representation = transformer_outputs.last_hidden_state[:, 0, :]  # [batch_size, transformer_dim]\n","        text_representation = self.dropout(text_representation)\n","\n","        # 2. PROCESAR FEATURES CATEG√ìRICAS\n","        categorical_embeddings = []\n","        for i, embedding_layer in enumerate(self.categorical_embeddings):\n","            cat_values = categorical_features[:, i]  # [batch_size]\n","            embedded = embedding_layer(cat_values)    # [batch_size, embedding_dim]\n","            categorical_embeddings.append(embedded)\n","\n","        # Concatenar todos los embeddings categ√≥ricos\n","        categorical_representation = torch.cat(categorical_embeddings, dim=1)  # [batch_size, total_cat_dim]\n","\n","        # 3. FUSIONAR TODO\n","        # Concatenar: texto + num√©ricas + categ√≥ricas\n","        fused = torch.cat([\n","            text_representation,\n","            numeric_features,\n","            categorical_representation\n","        ], dim=1)  # [batch_size, fusion_input_dim]\n","\n","        # 4. PASAR POR CAPAS DE FUSI√ìN\n","        fused = self.fusion_layers(fused)  # [batch_size, fusion_hidden_dim // 2]\n","\n","        # 5. CLASIFICAR\n","        logits = self.classifier(fused)  # [batch_size, num_labels]\n","\n","        # 6. CALCULAR LOSS SI HAY LABELS\n","        loss = None\n","        if labels is not None:\n","            loss_fct = nn.CrossEntropyLoss()\n","            loss = loss_fct(logits, labels)\n","\n","        # Retornar en formato compatible con Trainer\n","        return {\n","            'loss': loss,\n","            'logits': logits\n","        }\n","\n","\n","print(\"‚úÖ Clase MultimodalTransformerClassifier definida\")\n","print(\"\\nüìä Arquitectura del modelo:\")\n","print(\"   1. Transformer (texto) ‚Üí Representaci√≥n densa\")\n","print(\"   2. Embeddings (categ√≥ricas) ‚Üí Vectores densos\")\n","print(\"   3. Features num√©ricas ‚Üí Valores normalizados\")\n","print(\"   4. Fusi√≥n ‚Üí Capas densas con dropout\")\n","print(\"   5. Clasificador ‚Üí Predicci√≥n final\")\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["‚úÖ Clase MultimodalTransformerClassifier definida\n","\n","üìä Arquitectura del modelo:\n","   1. Transformer (texto) ‚Üí Representaci√≥n densa\n","   2. Embeddings (categ√≥ricas) ‚Üí Vectores densos\n","   3. Features num√©ricas ‚Üí Valores normalizados\n","   4. Fusi√≥n ‚Üí Capas densas con dropout\n","   5. Clasificador ‚Üí Predicci√≥n final\n"]}],"id":"Ko1ndUfoSH9D"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1jjWXVWHSH9F","executionInfo":{"status":"ok","timestamp":1762759904092,"user_tz":300,"elapsed":2921,"user":{"displayName":"Brayan Poma Huaman","userId":"00419443262019466393"}},"outputId":"63be2e99-b8d5-4f02-8b32-4c93ddd55ea7"},"source":["# ============================================================================\n","# üî§ INICIALIZAR TOKENIZER Y DATASETS\n","# ============================================================================\n","\n","print(\"\\n\" + \"=\"*80)\n","print(\"üî§ INICIALIZANDO TOKENIZER Y DATASETS\")\n","print(\"=\"*80 + \"\\n\")\n","\n","try:\n","    # Cargar tokenizer\n","    config.logger.info(f\"Cargando tokenizer: {config.MODEL_NAME}\")\n","    tokenizer = AutoTokenizer.from_pretrained(config.MODEL_NAME)\n","\n","    print(f\"‚úÖ Tokenizer cargado: {config.MODEL_NAME}\")\n","    print(f\"   Vocabulario: {len(tokenizer):,} tokens\")\n","\n","    # Crear datasets\n","    config.logger.info(\"Creando datasets multimodales...\")\n","\n","    train_dataset = MultimodalDataset(\n","        dataframe=train_df,\n","        tokenizer=tokenizer,\n","        config=config,\n","        is_train=True\n","    )\n","\n","    val_dataset = MultimodalDataset(\n","        dataframe=val_df,\n","        tokenizer=tokenizer,\n","        config=config,\n","        is_train=False\n","    )\n","\n","    test_dataset = MultimodalDataset(\n","        dataframe=test_df,\n","        tokenizer=tokenizer,\n","        config=config,\n","        is_train=False\n","    )\n","\n","    print(f\"\\n‚úÖ Datasets multimodales creados:\")\n","    print(f\"   Train: {len(train_dataset):,} ejemplos\")\n","    print(f\"   Validation: {len(val_dataset):,} ejemplos\")\n","    print(f\"   Test: {len(test_dataset):,} ejemplos\")\n","\n","    # Verificar un ejemplo\n","    sample = train_dataset[0]\n","    print(f\"\\nüìù Ejemplo de muestra:\")\n","    print(f\"   Input IDs shape: {sample['input_ids'].shape}\")\n","    print(f\"   Attention mask shape: {sample['attention_mask'].shape}\")\n","    print(f\"   Numeric features shape: {sample['numeric_features'].shape}\")\n","    print(f\"   Categorical features shape: {sample['categorical_features'].shape}\")\n","    print(f\"   Label: {sample['labels'].item()}\")\n","\n","    print(\"\\n\" + \"=\"*80)\n","    print(\"‚úÖ TOKENIZACI√ìN Y DATASETS COMPLETADOS\")\n","    print(\"=\"*80 + \"\\n\")\n","\n","except Exception as e:\n","    print(\"\\n\" + \"=\"*80)\n","    print(\"‚ùå ERROR EN LA TOKENIZACI√ìN\")\n","    print(\"=\"*80)\n","    print(f\"\\n{str(e)}\\n\")\n","    raise\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","================================================================================\n","üî§ INICIALIZANDO TOKENIZER Y DATASETS\n","================================================================================\n","\n","‚úÖ Tokenizer cargado: FacebookAI/xlm-roberta-base\n","   Vocabulario: 250,002 tokens\n","\n","‚úÖ Datasets multimodales creados:\n","   Train: 220,882 ejemplos\n","   Validation: 47,332 ejemplos\n","   Test: 47,332 ejemplos\n","\n","üìù Ejemplo de muestra:\n","   Input IDs shape: torch.Size([128])\n","   Attention mask shape: torch.Size([128])\n","   Numeric features shape: torch.Size([1])\n","   Categorical features shape: torch.Size([2])\n","   Label: 319\n","\n","================================================================================\n","‚úÖ TOKENIZACI√ìN Y DATASETS COMPLETADOS\n","================================================================================\n","\n"]}],"id":"1jjWXVWHSH9F"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oqgaSOSFSH9G","executionInfo":{"status":"ok","timestamp":1762759904220,"user_tz":300,"elapsed":122,"user":{"displayName":"Brayan Poma Huaman","userId":"00419443262019466393"}},"outputId":"59308503-782c-4073-a738-52be04c5217b"},"source":["# ============================================================================\n","# üìä FUNCIONES DE M√âTRICAS DETALLADAS\n","# ============================================================================\n","\n","def compute_detailed_metrics(eval_pred):\n","    \"\"\"\n","    Calcula m√©tricas completas: Accuracy, Precision, Recall, F1\n","    Con variantes: macro, micro y weighted\n","    \"\"\"\n","    predictions = eval_pred.predictions\n","    labels = eval_pred.label_ids\n","\n","    # Obtener predicciones\n","    if predictions.ndim > 1:\n","        preds = np.argmax(predictions, axis=1)\n","    else:\n","        preds = predictions\n","\n","    # Accuracy\n","    accuracy = accuracy_score(labels, preds)\n","\n","    # Macro\n","    precision_macro, recall_macro, f1_macro, _ = precision_recall_fscore_support(\n","        labels, preds, average='macro', zero_division=0\n","    )\n","\n","    # Micro\n","    precision_micro, recall_micro, f1_micro, _ = precision_recall_fscore_support(\n","        labels, preds, average='micro', zero_division=0\n","    )\n","\n","    # Weighted\n","    precision_weighted, recall_weighted, f1_weighted, _ = precision_recall_fscore_support(\n","        labels, preds, average='weighted', zero_division=0\n","    )\n","\n","    return {\n","        'accuracy': accuracy,\n","        'f1_macro': f1_macro,\n","        'f1_micro': f1_micro,\n","        'f1_weighted': f1_weighted,\n","        'precision_macro': precision_macro,\n","        'precision_micro': precision_micro,\n","        'precision_weighted': precision_weighted,\n","        'recall_macro': recall_macro,\n","        'recall_micro': recall_micro,\n","        'recall_weighted': recall_weighted,\n","    }\n","\n","\n","\n","def display_metrics(metrics, title=\"M√©tricas\"):\n","    \"\"\"Muestra las m√©tricas de forma organizada\"\"\"\n","    print(\"\\n\" + \"=\"*80)\n","    print(f\"üìä {title.upper()}\")\n","    print(\"=\"*80 + \"\\n\")\n","\n","    # Mostrar Loss si existe\n","    loss = (\n","        metrics.get('test_loss') or\n","        metrics.get('eval_loss') or\n","        metrics.get('loss', None)\n","    )\n","    if loss is not None:\n","        print(f\"üí• LOSS: {loss:.4f}\")\n","\n","    # Accuracy\n","    acc = (\n","        metrics.get('test_accuracy') or\n","        metrics.get('eval_accuracy') or\n","        metrics.get('accuracy', 0)\n","    )\n","    print(f\"üéØ ACCURACY: {acc:.4f}\")\n","    print(\"\\n\" + \"-\"*80)\n","\n","    # Tabla\n","    print(f\"\\n{'M√©trica':<20} {'Macro':>12} {'Micro':>12} {'Weighted':>12}\")\n","    print(\"-\"*60)\n","\n","    def get_m(name):\n","        return (\n","            metrics.get(f'test_{name}') or\n","            metrics.get(f'eval_{name}') or\n","            metrics.get(name, 0)\n","        )\n","\n","    print(f\"{'F1 Score':<20} {get_m('f1_macro'):>12.4f} {get_m('f1_micro'):>12.4f} {get_m('f1_weighted'):>12.4f}\")\n","    print(f\"{'Precision':<20} {get_m('precision_macro'):>12.4f} {get_m('precision_micro'):>12.4f} {get_m('precision_weighted'):>12.4f}\")\n","    print(f\"{'Recall':<20} {get_m('recall_macro'):>12.4f} {get_m('recall_micro'):>12.4f} {get_m('recall_weighted'):>12.4f}\")\n","\n","    print(\"\\n\" + \"=\"*80 + \"\\n\")\n","\n","\n","print(\"‚úÖ Funciones de m√©tricas cargadas (con loss incluido)\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["‚úÖ Funciones de m√©tricas cargadas\n"]}],"id":"oqgaSOSFSH9G"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qNAbk1SvSH9H","executionInfo":{"status":"ok","timestamp":1762759905762,"user_tz":300,"elapsed":1540,"user":{"displayName":"Brayan Poma Huaman","userId":"00419443262019466393"}},"outputId":"f80634da-2580-472f-f6d4-ace66a11bfda"},"source":["# ============================================================================\n","# ü§ñ INICIALIZAR MODELO MULTIMODAL\n","# ============================================================================\n","\n","print(\"\\n\" + \"=\"*80)\n","print(\"ü§ñ INICIALIZANDO MODELO MULTIMODAL\")\n","print(\"=\"*80 + \"\\n\")\n","\n","try:\n","    config.logger.info(f\"Cargando modelo: {config.MODEL_NAME}\")\n","\n","    # Crear modelo multimodal\n","    model = MultimodalTransformerClassifier(\n","        config=config,\n","        model_name=config.MODEL_NAME,\n","        num_labels=len(label2id),\n","        categorical_cardinalities=config.CATEGORICAL_CARDINALITIES\n","    )\n","\n","    # Mover a GPU si est√° disponible\n","    model.to(config.DEVICE)\n","\n","    # Informaci√≥n del modelo\n","    num_params = sum(p.numel() for p in model.parameters())\n","    num_trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n","\n","    print(f\"‚úÖ Modelo multimodal cargado\")\n","    print(f\"   Modelo base: {config.MODEL_NAME}\")\n","    print(f\"   N√∫mero de clases: {len(label2id)}\")\n","    print(f\"   Par√°metros totales: {num_params:,}\")\n","    print(f\"   Par√°metros entrenables: {num_trainable:,}\")\n","    print(f\"   Dispositivo: {config.DEVICE}\")\n","\n","    # Informaci√≥n de arquitectura\n","    print(f\"\\nüèóÔ∏è  Arquitectura:\")\n","    print(f\"   Transformer dim: {model.transformer_dim}\")\n","    print(f\"   Num. features num√©ricas: {model.num_numeric}\")\n","    print(f\"   Num. features categ√≥ricas: {model.num_categorical}\")\n","    print(f\"   Dim. embeddings categ√≥ricos: {config.CATEGORICAL_EMBEDDING_DIM}\")\n","    print(f\"   Dim. entrada fusi√≥n: {model.fusion_input_dim}\")\n","    print(f\"   Dim. oculta fusi√≥n: {config.FUSION_HIDDEN_DIM}\")\n","\n","    if torch.cuda.is_available():\n","        print(f\"\\n   Memoria GPU asignada: {torch.cuda.memory_allocated(0) / 1e9:.2f} GB\")\n","\n","    config.logger.info(f\"Modelo inicializado con {num_params:,} par√°metros\")\n","\n","    print(\"\\n\" + \"=\"*80)\n","    print(\"‚úÖ MODELO LISTO PARA ENTRENAMIENTO\")\n","    print(\"=\"*80 + \"\\n\")\n","\n","except Exception as e:\n","    print(\"\\n\" + \"=\"*80)\n","    print(\"‚ùå ERROR AL CARGAR EL MODELO\")\n","    print(\"=\"*80)\n","    print(f\"\\n{str(e)}\\n\")\n","    raise\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","================================================================================\n","ü§ñ INICIALIZANDO MODELO MULTIMODAL\n","================================================================================\n","\n","‚úÖ Modelo multimodal cargado\n","   Modelo base: FacebookAI/xlm-roberta-base\n","   N√∫mero de clases: 357\n","   Par√°metros totales: 278,329,013\n","   Par√°metros entrenables: 278,329,013\n","   Dispositivo: cuda\n","\n","üèóÔ∏è  Arquitectura:\n","   Transformer dim: 768\n","   Num. features num√©ricas: 1\n","   Num. features categ√≥ricas: 2\n","   Dim. embeddings categ√≥ricos: 16\n","   Dim. entrada fusi√≥n: 801\n","   Dim. oculta fusi√≥n: 256\n","\n","   Memoria GPU asignada: 7.85 GB\n","\n","================================================================================\n","‚úÖ MODELO LISTO PARA ENTRENAMIENTO\n","================================================================================\n","\n"]}],"id":"qNAbk1SvSH9H"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5VvroX6dSH9H","executionInfo":{"status":"ok","timestamp":1762759905786,"user_tz":300,"elapsed":20,"user":{"displayName":"Brayan Poma Huaman","userId":"00419443262019466393"}},"outputId":"88fbdf22-e2e1-42da-dc1d-ff6127bc3ac3"},"source":["# ============================================================================\n","# üîß CUSTOM TRAINER PARA MODELO MULTIMODAL\n","# ============================================================================\n","\n","class MultimodalTrainer(Trainer):\n","    \"\"\"\n","    Trainer personalizado que maneja inputs multimodales\n","    (texto + num√©ricas + categ√≥ricas)\n","    \"\"\"\n","\n","    def compute_loss(self, model, inputs, return_outputs=False,**kwargs):\n","        \"\"\"\n","        Calcula la p√©rdida pasando todos los inputs al modelo\n","        \"\"\"\n","        # Extraer inputs\n","        input_ids = inputs.get('input_ids')\n","        attention_mask = inputs.get('attention_mask')\n","        numeric_features = inputs.get('numeric_features')\n","        categorical_features = inputs.get('categorical_features')\n","        labels = inputs.get('labels')\n","\n","        # Forward pass\n","        outputs = model(\n","            input_ids=input_ids,\n","            attention_mask=attention_mask,\n","            numeric_features=numeric_features,\n","            categorical_features=categorical_features,\n","            labels=labels\n","        )\n","\n","        loss = outputs['loss']\n","\n","        return (loss, outputs) if return_outputs else loss\n","\n","    def prediction_step(self, model, inputs, prediction_loss_only, ignore_keys=None):\n","        \"\"\"\n","        Realiza un paso de predicci√≥n\n","        \"\"\"\n","        # Extraer inputs\n","        input_ids = inputs.get('input_ids')\n","        attention_mask = inputs.get('attention_mask')\n","        numeric_features = inputs.get('numeric_features')\n","        categorical_features = inputs.get('categorical_features')\n","        labels = inputs.get('labels')\n","\n","        device = self.args.device\n","\n","        # Mover a device\n","        if input_ids is not None:\n","            input_ids = input_ids.to(device)\n","        if attention_mask is not None:\n","            attention_mask = attention_mask.to(device)\n","        if numeric_features is not None:\n","            numeric_features = numeric_features.to(device)\n","        if categorical_features is not None:\n","            categorical_features = categorical_features.to(device)\n","        if labels is not None:\n","            labels = labels.to(device)\n","\n","        # Forward pass\n","        with torch.no_grad():\n","            outputs = model(\n","                input_ids=input_ids,\n","                attention_mask=attention_mask,\n","                numeric_features=numeric_features,\n","                categorical_features=categorical_features,\n","                labels=labels\n","            )\n","\n","        loss = outputs['loss']\n","        logits = outputs['logits']\n","\n","        if prediction_loss_only:\n","            return (loss, None, None)\n","\n","        return (loss, logits, labels)\n","\n","\n","print(\"‚úÖ Clase MultimodalTrainer definida\")\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["‚úÖ Clase MultimodalTrainer definida\n"]}],"id":"5VvroX6dSH9H"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RyJrKx0bSH9I","executionInfo":{"status":"ok","timestamp":1762759905864,"user_tz":300,"elapsed":67,"user":{"displayName":"Brayan Poma Huaman","userId":"00419443262019466393"}},"outputId":"5db3e80d-6c9d-4be5-86bc-4d3f64be54ed"},"source":["# ============================================================================\n","# ‚öôÔ∏è  CONFIGURACI√ìN DEL ENTRENAMIENTO\n","# ============================================================================\n","\n","print(\"\\n\" + \"=\"*80)\n","print(\"‚öôÔ∏è  CONFIGURANDO ENTRENAMIENTO\")\n","print(\"=\"*80 + \"\\n\")\n","\n","# Configuraci√≥n de argumentos\n","training_args = TrainingArguments(\n","    output_dir=config.CHECKPOINT_DIR,\n","    logging_dir=os.path.join(config.OUTPUT_DIR, 'logs'),\n","\n","    # Hiperpar√°metros\n","    learning_rate=config.LEARNING_RATE,\n","    per_device_train_batch_size=config.BATCH_SIZE,\n","    per_device_eval_batch_size=config.BATCH_SIZE,\n","    num_train_epochs=config.NUM_EPOCHS,\n","    warmup_steps=config.WARMUP_STEPS,\n","    weight_decay=config.WEIGHT_DECAY,\n","\n","    # Evaluaci√≥n\n","    eval_strategy=\"epoch\",\n","    save_strategy=\"epoch\",\n","    load_best_model_at_end=True,\n","    metric_for_best_model=\"f1_weighted\",\n","    greater_is_better=True,\n","\n","    # Logging\n","    logging_steps=100,\n","    logging_strategy=\"steps\",\n","\n","    # Optimizaci√≥n\n","    fp16=torch.cuda.is_available(),\n","    gradient_accumulation_steps=1,\n","\n","    # Otros\n","    seed=config.RANDOM_STATE,\n","    report_to=\"none\",\n","    disable_tqdm=False,\n",")\n","\n","# Inicializar Trainer\n","trainer = MultimodalTrainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=train_dataset,\n","    eval_dataset=val_dataset,\n","    compute_metrics=compute_detailed_metrics,\n","    callbacks=[\n","        EarlyStoppingCallback(\n","            early_stopping_patience=config.EARLY_STOPPING_PATIENCE\n","        )\n","    ]\n",")\n","\n","print(\"‚úÖ Configuraci√≥n:\")\n","print(f\"   Learning rate: {config.LEARNING_RATE}\")\n","print(f\"   Batch size: {config.BATCH_SIZE}\")\n","print(f\"   Epochs: {config.NUM_EPOCHS}\")\n","print(f\"   Early stopping: {config.EARLY_STOPPING_PATIENCE} epochs\")\n","print(f\"   FP16: {training_args.fp16}\")\n","print(f\"   M√©trica principal: f1_weighted\")\n","\n","print(\"\\n\" + \"=\"*80)\n","print(\"‚úÖ TRAINER CONFIGURADO Y LISTO\")\n","print(\"=\"*80 + \"\\n\")\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","================================================================================\n","‚öôÔ∏è  CONFIGURANDO ENTRENAMIENTO\n","================================================================================\n","\n","‚úÖ Configuraci√≥n:\n","   Learning rate: 2e-05\n","   Batch size: 16\n","   Epochs: 3\n","   Early stopping: 3 epochs\n","   FP16: True\n","   M√©trica principal: f1_weighted\n","\n","================================================================================\n","‚úÖ TRAINER CONFIGURADO Y LISTO\n","================================================================================\n","\n"]}],"id":"RyJrKx0bSH9I"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":936},"id":"Lim-RoVZSH9I","executionInfo":{"status":"ok","timestamp":1762767603046,"user_tz":300,"elapsed":7697169,"user":{"displayName":"Brayan Poma Huaman","userId":"00419443262019466393"}},"outputId":"3212b16d-24a4-4388-f7b3-f328c6a05c35"},"source":["# ============================================================================\n","# üöÄ ENTRENAMIENTO DEL MODELO MULTIMODAL\n","# ============================================================================\n","\n","print(\"\\n\" + \"=\"*80)\n","print(\"üöÄ INICIANDO ENTRENAMIENTO\")\n","print(\"=\"*80)\n","print(f\"\\nModelo: {config.MODEL_NAME} (Multimodal)\")\n","print(f\"Entradas: Texto + {len(config.NUMERIC_FEATURES)} num√©ricas + {len(config.CATEGORICAL_FEATURES)} categ√≥ricas\")\n","print(f\"Datos de entrenamiento: {len(train_dataset):,} ejemplos\")\n","print(f\"Datos de validaci√≥n: {len(val_dataset):,} ejemplos\")\n","print(f\"\\n‚è±Ô∏è  Esto puede tomar tiempo...\")\n","print(\"=\"*80 + \"\\n\")\n","\n","try:\n","    start_time = datetime.now()\n","    config.logger.info(\"Iniciando entrenamiento multimodal...\")\n","\n","    # ENTRENAR\n","    train_result = trainer.train()\n","\n","    end_time = datetime.now()\n","    training_time = end_time - start_time\n","\n","    config.logger.info(f\"Entrenamiento completado en {training_time}\")\n","\n","    print(\"\\n\" + \"=\"*80)\n","    print(\"‚úÖ ENTRENAMIENTO COMPLETADO\")\n","    print(\"=\"*80)\n","    print(f\"\\nTiempo total: {training_time}\")\n","    print(f\"Training loss: {train_result.training_loss:.4f}\")\n","\n","    # Evaluar en validation\n","    print(\"\\n\" + \"-\"*80)\n","    print(\"üìä Evaluando en conjunto de validaci√≥n...\")\n","    val_metrics = trainer.evaluate()\n","    display_metrics(val_metrics, \"M√©tricas de Validaci√≥n\")\n","\n","    print(\"=\"*80 + \"\\n\")\n","\n","except KeyboardInterrupt:\n","    print(\"\\n‚ö†Ô∏è  ENTRENAMIENTO INTERRUMPIDO\")\n","    raise\n","\n","except Exception as e:\n","    print(\"\\n‚ùå ERROR DURANTE EL ENTRENAMIENTO\")\n","    print(f\"\\n{str(e)}\\n\")\n","    config.logger.error(f\"Error: {str(e)}\", exc_info=True)\n","    raise\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","================================================================================\n","üöÄ INICIANDO ENTRENAMIENTO\n","================================================================================\n","\n","Modelo: FacebookAI/xlm-roberta-base (Multimodal)\n","Entradas: Texto + 1 num√©ricas + 2 categ√≥ricas\n","Datos de entrenamiento: 220,882 ejemplos\n","Datos de validaci√≥n: 47,332 ejemplos\n","\n","‚è±Ô∏è  Esto puede tomar tiempo...\n","================================================================================\n","\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='41418' max='41418' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [41418/41418 2:06:26, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1 Macro</th>\n","      <th>F1 Micro</th>\n","      <th>F1 Weighted</th>\n","      <th>Precision Macro</th>\n","      <th>Precision Micro</th>\n","      <th>Precision Weighted</th>\n","      <th>Recall Macro</th>\n","      <th>Recall Micro</th>\n","      <th>Recall Weighted</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.816000</td>\n","      <td>0.698539</td>\n","      <td>0.878813</td>\n","      <td>0.235013</td>\n","      <td>0.878813</td>\n","      <td>0.851172</td>\n","      <td>0.234621</td>\n","      <td>0.878813</td>\n","      <td>0.836773</td>\n","      <td>0.253380</td>\n","      <td>0.878813</td>\n","      <td>0.878813</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.571400</td>\n","      <td>0.485601</td>\n","      <td>0.909258</td>\n","      <td>0.323354</td>\n","      <td>0.909258</td>\n","      <td>0.890546</td>\n","      <td>0.342936</td>\n","      <td>0.909258</td>\n","      <td>0.883001</td>\n","      <td>0.336035</td>\n","      <td>0.909258</td>\n","      <td>0.909258</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.503400</td>\n","      <td>0.434664</td>\n","      <td>0.919970</td>\n","      <td>0.363425</td>\n","      <td>0.919970</td>\n","      <td>0.904766</td>\n","      <td>0.372255</td>\n","      <td>0.919970</td>\n","      <td>0.897110</td>\n","      <td>0.374813</td>\n","      <td>0.919970</td>\n","      <td>0.919970</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","================================================================================\n","‚úÖ ENTRENAMIENTO COMPLETADO\n","================================================================================\n","\n","Tiempo total: 2:06:29.159364\n","Training loss: 0.9807\n","\n","--------------------------------------------------------------------------------\n","üìä Evaluando en conjunto de validaci√≥n...\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='2959' max='2959' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2959/2959 01:47]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","================================================================================\n","üìä M√âTRICAS DE VALIDACI√ìN\n","================================================================================\n","\n","üéØ ACCURACY: 0.9200\n","\n","--------------------------------------------------------------------------------\n","\n","M√©trica                     Macro        Micro     Weighted\n","------------------------------------------------------------\n","F1 Score                   0.3634       0.9200       0.9048\n","Precision                  0.3723       0.9200       0.8971\n","Recall                     0.3748       0.9200       0.9200\n","\n","================================================================================\n","\n","================================================================================\n","\n"]}],"id":"Lim-RoVZSH9I"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"fwMph7pASH9I","executionInfo":{"status":"ok","timestamp":1762767719566,"user_tz":300,"elapsed":116515,"user":{"displayName":"Brayan Poma Huaman","userId":"00419443262019466393"}},"outputId":"a68b78dc-cb58-4af8-8452-cf28094b42e5"},"source":["# ============================================================================\n","# üß™ EVALUACI√ìN EN TEST SET\n","# ============================================================================\n","\n","print(\"\\n\" + \"=\"*80)\n","print(\"üß™ EVALUACI√ìN EN TEST SET\")\n","print(\"=\"*80 + \"\\n\")\n","\n","try:\n","    config.logger.info(\"Evaluando en test set...\")\n","\n","    # Obtener predicciones\n","    test_predictions = trainer.predict(test_dataset)\n","    test_metrics = test_predictions.metrics\n","\n","    # Mostrar m√©tricas\n","    display_metrics(test_metrics, \"M√©tricas de Test (Evaluaci√≥n Final)\")\n","\n","    # Guardar m√©tricas\n","    metrics_file = os.path.join(config.OUTPUT_DIR, 'test_metrics.json')\n","    with open(metrics_file, 'w', encoding='utf-8') as f:\n","        json.dump(test_metrics, f, indent=2)\n","\n","    print(f\"‚úÖ M√©tricas guardadas en: {metrics_file}\")\n","\n","    # An√°lisis detallado\n","    print(\"\\n\" + \"=\"*80)\n","    print(\"üìà AN√ÅLISIS DETALLADO\")\n","    print(\"=\"*80 + \"\\n\")\n","\n","    y_pred = np.argmax(test_predictions.predictions, axis=1)\n","    y_true = test_predictions.label_ids\n","\n","    # Reporte de clasificaci√≥n\n","    target_names = [id2label[i] for i in range(len(id2label))]\n","    class_report = classification_report(\n","        y_true,\n","        y_pred,\n","        target_names=target_names,\n","        zero_division=0,\n","        digits=4\n","    )\n","    print(class_report)\n","\n","    # Guardar reporte\n","    report_file = os.path.join(config.OUTPUT_DIR, 'classification_report.txt')\n","    with open(report_file, 'w', encoding='utf-8') as f:\n","        f.write(\"REPORTE DE CLASIFICACI√ìN MULTIMODAL - TEST SET\\n\")\n","        f.write(\"=\"*80 + \"\\n\\n\")\n","        f.write(f\"Modelo: {config.MODEL_NAME} (Multimodal)\\n\")\n","        f.write(f\"Features: Texto + {config.NUMERIC_FEATURES} + {config.CATEGORICAL_FEATURES}\\n\")\n","        f.write(f\"Fecha: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n","        f.write(\"\\n\" + \"=\"*80 + \"\\n\\n\")\n","        f.write(class_report)\n","\n","    print(f\"\\n‚úÖ Reporte guardado en: {report_file}\")\n","\n","    # An√°lisis de errores\n","    incorrect_mask = y_pred != y_true\n","    num_incorrect = incorrect_mask.sum()\n","\n","    print(\"\\n\" + \"=\"*80)\n","    print(\"üîç AN√ÅLISIS DE ERRORES\")\n","    print(\"=\"*80 + \"\\n\")\n","    print(f\"Total: {len(y_true):,}\")\n","    print(f\"Correctas: {(~incorrect_mask).sum():,}\")\n","    print(f\"Incorrectas: {num_incorrect:,} ({num_incorrect/len(y_true)*100:.2f}%)\")\n","\n","    # Guardar errores\n","    if num_incorrect > 0:\n","        errors_df = test_df[incorrect_mask].copy()\n","        errors_df['predicted_label'] = [id2label[pred] for pred in y_pred[incorrect_mask]]\n","        errors_df['true_label'] = [id2label[true] for true in y_true[incorrect_mask]]\n","\n","        probs = torch.nn.functional.softmax(torch.tensor(test_predictions.predictions), dim=-1)\n","        max_probs = probs.max(dim=-1).values.numpy()\n","        errors_df['confidence'] = max_probs[incorrect_mask]\n","\n","        errors_file = os.path.join(config.OUTPUT_DIR, 'error_analysis.csv')\n","        errors_df.to_csv(errors_file, index=False, encoding='utf-8')\n","        print(f\"\\n‚úÖ An√°lisis de errores guardado en: {errors_file}\")\n","\n","    print(\"\\n\" + \"=\"*80 + \"\\n\")\n","\n","except Exception as e:\n","    print(\"\\n‚ùå ERROR EN LA EVALUACI√ìN\")\n","    print(f\"\\n{str(e)}\\n\")\n","    raise\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","================================================================================\n","üß™ EVALUACI√ìN EN TEST SET\n","================================================================================\n","\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","================================================================================\n","üìä M√âTRICAS DE TEST (EVALUACI√ìN FINAL)\n","================================================================================\n","\n","üéØ ACCURACY: 0.0000\n","\n","--------------------------------------------------------------------------------\n","\n","M√©trica                     Macro        Micro     Weighted\n","------------------------------------------------------------\n","F1 Score                   0.0000       0.0000       0.0000\n","Precision                  0.0000       0.0000       0.0000\n","Recall                     0.0000       0.0000       0.0000\n","\n","================================================================================\n","\n","‚úÖ M√©tricas guardadas en: /content/drive/MyDrive/classification_coding_open_ended_occupational_responses_ENAHO/05_XLM_ROBERTA/res_modelo_2/xlm-roberta-base_multimodal_20251110_073138/test_metrics.json\n","\n","================================================================================\n","üìà AN√ÅLISIS DETALLADO\n","================================================================================\n","\n","              precision    recall  f1-score   support\n","\n","        0111     0.0000    0.0000    0.0000         3\n","        0112     0.0000    0.0000    0.0000         2\n","        0120     0.0000    0.0000    0.0000         9\n","        0211     0.0000    0.0000    0.0000         9\n","        0212     0.0000    0.0000    0.0000         5\n","        0213     0.0000    0.0000    0.0000         2\n","        0220     0.8192    1.0000    0.9006       145\n","        0311     0.0000    0.0000    0.0000         6\n","        0312     0.0000    0.0000    0.0000         8\n","        0313     0.0000    0.0000    0.0000         4\n","        1111     0.0000    0.0000    0.0000        11\n","        1113     0.0000    0.0000    0.0000         3\n","        1114     1.0000    0.7241    0.8400        29\n","        1131     0.0000    0.0000    0.0000         2\n","        1133     0.0000    0.0000    0.0000         3\n","        1143     0.0000    0.0000    0.0000         1\n","        1166     0.0000    0.0000    0.0000         3\n","        1167     0.0000    0.0000    0.0000         1\n","        1169     0.0000    0.0000    0.0000         2\n","        1211     0.0000    0.0000    0.0000         2\n","        1221     0.0000    0.0000    0.0000         4\n","        1321     0.0000    0.0000    0.0000         2\n","        1323     0.0000    0.0000    0.0000         2\n","        1341     0.0000    0.0000    0.0000         2\n","        1345     0.8161    1.0000    0.8987        71\n","        1346     0.0000    0.0000    0.0000         3\n","        1422     0.0000    0.0000    0.0000         6\n","        1499     0.0000    0.0000    0.0000         2\n","        2113     0.0000    0.0000    0.0000         3\n","        2114     0.0000    0.0000    0.0000         9\n","        2120     0.0000    0.0000    0.0000         2\n","        2131     0.8824    0.9375    0.9091        16\n","        2132     0.8409    0.8810    0.8605        42\n","        2141     0.6000    0.7826    0.6792        23\n","        2142     0.7109    0.9579    0.8161        95\n","        2143     0.7778    0.3333    0.4667        21\n","        2144     1.0000    0.4667    0.6364        15\n","        2145     0.0000    0.0000    0.0000         8\n","        2146     0.0000    0.0000    0.0000        12\n","        2149     0.0000    0.0000    0.0000        15\n","        2151     0.0000    0.0000    0.0000        10\n","        2152     0.0000    0.0000    0.0000        10\n","        2161     0.6042    0.9355    0.7342        31\n","        2162     0.0000    0.0000    0.0000        15\n","        2163     0.0000    0.0000    0.0000         8\n","        2166     0.6289    0.9683    0.7625        63\n","        2211     0.8621    0.9091    0.8850        55\n","        2212     0.6552    0.8444    0.7379        45\n","        2221     0.8588    1.0000    0.9241       146\n","        2222     0.8889    0.9796    0.9320        49\n","        2240     0.7727    0.9444    0.8500        18\n","        2251     0.7937    0.9259    0.8547        54\n","        2252     0.6667    0.3529    0.4615        17\n","        2254     0.0000    0.0000    0.0000         5\n","        2255     0.0000    0.0000    0.0000         8\n","        2256     0.0000    0.0000    0.0000         1\n","        2257     0.0000    0.0000    0.0000         1\n","        2311     0.8904    0.9630    0.9253       135\n","        2312     0.0000    0.0000    0.0000        11\n","        2320     0.0000    0.0000    0.0000         5\n","        2330     0.9410    0.9897    0.9647       387\n","        2341     0.9586    0.9701    0.9643       501\n","        2342     0.9227    0.9781    0.9496       183\n","        2351     0.0000    0.0000    0.0000         9\n","        2352     0.0000    0.0000    0.0000         5\n","        2353     0.0000    0.0000    0.0000         7\n","        2359     0.7343    0.8015    0.7664       131\n","        2411     0.8245    0.9627    0.8883       161\n","        2412     0.0000    0.0000    0.0000         8\n","        2421     0.0000    0.0000    0.0000        72\n","        2422     0.0000    0.0000    0.0000        11\n","        2431     0.0000    0.0000    0.0000         4\n","        2432     0.0000    0.0000    0.0000         3\n","        2511     0.4706    0.9796    0.6358        49\n","        2512     0.0000    0.0000    0.0000         9\n","        2513     0.0000    0.0000    0.0000         3\n","        2521     0.0000    0.0000    0.0000         4\n","        2611     0.9822    0.9822    0.9822       169\n","        2619     0.8235    0.4828    0.6087        29\n","        2631     0.0000    0.0000    0.0000        16\n","        2632     0.0000    0.0000    0.0000         6\n","        2634     0.8769    0.9828    0.9268        58\n","        2635     0.8824    0.9375    0.9091        16\n","        2636     0.0000    0.0000    0.0000         2\n","        2641     0.0000    0.0000    0.0000         2\n","        2642     0.7500    0.5294    0.6207        17\n","        2643     0.0000    0.0000    0.0000         2\n","        2651     0.0000    0.0000    0.0000         9\n","        2656     0.0000    0.0000    0.0000         2\n","        3111     0.0000    0.0000    0.0000         8\n","        3112     0.6322    0.8594    0.7285        64\n","        3113     0.8295    0.8111    0.8202        90\n","        3114     0.9231    0.5217    0.6667        23\n","        3115     0.7470    0.8671    0.8026       143\n","        3117     0.0000    0.0000    0.0000         4\n","        3118     0.6842    0.7222    0.7027        18\n","        3119     0.0000    0.0000    0.0000         4\n","        3121     0.0000    0.0000    0.0000        10\n","        3122     0.0000    0.0000    0.0000        42\n","        3123     0.0000    0.0000    0.0000        30\n","        3124     0.3631    0.9048    0.5182       126\n","        3125     0.0000    0.0000    0.0000         8\n","        3126     0.0000    0.0000    0.0000         5\n","        3129     0.0000    0.0000    0.0000        25\n","        3131     0.0000    0.0000    0.0000         1\n","        3132     0.0000    0.0000    0.0000         9\n","        3141     0.0000    0.0000    0.0000         5\n","        3142     0.0000    0.0000    0.0000         9\n","        3143     0.0000    0.0000    0.0000         2\n","        3145     0.0000    0.0000    0.0000         2\n","        3149     0.0000    0.0000    0.0000        23\n","        3151     0.0000    0.0000    0.0000         2\n","        3152     0.6279    0.8438    0.7200        32\n","        3153     0.0000    0.0000    0.0000         1\n","        3211     0.0000    0.0000    0.0000         4\n","        3212     0.7895    1.0000    0.8824        30\n","        3213     0.7000    0.9608    0.8099        51\n","        3215     0.0000    0.0000    0.0000         4\n","        3221     0.9694    0.8837    0.9246       215\n","        3230     0.9524    0.8696    0.9091        23\n","        3240     0.0000    0.0000    0.0000         8\n","        3251     0.6000    0.5625    0.5806        16\n","        3253     0.0000    0.0000    0.0000         1\n","        3255     0.6765    0.9583    0.7931        24\n","        3256     0.0000    0.0000    0.0000         6\n","        3257     0.2857    0.0606    0.1000        33\n","        3258     0.0000    0.0000    0.0000         2\n","        3259     0.0000    0.0000    0.0000         4\n","        3313     0.8462    0.6471    0.7333        34\n","        3314     0.8336    0.9704    0.8968       506\n","        3315     0.0000    0.0000    0.0000         4\n","        3316     0.0000    0.0000    0.0000         2\n","        3317     0.0000    0.0000    0.0000        12\n","        3321     0.7857    0.6875    0.7333        16\n","        3322     0.6345    0.8929    0.7418       140\n","        3323     0.0000    0.0000    0.0000         6\n","        3331     0.0000    0.0000    0.0000         7\n","        3332     0.0000    0.0000    0.0000         7\n","        3334     0.0000    0.0000    0.0000        22\n","        3339     0.0000    0.0000    0.0000        15\n","        3341     0.0000    0.0000    0.0000         3\n","        3411     0.6200    0.7949    0.6966        39\n","        3412     0.0000    0.0000    0.0000         2\n","        3413     0.7368    0.9333    0.8235        15\n","        3421     1.0000    0.2000    0.3333        10\n","        3422     0.8500    0.9444    0.8947        36\n","        3423     0.0000    0.0000    0.0000         2\n","        3431     0.9412    0.8889    0.9143        18\n","        3432     0.0000    0.0000    0.0000         9\n","        3434     0.0000    0.0000    0.0000         7\n","        3439     0.8714    1.0000    0.9313        61\n","        3511     0.0000    0.0000    0.0000        32\n","        3512     0.0000    0.0000    0.0000        11\n","        3513     0.4727    0.6842    0.5591        38\n","        3514     0.0000    0.0000    0.0000         6\n","        3521     0.8125    0.5000    0.6190        26\n","        3522     0.0000    0.0000    0.0000         2\n","        3523     0.0000    0.0000    0.0000         7\n","        4110     0.8503    0.9239    0.8856       289\n","        4120     0.9581    0.9946    0.9760       184\n","        4131     0.8235    0.8235    0.8235        17\n","        4132     0.9143    0.9412    0.9275        34\n","        4211     0.0000    0.0000    0.0000        43\n","        4212     0.0000    0.0000    0.0000         5\n","        4213     0.0000    0.0000    0.0000         7\n","        4214     1.0000    0.6786    0.8085        28\n","        4221     0.0000    0.0000    0.0000         9\n","        4222     0.7529    0.9697    0.8477        66\n","        4223     0.0000    0.0000    0.0000        25\n","        4224     0.8667    0.9681    0.9146        94\n","        4225     1.0000    0.4000    0.5714        20\n","        4229     0.0000    0.0000    0.0000         4\n","        4311     0.0000    0.0000    0.0000        13\n","        4312     0.8261    0.9344    0.8769       122\n","        4313     0.0000    0.0000    0.0000         3\n","        4321     0.9103    0.9312    0.9206       218\n","        4323     0.0000    0.0000    0.0000        18\n","        4411     0.0000    0.0000    0.0000        13\n","        4412     0.0000    0.0000    0.0000        10\n","        4414     0.0000    0.0000    0.0000         3\n","        4415     0.0000    0.0000    0.0000         8\n","        4416     0.0000    0.0000    0.0000        15\n","        4417     0.6446    0.8917    0.7483       120\n","        4419     0.9182    0.9319    0.9250       602\n","        5111     0.0000    0.0000    0.0000         2\n","        5112     0.0000    0.0000    0.0000         4\n","        5113     1.0000    1.0000    1.0000        13\n","        5120     0.9601    0.9700    0.9650      1365\n","        5131     0.9595    0.9881    0.9736       336\n","        5132     0.0000    0.0000    0.0000        12\n","        5141     0.9756    0.7921    0.8743       101\n","        5142     0.7619    0.9412    0.8421        85\n","        5211     0.8986    0.9029    0.9007       412\n","        5212     0.9719    0.9830    0.9774      3587\n","        5213     0.9756    0.9693    0.9724      1074\n","        5221     0.0000    0.0000    0.0000        13\n","        5222     0.0000    0.0000    0.0000         7\n","        5223     0.0000    0.0000    0.0000         5\n","        5230     0.7912    1.0000    0.8834       144\n","        5241     1.0000    0.5294    0.6923        34\n","        5243     0.8276    0.9000    0.8623        80\n","        5244     0.8298    0.7959    0.8125        49\n","        5245     0.7949    0.6596    0.7209        47\n","        5311     0.6623    0.8644    0.7500        59\n","        5312     0.9167    0.9802    0.9474       101\n","        5321     0.0000    0.0000    0.0000         2\n","        5322     0.8750    0.2917    0.4375        24\n","        5329     0.9545    0.6774    0.7925        31\n","        5412     0.8276    0.9600    0.8889        75\n","        5413     0.0000    0.0000    0.0000         8\n","        5414     0.7419    0.9020    0.8142       102\n","        5419     0.0000    0.0000    0.0000         8\n","        6111     0.9798    0.9716    0.9757       599\n","        6112     0.9569    0.9845    0.9705       451\n","        6113     0.0000    0.0000    0.0000         3\n","        6114     0.9991    0.9998    0.9995      6562\n","        6121     0.9770    0.9807    0.9789       779\n","        6122     0.9309    0.9439    0.9374       214\n","        6123     0.0000    0.0000    0.0000         4\n","        6210     0.7059    0.7059    0.7059        34\n","        6221     0.0000    0.0000    0.0000         9\n","        6222     0.8082    0.9888    0.8894       179\n","        6223     0.0000    0.0000    0.0000        19\n","        6224     0.0000    0.0000    0.0000         4\n","        6310     0.0000    0.0000    0.0000         2\n","        6320     0.0000    0.0000    0.0000         5\n","        7111     0.9194    0.9161    0.9177       274\n","        7112     0.0000    0.0000    0.0000         6\n","        7113     0.9072    0.8302    0.8670       106\n","        7119     0.8606    0.9161    0.8875       155\n","        7121     0.0000    0.0000    0.0000         3\n","        7122     0.0000    0.0000    0.0000         1\n","        7123     0.0000    0.0000    0.0000        11\n","        7125     0.0000    0.0000    0.0000         2\n","        7126     0.6538    0.8947    0.7556        19\n","        7127     0.8485    0.9655    0.9032        58\n","        7128     0.7412    1.0000    0.8514       126\n","        7129     0.0000    0.0000    0.0000        37\n","        7212     0.8602    0.9412    0.8989       170\n","        7213     0.0000    0.0000    0.0000         3\n","        7214     0.0000    0.0000    0.0000         7\n","        7221     0.6207    0.8911    0.7317       101\n","        7222     0.0000    0.0000    0.0000        18\n","        7223     0.6667    0.1250    0.2105        16\n","        7224     0.0000    0.0000    0.0000         4\n","        7231     0.7872    0.9708    0.8694       240\n","        7233     0.0000    0.0000    0.0000         6\n","        7234     0.0000    0.0000    0.0000        35\n","        7235     0.0000    0.0000    0.0000         7\n","        7311     0.0000    0.0000    0.0000         7\n","        7312     0.6957    0.9057    0.7869        53\n","        7313     1.0000    0.2069    0.3429        29\n","        7321     0.0000    0.0000    0.0000         1\n","        7322     0.8820    0.9345    0.9075       168\n","        7331     0.0000    0.0000    0.0000         4\n","        7332     0.0000    0.0000    0.0000        15\n","        7333     0.0000    0.0000    0.0000         3\n","        7341     1.0000    0.5938    0.7451        32\n","        7342     0.0000    0.0000    0.0000        10\n","        7351     0.6829    0.9447    0.7927       253\n","        7352     0.7380    0.8415    0.7863       164\n","        7353     0.0000    0.0000    0.0000         5\n","        7354     0.7661    0.7915    0.7786       211\n","        7355     1.0000    0.1064    0.1923        47\n","        7356     0.0000    0.0000    0.0000         9\n","        7361     0.0000    0.0000    0.0000        14\n","        7362     0.7176    1.0000    0.8356        61\n","        7391     0.0000    0.0000    0.0000         7\n","        7392     0.0000    0.0000    0.0000         4\n","        7399     0.5938    0.7703    0.6706        74\n","        7411     0.7863    0.9035    0.8408       114\n","        7412     0.0000    0.0000    0.0000         5\n","        7421     0.5873    0.8506    0.6948        87\n","        7422     0.0000    0.0000    0.0000        24\n","        7431     0.0000    0.0000    0.0000         5\n","        7432     0.0000    0.0000    0.0000         2\n","        7511     0.8824    0.4412    0.5882        34\n","        7512     0.0000    0.0000    0.0000        11\n","        7513     0.9126    0.9882    0.9489       338\n","        7514     0.8000    0.9412    0.8649        34\n","        7515     0.0000    0.0000    0.0000        33\n","        7517     0.0000    0.0000    0.0000         3\n","        7518     0.8923    0.9206    0.9062        63\n","        7519     0.7209    0.4921    0.5849        63\n","        8111     0.7069    0.7736    0.7387        53\n","        8112     0.0000    0.0000    0.0000        14\n","        8113     0.0000    0.0000    0.0000         2\n","        8114     0.0000    0.0000    0.0000         4\n","        8121     0.0000    0.0000    0.0000         3\n","        8131     0.0000    0.0000    0.0000        16\n","        8141     0.8710    0.8710    0.8710        31\n","        8142     0.0000    0.0000    0.0000        16\n","        8151     0.0000    0.0000    0.0000         4\n","        8152     0.0000    0.0000    0.0000         9\n","        8153     0.0000    0.0000    0.0000        13\n","        8154     0.0000    0.0000    0.0000         3\n","        8156     0.0000    0.0000    0.0000         7\n","        8159     0.0000    0.0000    0.0000         5\n","        8160     0.0000    0.0000    0.0000        13\n","        8171     0.7368    0.6667    0.7000        21\n","        8173     0.0000    0.0000    0.0000         3\n","        8181     0.0000    0.0000    0.0000        10\n","        8183     0.0000    0.0000    0.0000         4\n","        8189     0.0000    0.0000    0.0000        23\n","        8321     0.9809    0.9809    0.9809       940\n","        8322     0.9761    0.9459    0.9607       776\n","        8331     0.7950    0.9360    0.8597       203\n","        8332     0.9231    0.9306    0.9268       245\n","        8341     0.6875    0.8462    0.7586        39\n","        8342     0.6250    0.1639    0.2597        61\n","        8343     0.4573    0.8426    0.5928       108\n","        8351     0.0000    0.0000    0.0000         2\n","        8352     0.9394    0.8158    0.8732        38\n","        9111     0.9914    0.9957    0.9935       694\n","        9112     0.9286    0.9286    0.9286       546\n","        9121     0.9617    0.9901    0.9757       203\n","        9122     0.9143    0.9143    0.9143        35\n","        9124     0.0000    0.0000    0.0000         3\n","        9129     0.0000    0.0000    0.0000        16\n","        9211     0.9981    0.9975    0.9978      9854\n","        9212     0.0000    0.0000    0.0000        13\n","        9213     0.6471    0.3143    0.4231        35\n","        9214     0.9333    0.5833    0.7179        24\n","        9311     0.8889    0.9846    0.9343       130\n","        9312     0.9509    0.9064    0.9281       171\n","        9313     0.9831    0.9807    0.9819      1242\n","        9321     0.5683    0.9080    0.6991        87\n","        9329     0.0000    0.0000    0.0000         9\n","        9331     0.8718    0.7391    0.8000        46\n","        9332     0.0000    0.0000    0.0000         2\n","        9333     0.9083    0.9654    0.9360       318\n","        9334     0.8571    0.9818    0.9153        55\n","        9411     0.8860    0.8638    0.8748       279\n","        9412     0.9138    0.9587    0.9357       774\n","        9511     0.7759    0.9000    0.8333       150\n","        9512     0.0000    0.0000    0.0000        17\n","        9521     0.8208    0.9161    0.8659       155\n","        9522     0.0000    0.0000    0.0000        19\n","        9523     1.0000    0.8438    0.9153        32\n","        9524     0.7317    0.6977    0.7143        43\n","        9531     0.8710    0.6750    0.7606        40\n","        9533     0.9404    0.9498    0.9451       299\n","        9534     0.0000    0.0000    0.0000         6\n","        9535     0.9188    0.9095    0.9141       199\n","        9536     0.0000    0.0000    0.0000        12\n","        9537     0.0000    0.0000    0.0000         7\n","        9541     0.0000    0.0000    0.0000        33\n","        9542     0.0000    0.0000    0.0000         3\n","        9549     0.4459    0.7527    0.5600        93\n","        9611     0.0000    0.0000    0.0000        15\n","        9612     0.8611    0.9789    0.9163        95\n","        9613     0.7284    0.8551    0.7867        69\n","        9621     0.8521    0.9237    0.8864       131\n","        9622     0.9323    0.9372    0.9347       382\n","        9623     0.0000    0.0000    0.0000         3\n","        9624     0.0000    0.0000    0.0000         3\n","        9629     0.5961    0.6488    0.6213       951\n","\n","    accuracy                         0.9178     47332\n","   macro avg     0.3694    0.3737    0.3619     47332\n","weighted avg     0.8950    0.9178    0.9029     47332\n","\n","\n","‚úÖ Reporte guardado en: /content/drive/MyDrive/classification_coding_open_ended_occupational_responses_ENAHO/05_XLM_ROBERTA/res_modelo_2/xlm-roberta-base_multimodal_20251110_073138/classification_report.txt\n","\n","================================================================================\n","üîç AN√ÅLISIS DE ERRORES\n","================================================================================\n","\n","Total: 47,332\n","Correctas: 43,439\n","Incorrectas: 3,893 (8.22%)\n","\n","‚úÖ An√°lisis de errores guardado en: /content/drive/MyDrive/classification_coding_open_ended_occupational_responses_ENAHO/05_XLM_ROBERTA/res_modelo_2/xlm-roberta-base_multimodal_20251110_073138/error_analysis.csv\n","\n","================================================================================\n","\n"]}],"id":"fwMph7pASH9I"},{"cell_type":"code","source":["preds = trainer.predict(test_dataset)\n","print(preds.metrics)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":54},"id":"6MVPM7-5Leoj","executionInfo":{"status":"ok","timestamp":1762768440709,"user_tz":300,"elapsed":121558,"user":{"displayName":"Brayan Poma Huaman","userId":"00419443262019466393"}},"outputId":"f28b6c38-d725-4602-ef6c-238c6167c757"},"id":"6MVPM7-5Leoj","execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["{'test_loss': 0.44273921847343445, 'test_accuracy': 0.9177512042592749, 'test_f1_macro': 0.3619313712806495, 'test_f1_micro': 0.9177512042592749, 'test_f1_weighted': 0.9029051868778002, 'test_precision_macro': 0.3693755989200456, 'test_precision_micro': 0.9177512042592749, 'test_precision_weighted': 0.8950139455928376, 'test_recall_macro': 0.37366813328528076, 'test_recall_micro': 0.9177512042592749, 'test_recall_weighted': 0.9177512042592749, 'test_runtime': 121.5236, 'test_samples_per_second': 389.488, 'test_steps_per_second': 24.349}\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"n-lGOSTzSH9J","executionInfo":{"status":"ok","timestamp":1762767736614,"user_tz":300,"elapsed":17036,"user":{"displayName":"Brayan Poma Huaman","userId":"00419443262019466393"}},"outputId":"e27133f1-2b68-4379-ff3c-b794590419b8"},"source":["# ============================================================================\n","# üíæ GUARDADO COMPLETO DEL MODELO Y ARTEFACTOS\n","# ============================================================================\n","\n","print(\"\\n\" + \"=\"*80)\n","print(\"üíæ GUARDANDO MODELO Y ARTEFACTOS\")\n","print(\"=\"*80 + \"\\n\")\n","\n","try:\n","    # 1. Guardar modelo completo\n","    torch.save({\n","        'model_state_dict': model.state_dict(),\n","        'config': {\n","            'model_name': config.MODEL_NAME,\n","            'num_labels': len(label2id),\n","            'categorical_cardinalities': config.CATEGORICAL_CARDINALITIES,\n","            'categorical_embedding_dim': config.CATEGORICAL_EMBEDDING_DIM,\n","            'fusion_hidden_dim': config.FUSION_HIDDEN_DIM,\n","            'dropout_rate': config.DROPOUT_RATE,\n","        }\n","    }, os.path.join(config.MODEL_SAVE_DIR, 'pytorch_model.bin'))\n","\n","    # 2. Guardar tokenizer\n","    tokenizer.save_pretrained(config.MODEL_SAVE_DIR)\n","\n","    print(f\"‚úÖ Modelo guardado en: {config.MODEL_SAVE_DIR}\")\n","\n","    # 3. Guardar artefactos\n","    artifacts = {\n","        'label2id': label2id,\n","        'id2label': id2label,\n","        'num_labels': len(label2id),\n","        'model_name': config.MODEL_NAME,\n","        'model_type': config.model_type,\n","        'text_column': config.TEXT_COLUMN,\n","        'numeric_features': config.NUMERIC_FEATURES,\n","        'categorical_features': config.CATEGORICAL_FEATURES,\n","        'categorical_cardinalities': config.CATEGORICAL_CARDINALITIES,\n","        'target_column': config.TARGET_COLUMN,\n","        'max_length': config.MAX_LENGTH,\n","        'categorical_embedding_dim': config.CATEGORICAL_EMBEDDING_DIM,\n","        'fusion_hidden_dim': config.FUSION_HIDDEN_DIM,\n","        'dropout_rate': config.DROPOUT_RATE,\n","        'test_metrics': test_metrics,\n","        'training_date': datetime.now().isoformat(),\n","        'scaler': data_loader.scaler,  # Guardar el scaler\n","    }\n","\n","    artifacts_file = os.path.join(config.OUTPUT_DIR, 'artifacts.pkl')\n","    with open(artifacts_file, 'wb') as f:\n","        pickle.dump(artifacts, f)\n","\n","    print(f\"‚úÖ Artefactos guardados en: {artifacts_file}\")\n","\n","    # 4. Crear README\n","    readme_content = f\"\"\"# Modelo Multimodal: {config.experiment_name}\n","\n","## Informaci√≥n del Modelo\n","- **Modelo Base**: {config.MODEL_NAME}\n","- **Tipo**: Multimodal (Texto + Num√©ricas + Categ√≥ricas)\n","- **N√∫mero de Clases**: {len(label2id)}\n","- **Fecha de Entrenamiento**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n","\n","## Features de Entrada\n","1. **Texto**: {config.TEXT_COLUMN}\n","2. **Num√©ricas**: {', '.join(config.NUMERIC_FEATURES)}\n","3. **Categ√≥ricas**: {', '.join(config.CATEGORICAL_FEATURES)}\n","\n","## Arquitectura\n","- Transformer dim: {model.transformer_dim}\n","- Embedding categ√≥rico: {config.CATEGORICAL_EMBEDDING_DIM}D\n","- Fusion hidden: {config.FUSION_HIDDEN_DIM}D\n","- Dropout: {config.DROPOUT_RATE}\n","\n","## Resultados (Test Set)\n","- **Accuracy**: {test_metrics.get('test_accuracy', test_metrics.get('eval_accuracy', 0)):.4f}\n","- **F1 Weighted**: {test_metrics.get('test_f1_weighted', test_metrics.get('eval_f1_weighted', 0)):.4f}\n","- **F1 Macro**: {test_metrics.get('test_f1_macro', test_metrics.get('eval_f1_macro', 0)):.4f}\n","\n","## Archivos\n","- `pytorch_model.bin`: Modelo completo\n","- `artifacts.pkl`: Mapeos y metadata (incluye scaler)\n","- `test_metrics.json`: M√©tricas completas\n","- `classification_report.txt`: Reporte por clase\n","- `error_analysis.csv`: An√°lisis de errores\n","\"\"\"\n","\n","    readme_file = os.path.join(config.OUTPUT_DIR, 'README.md')\n","    with open(readme_file, 'w', encoding='utf-8') as f:\n","        f.write(readme_content)\n","\n","    print(f\"‚úÖ README creado en: {readme_file}\")\n","\n","    print(\"\\n\" + \"=\"*80)\n","    print(\"üéâ GUARDADO COMPLETADO\")\n","    print(\"=\"*80 + \"\\n\")\n","\n","except Exception as e:\n","    print(\"\\n‚ùå ERROR AL GUARDAR\")\n","    print(f\"\\n{str(e)}\\n\")\n","    raise\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","================================================================================\n","üíæ GUARDANDO MODELO Y ARTEFACTOS\n","================================================================================\n","\n","‚úÖ Modelo guardado en: /content/drive/MyDrive/classification_coding_open_ended_occupational_responses_ENAHO/05_XLM_ROBERTA/res_modelo_2/xlm-roberta-base_multimodal_20251110_073138/final_model\n","‚úÖ Artefactos guardados en: /content/drive/MyDrive/classification_coding_open_ended_occupational_responses_ENAHO/05_XLM_ROBERTA/res_modelo_2/xlm-roberta-base_multimodal_20251110_073138/artifacts.pkl\n","‚úÖ README creado en: /content/drive/MyDrive/classification_coding_open_ended_occupational_responses_ENAHO/05_XLM_ROBERTA/res_modelo_2/xlm-roberta-base_multimodal_20251110_073138/README.md\n","\n","================================================================================\n","üéâ GUARDADO COMPLETADO\n","================================================================================\n","\n"]}],"id":"n-lGOSTzSH9J"},{"cell_type":"markdown","metadata":{"id":"g9-P4HEcSH9J"},"source":["---\n","\n","# üéâ ¬°ENTRENAMIENTO MULTIMODAL COMPLETADO!\n","\n","## üìä Modelo Entrenado\n","\n","Has entrenado exitosamente un **modelo multimodal** que combina:\n","- üìù **Texto** procesado con Transformer\n","- üî¢ **Features num√©ricas** (edad) normalizadas\n","- üìä **Features categ√≥ricas** (nivel educativo, desempe√±o) con embeddings\n","\n","## üéØ Pr√≥ximos Pasos\n","\n","### Para comparar con baseline:\n","1. Entrena el modelo solo-texto (`training_script_universal.ipynb`)\n","2. Compara las m√©tricas:\n","   - Si mejora >1%: El modelo multimodal vale la pena ‚úÖ\n","   - Si mejora <1%: Considera la complejidad adicional ‚ö†Ô∏è\n","\n","### Para mejorar el modelo:\n","- Ajusta `CATEGORICAL_EMBEDDING_DIM`\n","- Experimenta con `FUSION_HIDDEN_DIM`\n","- Prueba diferentes `DROPOUT_RATE`\n","- Agrega m√°s features si est√°n disponibles\n","\n","### Para usar el modelo:\n","Consulta `GUIA_MODELO_MULTIMODAL.md` para instrucciones de inferencia\n","\n","---\n","\n","**¬°Modelo multimodal listo! üöÄ**\n"],"id":"g9-P4HEcSH9J"}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.0"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}