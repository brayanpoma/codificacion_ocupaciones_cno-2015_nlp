{"cells":[{"cell_type":"markdown","metadata":{"id":"HZsUKvPcIKbi"},"source":["# üöÄ Entrenamiento de Modelos Transformer para Clasificaci√≥n de Ocupaciones ENAHO\n","\n","---\n","\n","## üìã Descripci√≥n\n","Script robusto y universal para entrenar modelos de clasificaci√≥n de texto.\n","\n","### üéØ Modelos Soportados:\n","- **BETO**: `dccuchile/bert-base-spanish-wwm-cased` (Espa√±ol)\n","- **XLM-RoBERTa**: `FacebookAI/xlm-roberta-base` (Multiling√ºe)\n","\n","### ‚ú® Caracter√≠sticas:\n","- ‚úÖ Cambio de modelo con una sola variable\n","- ‚úÖ M√©tricas detalladas (macro, micro, weighted)\n","- ‚úÖ Manejo robusto de errores\n","- ‚úÖ Logging detallado para debugging\n","- ‚úÖ Validaci√≥n de datos en cada paso\n","- ‚úÖ Guardado completo de modelo y artefactos\n","- ‚úÖ Funciones de predicci√≥n e inferencia\n","\n","---\n","\n","**Autor**: Sistema de Clasificaci√≥n ENAHO  \n","**Fecha**: 2025  \n","**Entorno**: VSCode con Jupyter Notebook  \n"],"id":"HZsUKvPcIKbi"},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5jXhWE22Ii01","executionInfo":{"status":"ok","timestamp":1762988138655,"user_tz":300,"elapsed":21633,"user":{"displayName":"BRAYAN POMA HUAMAN","userId":"12837018889427630165"}},"outputId":"af825230-83d9-43cc-9083-63a244f9ce98"},"id":"5jXhWE22Ii01","execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9LksZDJXIKbq","executionInfo":{"status":"ok","timestamp":1762988138668,"user_tz":300,"elapsed":15,"user":{"displayName":"BRAYAN POMA HUAMAN","userId":"12837018889427630165"}},"outputId":"dc8cb488-d522-4977-ea80-1b19ea330968"},"source":["# ============================================================================\n","# INSTALACI√ìN DE DEPENDENCIAS (Ejecutar solo una vez)\n","# ============================================================================\n","\n","# Descomenta si necesitas instalar las librer√≠as\n","# !pip install transformers==4.36.0 datasets==2.15.0 scikit-learn==1.3.2\n","# !pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n","# !pip install accelerate sentencepiece\n","\n","print(\"‚úÖ Si las librer√≠as ya est√°n instaladas, puedes continuar\")\n"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["‚úÖ Si las librer√≠as ya est√°n instaladas, puedes continuar\n"]}],"id":"9LksZDJXIKbq"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YAmxPXboIKbr","executionInfo":{"status":"ok","timestamp":1762988186726,"user_tz":300,"elapsed":48056,"user":{"displayName":"BRAYAN POMA HUAMAN","userId":"12837018889427630165"}},"outputId":"62a71686-7a75-4962-b62b-7ff6c92e68fa"},"source":["# ============================================================================\n","# IMPORTACIONES Y VERIFICACI√ìN DEL ENTORNO\n","# ============================================================================\n","\n","import sys\n","import os\n","import warnings\n","import logging\n","from datetime import datetime\n","from pathlib import Path\n","\n","# Data & ML\n","import pandas as pd\n","import numpy as np\n","import torch\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import (\n","    accuracy_score,\n","    precision_recall_fscore_support,\n","    classification_report,\n","    confusion_matrix\n",")\n","\n","# Transformers\n","from transformers import (\n","    AutoTokenizer,\n","    AutoModelForSequenceClassification,\n","    TrainingArguments,\n","    Trainer,\n","    EarlyStoppingCallback\n",")\n","from torch.utils.data import Dataset\n","\n","# Utilities\n","from tqdm.auto import tqdm\n","import pickle\n","import json\n","\n","warnings.filterwarnings('ignore')\n","\n","# ============================================================================\n","# CONFIGURACI√ìN DE LOGGING\n","# ============================================================================\n","\n","def setup_logging(output_dir):\n","    \"\"\"Configura el sistema de logging para debugging\"\"\"\n","    os.makedirs(output_dir, exist_ok=True)\n","    log_file = os.path.join(output_dir, f'training_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.log')\n","\n","    logging.basicConfig(\n","        level=logging.INFO,\n","        format='%(asctime)s - %(levelname)s - %(message)s',\n","        handlers=[\n","            logging.FileHandler(log_file, encoding='utf-8'),\n","            logging.StreamHandler(sys.stdout)\n","        ]\n","    )\n","    return logging.getLogger(__name__)\n","\n","# ============================================================================\n","# VERIFICACI√ìN DE GPU\n","# ============================================================================\n","\n","print(\"\\n\" + \"=\"*80)\n","print(\"üîç VERIFICACI√ìN DEL ENTORNO\")\n","print(\"=\"*80)\n","\n","print(f\"\\nüì¶ Versiones:\")\n","print(f\"   Python: {sys.version.split()[0]}\")\n","print(f\"   PyTorch: {torch.__version__}\")\n","print(f\"   CUDA disponible: {torch.cuda.is_available()}\")\n","\n","if torch.cuda.is_available():\n","    print(f\"\\nüéÆ GPU Detectada:\")\n","    print(f\"   Dispositivo: {torch.cuda.get_device_name(0)}\")\n","    print(f\"   Memoria total: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n","    print(f\"   Memoria libre: {(torch.cuda.get_device_properties(0).total_memory - torch.cuda.memory_allocated(0)) / 1e9:.2f} GB\")\n","else:\n","    print(\"\\n‚ö†Ô∏è  GPU no detectada - El entrenamiento ser√° lento\")\n","    print(\"   Considera usar Google Colab o configurar CUDA\")\n","\n","print(\"\\n\" + \"=\"*80)\n","print(\"‚úÖ Importaciones completadas correctamente\")\n","print(\"=\"*80 + \"\\n\")\n"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","================================================================================\n","üîç VERIFICACI√ìN DEL ENTORNO\n","================================================================================\n","\n","üì¶ Versiones:\n","   Python: 3.12.12\n","   PyTorch: 2.8.0+cu126\n","   CUDA disponible: True\n","\n","üéÆ GPU Detectada:\n","   Dispositivo: Tesla T4\n","   Memoria total: 15.83 GB\n","   Memoria libre: 15.83 GB\n","\n","================================================================================\n","‚úÖ Importaciones completadas correctamente\n","================================================================================\n","\n"]}],"id":"YAmxPXboIKbr"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":591},"id":"xfu88qZ_IKbs","executionInfo":{"status":"ok","timestamp":1762988187960,"user_tz":300,"elapsed":1226,"user":{"displayName":"BRAYAN POMA HUAMAN","userId":"12837018889427630165"}},"outputId":"f50d8a02-c097-4225-b92d-df9114560dff"},"source":["# ============================================================================\n","# ‚öôÔ∏è  CONFIGURACI√ìN PRINCIPAL - MODIFICA AQU√ç\n","# ============================================================================\n","\n","class ModelConfig:\n","    \"\"\"\n","    Configuraci√≥n centralizada del modelo y entrenamiento\n","\n","    IMPORTANTE: Solo necesitas cambiar MODEL_NAME para entrenar un modelo diferente\n","    \"\"\"\n","\n","    # ========================================================================\n","    # üéØ SELECCI√ìN DEL MODELO - CAMBIA SOLO ESTA L√çNEA\n","    # ========================================================================\n","\n","    # MODEL_NAME = \"FacebookAI/xlm-roberta-base\"  # Opci√≥n 1: XLM-RoBERTa (multiling√ºe)\n","    # MODEL_NAME = \"dccuchile/bert-base-spanish-wwm-cased\"  # Opci√≥n 2: BETO (espa√±ol)\n","    MODEL_NAME = \"bertin-project/bertin-roberta-base-spanish\"\n","\n","    # ========================================================================\n","    # üìÇ RUTAS DE DATOS\n","    # ========================================================================\n","\n","    # Ruta al archivo de datos (ajusta seg√∫n tu ubicaci√≥n)\n","    DATA_PATH = \"/content/drive/MyDrive/PI_PEU/BASE_LIMPIA_VF.parquet\"  # Cambia esta ruta\n","\n","    # Directorio base para outputs\n","    BASE_OUTPUT_DIR = \"/content/drive/MyDrive/Colab Notebooks/PI_PEU/Robertabne\"\n","\n","    # ========================================================================\n","    # üìä COLUMNAS DEL DATASET\n","    # ========================================================================\n","\n","    TEXT_COLUMN = \"texto_final\"  # Columna con el texto\n","    TARGET_COLUMN = \"p505r4\"     # Columna objetivo (clase)\n","\n","    # ========================================================================\n","    # üéõÔ∏è  HIPERPAR√ÅMETROS DE ENTRENAMIENTO\n","    # ========================================================================\n","\n","    # Tokenizaci√≥n\n","    MAX_LENGTH = 128  # Longitud m√°xima de tokens\n","\n","    # Entrenamiento\n","    BATCH_SIZE = 16          # Ajusta seg√∫n tu GPU (16, 32, 64)\n","    LEARNING_RATE = 2e-5     # Tasa de aprendizaje\n","    NUM_EPOCHS = 3           # N√∫mero de √©pocas\n","    WARMUP_STEPS = 500       # Pasos de warmup\n","    WEIGHT_DECAY = 0.01      # Regularizaci√≥n\n","\n","    # Divisi√≥n de datos\n","    TEST_SIZE = 0.15         # 15% para test\n","    VAL_SIZE = 0.15          # 15% para validaci√≥n\n","    RANDOM_STATE = 2025      # Semilla para reproducibilidad\n","\n","    # Filtrado de clases raras\n","    MIN_SAMPLES_PER_CLASS = 10  # M√≠nimo de muestras por clase\n","\n","    # Early stopping\n","    EARLY_STOPPING_PATIENCE = 3\n","\n","    # ========================================================================\n","    # üîß CONFIGURACI√ìN AUTOM√ÅTICA (NO MODIFICAR)\n","    # ========================================================================\n","\n","    def __init__(self):\n","        \"\"\"Inicializa configuraci√≥n y crea directorios\"\"\"\n","        # Detectar tipo de modelo del nombre\n","        if \"roberta\" in self.MODEL_NAME.lower():\n","            self.model_type = \"xlm-roberta\"\n","        elif \"bert\" in self.MODEL_NAME.lower():\n","            self.model_type = \"bert\"\n","        else:\n","            self.model_type = \"transformer\"\n","\n","        # Crear nombre descriptivo para el experimento\n","        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n","        model_short_name = self.MODEL_NAME.split('/')[-1]\n","        self.experiment_name = f\"{model_short_name}_{timestamp}\"\n","\n","        # Configurar directorios\n","        self.OUTPUT_DIR = os.path.join(self.BASE_OUTPUT_DIR, self.experiment_name)\n","        self.MODEL_SAVE_DIR = os.path.join(self.OUTPUT_DIR, \"final_model\")\n","        self.CHECKPOINT_DIR = os.path.join(self.OUTPUT_DIR, \"checkpoints\")\n","\n","        # Crear directorios\n","        for dir_path in [self.OUTPUT_DIR, self.MODEL_SAVE_DIR, self.CHECKPOINT_DIR]:\n","            os.makedirs(dir_path, exist_ok=True)\n","\n","        # Device\n","        self.DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","\n","        # Configurar logging\n","        self.logger = setup_logging(self.OUTPUT_DIR)\n","        self.logger.info(f\"Experimento iniciado: {self.experiment_name}\")\n","        self.logger.info(f\"Modelo seleccionado: {self.MODEL_NAME}\")\n","        self.logger.info(f\"Dispositivo: {self.DEVICE}\")\n","\n","    def display_config(self):\n","        \"\"\"Muestra la configuraci√≥n actual\"\"\"\n","        print(\"\\n\" + \"=\"*80)\n","        print(\"‚öôÔ∏è  CONFIGURACI√ìN DEL MODELO\")\n","        print(\"=\"*80)\n","        print(f\"\\nü§ñ Modelo: {self.MODEL_NAME}\")\n","        print(f\"   Tipo: {self.model_type}\")\n","        print(f\"   Experimento: {self.experiment_name}\")\n","        print(f\"\\nüìÇ Rutas:\")\n","        print(f\"   Datos: {self.DATA_PATH}\")\n","        print(f\"   Output: {self.OUTPUT_DIR}\")\n","        print(f\"   Modelo final: {self.MODEL_SAVE_DIR}\")\n","        print(f\"\\nüìä Datos:\")\n","        print(f\"   Columna texto: {self.TEXT_COLUMN}\")\n","        print(f\"   Columna target: {self.TARGET_COLUMN}\")\n","        print(f\"   Max length: {self.MAX_LENGTH}\")\n","        print(f\"\\nüéõÔ∏è  Entrenamiento:\")\n","        print(f\"   Batch size: {self.BATCH_SIZE}\")\n","        print(f\"   Learning rate: {self.LEARNING_RATE}\")\n","        print(f\"   Epochs: {self.NUM_EPOCHS}\")\n","        print(f\"   Early stopping: {self.EARLY_STOPPING_PATIENCE} epochs\")\n","        print(f\"\\nüíæ Divisi√≥n de datos:\")\n","        print(f\"   Test: {self.TEST_SIZE*100:.0f}%\")\n","        print(f\"   Validaci√≥n: {self.VAL_SIZE*100:.0f}%\")\n","        print(f\"   Train: {(1-self.TEST_SIZE-self.VAL_SIZE)*100:.0f}%\")\n","        print(\"\\n\" + \"=\"*80 + \"\\n\")\n","\n","    def save_config(self):\n","        \"\"\"Guarda la configuraci√≥n en JSON\"\"\"\n","        config_dict = {\n","            'model_name': self.MODEL_NAME,\n","            'model_type': self.model_type,\n","            'experiment_name': self.experiment_name,\n","            'data_path': self.DATA_PATH,\n","            'text_column': self.TEXT_COLUMN,\n","            'target_column': self.TARGET_COLUMN,\n","            'max_length': self.MAX_LENGTH,\n","            'batch_size': self.BATCH_SIZE,\n","            'learning_rate': self.LEARNING_RATE,\n","            'num_epochs': self.NUM_EPOCHS,\n","            'test_size': self.TEST_SIZE,\n","            'val_size': self.VAL_SIZE,\n","            'random_state': self.RANDOM_STATE,\n","            'min_samples_per_class': self.MIN_SAMPLES_PER_CLASS,\n","            'device': self.DEVICE,\n","            'timestamp': datetime.now().isoformat()\n","        }\n","\n","        config_path = os.path.join(self.OUTPUT_DIR, 'config.json')\n","        with open(config_path, 'w', encoding='utf-8') as f:\n","            json.dump(config_dict, f, indent=2, ensure_ascii=False)\n","\n","        self.logger.info(f\"Configuraci√≥n guardada en: {config_path}\")\n","        return config_path\n","\n","\n","# Inicializar configuraci√≥n\n","config = ModelConfig()\n","config.display_config()\n","config.save_config()\n"],"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","================================================================================\n","‚öôÔ∏è  CONFIGURACI√ìN DEL MODELO\n","================================================================================\n","\n","ü§ñ Modelo: bertin-project/bertin-roberta-base-spanish\n","   Tipo: xlm-roberta\n","   Experimento: bertin-roberta-base-spanish_20251112_225626\n","\n","üìÇ Rutas:\n","   Datos: /content/drive/MyDrive/PI_PEU/BASE_LIMPIA_VF.parquet\n","   Output: /content/drive/MyDrive/Colab Notebooks/PI_PEU/Robertabne/bertin-roberta-base-spanish_20251112_225626\n","   Modelo final: /content/drive/MyDrive/Colab Notebooks/PI_PEU/Robertabne/bertin-roberta-base-spanish_20251112_225626/final_model\n","\n","üìä Datos:\n","   Columna texto: texto_final\n","   Columna target: p505r4\n","   Max length: 128\n","\n","üéõÔ∏è  Entrenamiento:\n","   Batch size: 16\n","   Learning rate: 2e-05\n","   Epochs: 3\n","   Early stopping: 3 epochs\n","\n","üíæ Divisi√≥n de datos:\n","   Test: 15%\n","   Validaci√≥n: 15%\n","   Train: 70%\n","\n","================================================================================\n","\n"]},{"output_type":"execute_result","data":{"text/plain":["'/content/drive/MyDrive/Colab Notebooks/PI_PEU/Robertabne/bertin-roberta-base-spanish_20251112_225626/config.json'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":4}],"id":"xfu88qZ_IKbs"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qfG0DkcRIKbt","executionInfo":{"status":"ok","timestamp":1762988197747,"user_tz":300,"elapsed":9769,"user":{"displayName":"BRAYAN POMA HUAMAN","userId":"12837018889427630165"}},"outputId":"34b6b467-3311-475f-8574-5d52560a3099"},"source":["# ============================================================================\n","# üìÇ CARGA Y VALIDACI√ìN DE DATOS\n","# ============================================================================\n","\n","class DataLoader:\n","    \"\"\"Cargador y validador de datos con manejo robusto de errores\"\"\"\n","\n","    def __init__(self, config):\n","        self.config = config\n","        self.logger = config.logger\n","\n","    def load_data(self):\n","        \"\"\"\n","        Carga datos desde archivo con validaci√≥n\n","\n","        Returns:\n","            pd.DataFrame: Datos cargados\n","        \"\"\"\n","        try:\n","            self.logger.info(f\"Cargando datos desde: {self.config.DATA_PATH}\")\n","\n","            # Verificar que el archivo existe\n","            if not os.path.exists(self.config.DATA_PATH):\n","                raise FileNotFoundError(\n","                    f\"‚ùå El archivo no existe: {self.config.DATA_PATH}\\n\"\n","                    f\"   Por favor, verifica la ruta en ModelConfig.DATA_PATH\"\n","                )\n","\n","            # Cargar seg√∫n extensi√≥n\n","            file_ext = os.path.splitext(self.config.DATA_PATH)[1].lower()\n","\n","            if file_ext == '.parquet':\n","                df = pd.read_parquet(self.config.DATA_PATH)\n","            elif file_ext == '.csv':\n","                df = pd.read_csv(self.config.DATA_PATH)\n","            elif file_ext in ['.xlsx', '.xls']:\n","                df = pd.read_excel(self.config.DATA_PATH)\n","            else:\n","                raise ValueError(\n","                    f\"‚ùå Formato no soportado: {file_ext}\\n\"\n","                    f\"   Formatos v√°lidos: .parquet, .csv, .xlsx, .xls\"\n","                )\n","\n","            self.logger.info(f\"‚úÖ Datos cargados: {df.shape[0]:,} filas x {df.shape[1]} columnas\")\n","\n","            return df\n","\n","        except Exception as e:\n","            self.logger.error(f\"‚ùå Error al cargar datos: {str(e)}\")\n","            raise\n","\n","    def validate_data(self, df):\n","        \"\"\"\n","        Valida que los datos tengan las columnas necesarias\n","\n","        Args:\n","            df: DataFrame a validar\n","\n","        Raises:\n","            ValueError: Si faltan columnas requeridas\n","        \"\"\"\n","        self.logger.info(\"Validando estructura de datos...\")\n","\n","        # Verificar columnas requeridas\n","        required_cols = [self.config.TEXT_COLUMN, self.config.TARGET_COLUMN]\n","        missing_cols = [col for col in required_cols if col not in df.columns]\n","\n","        if missing_cols:\n","            available_cols = list(df.columns)\n","            raise ValueError(\n","                f\"‚ùå Columnas faltantes: {missing_cols}\\n\"\n","                f\"   Columnas disponibles: {available_cols}\\n\"\n","                f\"   Verifica TEXT_COLUMN y TARGET_COLUMN en ModelConfig\"\n","            )\n","\n","        # Validar datos no nulos\n","        null_text = df[self.config.TEXT_COLUMN].isna().sum()\n","        null_target = df[self.config.TARGET_COLUMN].isna().sum()\n","\n","        self.logger.info(\n","            f\"   Valores nulos - Texto: {null_text:,}, Target: {null_target:,}\"\n","        )\n","\n","        # Validar textos vac√≠os\n","        empty_text = (df[self.config.TEXT_COLUMN].str.strip() == '').sum()\n","        if empty_text > 0:\n","            self.logger.warning(f\"   ‚ö†Ô∏è  Textos vac√≠os: {empty_text:,}\")\n","\n","        self.logger.info(\"‚úÖ Validaci√≥n completada\")\n","\n","    def filter_valid_records(self, df):\n","        \"\"\"\n","        Filtra registros v√°lidos (no nulos, no vac√≠os)\n","\n","        Args:\n","            df: DataFrame original\n","\n","        Returns:\n","            pd.DataFrame: DataFrame filtrado\n","        \"\"\"\n","        self.logger.info(\"Filtrando registros v√°lidos...\")\n","\n","        initial_count = len(df)\n","\n","        # Filtrar nulos y vac√≠os\n","        df_clean = df[\n","            df[self.config.TEXT_COLUMN].notna() &\n","            df[self.config.TARGET_COLUMN].notna() &\n","            (df[self.config.TEXT_COLUMN].str.strip() != '')\n","        ].copy()\n","\n","        final_count = len(df_clean)\n","        removed = initial_count - final_count\n","\n","        self.logger.info(\n","            f\"   Registros iniciales: {initial_count:,}\\n\"\n","            f\"   Registros v√°lidos: {final_count:,}\\n\"\n","            f\"   Removidos: {removed:,} ({removed/initial_count*100:.2f}%)\"\n","        )\n","\n","        if final_count == 0:\n","            raise ValueError(\n","                \"‚ùå No quedan registros v√°lidos despu√©s del filtrado\\n\"\n","                \"   Verifica la calidad de tus datos\"\n","            )\n","\n","        return df_clean\n","\n","    def filter_rare_classes(self, df):\n","        \"\"\"\n","        Filtra clases con pocas muestras\n","\n","        Args:\n","            df: DataFrame\n","\n","        Returns:\n","            pd.DataFrame: DataFrame filtrado\n","        \"\"\"\n","        self.logger.info(\n","            f\"Filtrando clases con < {self.config.MIN_SAMPLES_PER_CLASS} muestras...\"\n","        )\n","\n","        # Contar muestras por clase\n","        class_counts = df[self.config.TARGET_COLUMN].value_counts()\n","\n","        # Identificar clases v√°lidas\n","        valid_classes = class_counts[class_counts >= self.config.MIN_SAMPLES_PER_CLASS].index\n","        rare_classes = class_counts[class_counts < self.config.MIN_SAMPLES_PER_CLASS]\n","\n","        # Filtrar\n","        df_filtered = df[df[self.config.TARGET_COLUMN].isin(valid_classes)].copy()\n","\n","        self.logger.info(\n","            f\"   Clases originales: {len(class_counts):,}\\n\"\n","            f\"   Clases mantenidas: {len(valid_classes):,}\\n\"\n","            f\"   Clases removidas: {len(rare_classes):,}\\n\"\n","            f\"   Registros antes: {len(df):,}\\n\"\n","            f\"   Registros despu√©s: {len(df_filtered):,}\"\n","        )\n","\n","        if len(df_filtered) == 0:\n","            raise ValueError(\n","                f\"‚ùå No quedan registros despu√©s de filtrar clases raras\\n\"\n","                f\"   Considera reducir MIN_SAMPLES_PER_CLASS\"\n","            )\n","\n","        return df_filtered\n","\n","    def create_label_mapping(self, df):\n","        \"\"\"\n","        Crea mapeo de etiquetas a √≠ndices\n","\n","        Args:\n","            df: DataFrame\n","\n","        Returns:\n","            tuple: (df_with_labels, label2id, id2label)\n","        \"\"\"\n","        self.logger.info(\"Creando mapeo de etiquetas...\")\n","\n","        # Obtener clases √∫nicas ordenadas\n","        unique_labels = sorted(df[self.config.TARGET_COLUMN].unique())\n","\n","        # Crear mapeos\n","        label2id = {label: idx for idx, label in enumerate(unique_labels)}\n","        id2label = {idx: label for label, idx in label2id.items()}\n","\n","        # Agregar columna de √≠ndices num√©ricos\n","        df['label_id'] = df[self.config.TARGET_COLUMN].map(label2id)\n","\n","        # Verificar que no hay nulos (no deber√≠a pasar)\n","        if df['label_id'].isna().any():\n","            raise ValueError(\"‚ùå Error en el mapeo de etiquetas\")\n","\n","        self.logger.info(\n","            f\"‚úÖ Mapeo creado: {len(label2id)} clases (√≠ndices 0-{len(label2id)-1})\"\n","        )\n","\n","        # Mostrar distribuci√≥n de clases\n","        class_dist = df[self.config.TARGET_COLUMN].value_counts()\n","        self.logger.info(\n","            f\"   Clase m√°s frecuente: {class_dist.index[0]} ({class_dist.iloc[0]:,} muestras)\\n\"\n","            f\"   Clase menos frecuente: {class_dist.index[-1]} ({class_dist.iloc[-1]:,} muestras)\\n\"\n","            f\"   Promedio por clase: {class_dist.mean():.1f}\"\n","        )\n","\n","        return df, label2id, id2label\n","\n","    def split_data(self, df):\n","        \"\"\"\n","        Divide datos en train, validation y test con estratificaci√≥n\n","\n","        Args:\n","            df: DataFrame\n","\n","        Returns:\n","            tuple: (train_df, val_df, test_df)\n","        \"\"\"\n","        self.logger.info(\"Dividiendo datos...\")\n","\n","        try:\n","            # Primero separar test\n","            train_val, test = train_test_split(\n","                df,\n","                test_size=self.config.TEST_SIZE,\n","                random_state=self.config.RANDOM_STATE,\n","                stratify=df['label_id']\n","            )\n","\n","            # Luego separar train y validation\n","            val_size_adjusted = self.config.VAL_SIZE / (1 - self.config.TEST_SIZE)\n","            train, val = train_test_split(\n","                train_val,\n","                test_size=val_size_adjusted,\n","                random_state=self.config.RANDOM_STATE,\n","                stratify=train_val['label_id']\n","            )\n","\n","            self.logger.info(\n","                f\"‚úÖ Divisi√≥n completada:\\n\"\n","                f\"   Train: {len(train):,} ({len(train)/len(df)*100:.1f}%)\\n\"\n","                f\"   Validation: {len(val):,} ({len(val)/len(df)*100:.1f}%)\\n\"\n","                f\"   Test: {len(test):,} ({len(test)/len(df)*100:.1f}%)\"\n","            )\n","\n","            return train, val, test\n","\n","        except ValueError as e:\n","            self.logger.error(\n","                f\"‚ùå Error al dividir datos: {str(e)}\\n\"\n","                f\"   Puede ser que algunas clases tengan muy pocas muestras\\n\"\n","                f\"   Considera aumentar MIN_SAMPLES_PER_CLASS\"\n","            )\n","            raise\n","\n","\n","# ============================================================================\n","# EJECUTAR CARGA DE DATOS\n","# ============================================================================\n","\n","print(\"\\n\" + \"=\"*80)\n","print(\"üìÇ CARGANDO Y PREPARANDO DATOS\")\n","print(\"=\"*80 + \"\\n\")\n","\n","try:\n","    # Inicializar cargador\n","    data_loader = DataLoader(config)\n","\n","    # Cargar datos\n","    df_raw = data_loader.load_data()\n","\n","    # Validar estructura\n","    data_loader.validate_data(df_raw)\n","\n","    # Filtrar registros v√°lidos\n","    df_valid = data_loader.filter_valid_records(df_raw)\n","\n","    # Filtrar clases raras\n","    df_filtered = data_loader.filter_rare_classes(df_valid)\n","\n","    # Crear mapeo de etiquetas\n","    df_final, label2id, id2label = data_loader.create_label_mapping(df_filtered)\n","\n","    # Dividir datos\n","    train_df, val_df, test_df = data_loader.split_data(df_final)\n","\n","    print(\"\\n\" + \"=\"*80)\n","    print(\"‚úÖ DATOS PREPARADOS EXITOSAMENTE\")\n","    print(\"=\"*80 + \"\\n\")\n","\n","    # Guardar informaci√≥n de las clases\n","    class_info = {\n","        'num_classes': len(label2id),\n","        'label2id': label2id,\n","        'id2label': id2label,\n","        'class_distribution': df_final[config.TARGET_COLUMN].value_counts().to_dict()\n","    }\n","\n","    with open(os.path.join(config.OUTPUT_DIR, 'class_info.json'), 'w', encoding='utf-8') as f:\n","        json.dump(class_info, f, indent=2, ensure_ascii=False)\n","\n","except Exception as e:\n","    print(\"\\n\" + \"=\"*80)\n","    print(\"‚ùå ERROR EN LA CARGA DE DATOS\")\n","    print(\"=\"*80)\n","    print(f\"\\n{str(e)}\\n\")\n","    print(\"Por favor, revisa:\")\n","    print(\"1. La ruta del archivo en ModelConfig.DATA_PATH\")\n","    print(\"2. Los nombres de columnas en TEXT_COLUMN y TARGET_COLUMN\")\n","    print(\"3. La calidad de tus datos (nulos, vac√≠os, etc.)\")\n","    print(\"\\n\" + \"=\"*80 + \"\\n\")\n","    raise\n"],"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","================================================================================\n","üìÇ CARGANDO Y PREPARANDO DATOS\n","================================================================================\n","\n","\n","================================================================================\n","‚úÖ DATOS PREPARADOS EXITOSAMENTE\n","================================================================================\n","\n"]}],"id":"qfG0DkcRIKbt"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":576,"referenced_widgets":["911ac04675ab4199852695fa05f00797","7862035c21a84927b8028392fc13a589","be38dc7bd5694b21a8527d36cf406648","c7091898b28344febdfe2ec9ace23106","0375010933204f9b8e406e61756ec5be","f525472bdbf648ae9df1e7f981dc2ec3","b000138d29134636a32198a2ea337c80","ac5b07d12bb24954a4e5c2236be880b1","e72e57d1493744588eaae99734c2d1e6","3018cb1086c04aabb1fa4abfb3162075","c534251e33b742d5ab73ef2795219e2c","9b86774e14cf4d2ea10e2931f39c70b6","f78c692fc732426c9b38ef9d8f43fc60","885eee9420f04e0bbc9259fc6a2eff43","7a99f623dd3b473c8deaa277df7221ba","6b85658cf90b4cb7ae5b128593a30b9d","9522c40242b44d0fad48f841eb113fc3","c5daef87f9314a188d9a331bb3c5359f","1dda9ab1ff6e4107a04eda07c78961fe","2bfa143afa7444c5986d8edcc7e1edca","cd0998bfe8fb43ecb0dcd1aca389f316","07e416cd8ffa48ec9d037657830ea11a","f60333e117eb439c9fba97908f0ee718","c524e6bff6c34d0b9ec97847bbf9f087","85bdafe751304a0d9ee13861534cb03e","fe20159971d2412dbc32fcf0db3f78d3","fc9994da0115411892022b617076de1e","778b74759d874d578af4f7972c75764b","5c8e625ec02c49dcb69642e4f1b7f112","a4d6d91c27264442b96543ba669d5dc7","a4d66b6debc345c999fa02e7b37d2fc6","8c825ff3358749fea7f7bfb6a754a44b","dba98dfc296b44389de6e24df0443522","f99a755e0bb047bb923135b1a9134ea7","8893b1bd0565466aa20ca63d8c89f1c0","75911875344a46ebb004d97fa60b4952","64b1be07b65347f2802b5ba9683a90ac","05e68c7cbf85497491201fadcc802a84","9c9ed7435beb41ed8e886f3ea9e1c206","4e2552fae4954a2e852bc791b9ac24bf","009f4156efc140228cf5856b907addd6","6b7c3c8561c44ecb928c9b072e91de56","f991153bf87b49658c8de171335c50e9","1b079b42eaf34918bc01be5cfcdbc3f6","68cef520e72f44499cd46c077b7433de","8a9ef415eb774e6493ae4c6777b0716d","5ca5bfa4b77d4957b86c283d45f2207f","c2f1d9c6e95f4174ad8527799d6bcf77","29e37dc9d30a4461b93f46d3707bc478","ceed5f8a67e34875b732a85f66e1ff0d","67be2b89f2e24a90ab39b73c8710caa2","dc5e684ecb1a4cb4b943a955e0094b55","647e1690452a44ecb5c4034d8ce16521","7f4bd80f44694ea0ae4d16e601b7f7cb","aa12dfb99c5a4702847eafa65d66b25d"]},"id":"K4LnQZmXIKbv","executionInfo":{"status":"ok","timestamp":1762988201037,"user_tz":300,"elapsed":3285,"user":{"displayName":"BRAYAN POMA HUAMAN","userId":"12837018889427630165"}},"outputId":"84c427c0-6d8f-4d18-e888-b46a70afa34d"},"source":["# ============================================================================\n","# üî§ DATASET Y TOKENIZACI√ìN\n","# ============================================================================\n","\n","class TextClassificationDataset(Dataset):\n","    \"\"\"\n","    Dataset personalizado para clasificaci√≥n de texto\n","    Compatible con cualquier modelo de Hugging Face\n","    \"\"\"\n","\n","    def __init__(self, texts, labels, tokenizer, max_length):\n","        \"\"\"\n","        Args:\n","            texts: Lista de textos\n","            labels: Lista de etiquetas (√≠ndices num√©ricos)\n","            tokenizer: Tokenizer de Hugging Face\n","            max_length: Longitud m√°xima de tokens\n","        \"\"\"\n","        self.texts = texts\n","        self.labels = labels\n","        self.tokenizer = tokenizer\n","        self.max_length = max_length\n","\n","    def __len__(self):\n","        return len(self.texts)\n","\n","    def __getitem__(self, idx):\n","        \"\"\"\n","        Obtiene un ejemplo tokenizado\n","\n","        Returns:\n","            dict: Diccionario con input_ids, attention_mask y labels\n","        \"\"\"\n","        text = str(self.texts[idx])\n","        label = int(self.labels[idx])\n","\n","        # Tokenizar\n","        encoding = self.tokenizer(\n","            text,\n","            max_length=self.max_length,\n","            padding='max_length',\n","            truncation=True,\n","            return_tensors='pt'\n","        )\n","\n","        return {\n","            'input_ids': encoding['input_ids'].flatten(),\n","            'attention_mask': encoding['attention_mask'].flatten(),\n","            'labels': torch.tensor(label, dtype=torch.long)\n","        }\n","\n","\n","# ============================================================================\n","# INICIALIZAR TOKENIZER Y DATASETS\n","# ============================================================================\n","\n","print(\"\\n\" + \"=\"*80)\n","print(\"üî§ INICIALIZANDO TOKENIZER Y DATASETS\")\n","print(\"=\"*80 + \"\\n\")\n","\n","try:\n","    # Cargar tokenizer\n","    config.logger.info(f\"Cargando tokenizer: {config.MODEL_NAME}\")\n","    tokenizer = AutoTokenizer.from_pretrained(config.MODEL_NAME)\n","\n","    print(f\"‚úÖ Tokenizer cargado: {config.MODEL_NAME}\")\n","    print(f\"   Vocabulario: {len(tokenizer):,} tokens\")\n","    print(f\"   Tipo: {tokenizer.__class__.__name__}\")\n","\n","    # Crear datasets\n","    config.logger.info(\"Creando datasets...\")\n","\n","    train_dataset = TextClassificationDataset(\n","        texts=train_df[config.TEXT_COLUMN].tolist(),\n","        labels=train_df['label_id'].tolist(),\n","        tokenizer=tokenizer,\n","        max_length=config.MAX_LENGTH\n","    )\n","\n","    val_dataset = TextClassificationDataset(\n","        texts=val_df[config.TEXT_COLUMN].tolist(),\n","        labels=val_df['label_id'].tolist(),\n","        tokenizer=tokenizer,\n","        max_length=config.MAX_LENGTH\n","    )\n","\n","    test_dataset = TextClassificationDataset(\n","        texts=test_df[config.TEXT_COLUMN].tolist(),\n","        labels=test_df['label_id'].tolist(),\n","        tokenizer=tokenizer,\n","        max_length=config.MAX_LENGTH\n","    )\n","\n","    print(f\"\\n‚úÖ Datasets creados:\")\n","    print(f\"   Train: {len(train_dataset):,} ejemplos\")\n","    print(f\"   Validation: {len(val_dataset):,} ejemplos\")\n","    print(f\"   Test: {len(test_dataset):,} ejemplos\")\n","\n","    # Verificar un ejemplo\n","    sample = train_dataset[0]\n","    print(f\"\\nüìù Ejemplo de muestra tokenizada:\")\n","    print(f\"   Input IDs shape: {sample['input_ids'].shape}\")\n","    print(f\"   Attention mask shape: {sample['attention_mask'].shape}\")\n","    print(f\"   Label: {sample['labels'].item()}\")\n","\n","    print(\"\\n\" + \"=\"*80)\n","    print(\"‚úÖ TOKENIZACI√ìN COMPLETADA\")\n","    print(\"=\"*80 + \"\\n\")\n","\n","except Exception as e:\n","    print(\"\\n\" + \"=\"*80)\n","    print(\"‚ùå ERROR EN LA TOKENIZACI√ìN\")\n","    print(\"=\"*80)\n","    print(f\"\\n{str(e)}\\n\")\n","    print(\"Posibles causas:\")\n","    print(\"1. El modelo no est√° disponible (verifica MODEL_NAME)\")\n","    print(\"2. No hay conexi√≥n a internet para descargar el tokenizer\")\n","    print(\"3. Problema con los datos de entrada\")\n","    print(\"\\n\" + \"=\"*80 + \"\\n\")\n","    raise\n"],"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","================================================================================\n","üî§ INICIALIZANDO TOKENIZER Y DATASETS\n","================================================================================\n","\n"]},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json: 0.00B [00:00, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"911ac04675ab4199852695fa05f00797"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["vocab.json: 0.00B [00:00, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9b86774e14cf4d2ea10e2931f39c70b6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["merges.txt: 0.00B [00:00, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f60333e117eb439c9fba97908f0ee718"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json: 0.00B [00:00, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f99a755e0bb047bb923135b1a9134ea7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["special_tokens_map.json:   0%|          | 0.00/772 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"68cef520e72f44499cd46c077b7433de"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["‚úÖ Tokenizer cargado: bertin-project/bertin-roberta-base-spanish\n","   Vocabulario: 50,262 tokens\n","   Tipo: RobertaTokenizerFast\n","\n","‚úÖ Datasets creados:\n","   Train: 220,937 ejemplos\n","   Validation: 47,344 ejemplos\n","   Test: 47,344 ejemplos\n","\n","üìù Ejemplo de muestra tokenizada:\n","   Input IDs shape: torch.Size([128])\n","   Attention mask shape: torch.Size([128])\n","   Label: 356\n","\n","================================================================================\n","‚úÖ TOKENIZACI√ìN COMPLETADA\n","================================================================================\n","\n"]}],"id":"K4LnQZmXIKbv"},{"cell_type":"code","metadata":{"id":"EcEm9PKOIKbw","executionInfo":{"status":"ok","timestamp":1762988201114,"user_tz":300,"elapsed":74,"user":{"displayName":"BRAYAN POMA HUAMAN","userId":"12837018889427630165"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"9dd32ffb-2c6d-47d3-94fb-e8c106349e3b"},"source":["# ============================================================================\n","# üìä M√âTRICAS DETALLADAS\n","# ============================================================================\n","\n","def compute_detailed_metrics(eval_pred):\n","    \"\"\"\n","    Calcula m√©tricas detalladas: Accuracy, Precision, Recall, F1\n","    Con variantes: macro, micro y weighted\n","\n","    Args:\n","        eval_pred: Predicciones del modelo (predictions, label_ids)\n","\n","    Returns:\n","        dict: Diccionario con todas las m√©tricas\n","    \"\"\"\n","    predictions, labels = eval_pred\n","\n","    # Obtener predicciones (argmax si son logits)\n","    if predictions.ndim > 1:\n","        preds = np.argmax(predictions, axis=1)\n","    else:\n","        preds = predictions\n","\n","    # Accuracy\n","    accuracy = accuracy_score(labels, preds)\n","\n","    # Precision, Recall, F1 con diferentes promedios\n","    # Macro: promedio sin ponderar (todas las clases tienen el mismo peso)\n","    precision_macro, recall_macro, f1_macro, _ = precision_recall_fscore_support(\n","        labels, preds, average='macro', zero_division=0\n","    )\n","\n","    # Micro: agregado global (considera todas las muestras por igual)\n","    precision_micro, recall_micro, f1_micro, _ = precision_recall_fscore_support(\n","        labels, preds, average='micro', zero_division=0\n","    )\n","\n","    # Weighted: promedio ponderado por soporte de cada clase\n","    precision_weighted, recall_weighted, f1_weighted, _ = precision_recall_fscore_support(\n","        labels, preds, average='weighted', zero_division=0\n","    )\n","\n","    return {\n","        # Accuracy (solo una versi√≥n)\n","        'accuracy': accuracy,\n","\n","        # F1 Score\n","        'f1_macro': f1_macro,\n","        'f1_micro': f1_micro,\n","        'f1_weighted': f1_weighted,\n","\n","        # Precision\n","        'precision_macro': precision_macro,\n","        'precision_micro': precision_micro,\n","        'precision_weighted': precision_weighted,\n","\n","        # Recall\n","        'recall_macro': recall_macro,\n","        'recall_micro': recall_micro,\n","        'recall_weighted': recall_weighted,\n","    }\n","\n","\n","\n","def display_metrics(metrics, title=\"M√©tricas\"):\n","    \"\"\"Muestra las m√©tricas de forma organizada\"\"\"\n","    print(\"\\n\" + \"=\"*80)\n","    print(f\"üìä {title.upper()}\")\n","    print(\"=\"*80 + \"\\n\")\n","\n","    # Mostrar Loss si existe\n","    loss = (\n","        metrics.get('test_loss') or\n","        metrics.get('eval_loss') or\n","        metrics.get('loss', None)\n","    )\n","    if loss is not None:\n","        print(f\"üí• LOSS: {loss:.4f}\")\n","\n","    # Accuracy\n","    acc = (\n","        metrics.get('test_accuracy') or\n","        metrics.get('eval_accuracy') or\n","        metrics.get('accuracy', 0)\n","    )\n","    print(f\"üéØ ACCURACY: {acc:.4f}\")\n","    print(\"\\n\" + \"-\"*80)\n","\n","    # Tabla\n","    print(f\"\\n{'M√©trica':<20} {'Macro':>12} {'Micro':>12} {'Weighted':>12}\")\n","    print(\"-\"*60)\n","\n","    def get_m(name):\n","        return (\n","            metrics.get(f'test_{name}') or\n","            metrics.get(f'eval_{name}') or\n","            metrics.get(name, 0)\n","        )\n","\n","    print(f\"{'F1 Score':<20} {get_m('f1_macro'):>12.4f} {get_m('f1_micro'):>12.4f} {get_m('f1_weighted'):>12.4f}\")\n","    print(f\"{'Precision':<20} {get_m('precision_macro'):>12.4f} {get_m('precision_micro'):>12.4f} {get_m('precision_weighted'):>12.4f}\")\n","    print(f\"{'Recall':<20} {get_m('recall_macro'):>12.4f} {get_m('recall_micro'):>12.4f} {get_m('recall_weighted'):>12.4f}\")\n","\n","    print(\"\\n\" + \"=\"*80 + \"\\n\")\n","\n","\n","print(\"‚úÖ Funciones de m√©tricas cargadas (con loss incluido)\")\n"],"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["‚úÖ Funciones de m√©tricas cargadas (con loss incluido)\n"]}],"id":"EcEm9PKOIKbw"},{"cell_type":"code","metadata":{"id":"qXtQxEM-IKbw","executionInfo":{"status":"ok","timestamp":1762988208319,"user_tz":300,"elapsed":7196,"user":{"displayName":"BRAYAN POMA HUAMAN","userId":"12837018889427630165"}},"colab":{"base_uri":"https://localhost:8080/","height":431,"referenced_widgets":["d563d61a3a4a4ea2a5de306ab9bb8a9f","14b2252e80864a41b4fc2fe293e67353","cc22a9432c0149eb8a35fe18387b46ce","a419f90b2e444163be201a4e7f66b0f4","4de92f8077b74aca857936188a2d821c","dc215a291b5c42c5b69ad9e19f89168c","a4e1b0abdee645e5b27b9cbf9b2bdc37","7288499473bc4b10bc0ef129d698fb78","f321cfb4233b4ceb90fe6ceb92b5ca94","8cf50382e8c342aaa773bf34c6abf26e","24bd48289b284d18ae3ccc1456922a1c","774663d1fa114882a10c377949dbdea3","3fb9e84936204c338c02cbb00aadbb31","5b10469357c04250bdce90d4e256e06b","e7fb913d2c794d1b99661496fd324150","f381dd7ae35f4341857935ec22a47749","03c85293c0af4f45bf202b83b6ee4417","96f859c725de47088e71d93ef7752659","a38dd13e616c428eae0474d367226548","266f400b91ca47a7860ca4d1c6d048a0","42b63e4bc9164db18e42e285b7b81514","70e1b4736a674773b8716e04acd17524"]},"outputId":"52659ad0-cb7a-4cc6-908d-971809ca220f"},"source":["# ============================================================================\n","# ü§ñ INICIALIZACI√ìN DEL MODELO\n","# ============================================================================\n","\n","print(\"\\n\" + \"=\"*80)\n","print(\"ü§ñ INICIALIZANDO MODELO\")\n","print(\"=\"*80 + \"\\n\")\n","\n","try:\n","    config.logger.info(f\"Cargando modelo: {config.MODEL_NAME}\")\n","\n","    # Cargar modelo\n","    model = AutoModelForSequenceClassification.from_pretrained(\n","        config.MODEL_NAME,\n","        num_labels=len(label2id),\n","        id2label=id2label,\n","        label2id=label2id,\n","        problem_type=\"single_label_classification\"\n","    )\n","\n","    # Mover a GPU si est√° disponible\n","    model.to(config.DEVICE)\n","\n","    # Informaci√≥n del modelo\n","    num_params = sum(p.numel() for p in model.parameters())\n","    num_trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n","\n","    print(f\"‚úÖ Modelo cargado: {config.MODEL_NAME}\")\n","    print(f\"   Tipo: {model.__class__.__name__}\")\n","    print(f\"   N√∫mero de clases: {len(label2id)}\")\n","    print(f\"   Par√°metros totales: {num_params:,}\")\n","    print(f\"   Par√°metros entrenables: {num_trainable:,}\")\n","    print(f\"   Dispositivo: {config.DEVICE}\")\n","\n","    if torch.cuda.is_available():\n","        print(f\"   Memoria GPU asignada: {torch.cuda.memory_allocated(0) / 1e9:.2f} GB\")\n","\n","    config.logger.info(f\"Modelo inicializado con {num_params:,} par√°metros\")\n","\n","    print(\"\\n\" + \"=\"*80)\n","    print(\"‚úÖ MODELO LISTO PARA ENTRENAMIENTO\")\n","    print(\"=\"*80 + \"\\n\")\n","\n","except Exception as e:\n","    print(\"\\n\" + \"=\"*80)\n","    print(\"‚ùå ERROR AL CARGAR EL MODELO\")\n","    print(\"=\"*80)\n","    print(f\"\\n{str(e)}\\n\")\n","    print(\"Posibles causas:\")\n","    print(\"1. El nombre del modelo es incorrecto\")\n","    print(\"2. No hay conexi√≥n a internet para descargar el modelo\")\n","    print(\"3. No hay suficiente memoria GPU/RAM\")\n","    print(\"4. Incompatibilidad de versiones de transformers\")\n","    print(\"\\nModelos v√°lidos:\")\n","    print(\"- FacebookAI/xlm-roberta-base\")\n","    print(\"- dccuchile/bert-base-spanish-wwm-cased\")\n","    print(\"\\n\" + \"=\"*80 + \"\\n\")\n","    raise\n"],"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","================================================================================\n","ü§ñ INICIALIZANDO MODELO\n","================================================================================\n","\n"]},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/674 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d563d61a3a4a4ea2a5de306ab9bb8a9f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"774663d1fa114882a10c377949dbdea3"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at bertin-project/bertin-roberta-base-spanish and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["‚úÖ Modelo cargado: bertin-project/bertin-roberta-base-spanish\n","   Tipo: RobertaForSequenceClassification\n","   N√∫mero de clases: 357\n","   Par√°metros totales: 124,917,861\n","   Par√°metros entrenables: 124,917,861\n","   Dispositivo: cuda\n","   Memoria GPU asignada: 0.50 GB\n","\n","================================================================================\n","‚úÖ MODELO LISTO PARA ENTRENAMIENTO\n","================================================================================\n","\n"]}],"id":"qXtQxEM-IKbw"},{"cell_type":"code","metadata":{"id":"W_6d3qt-IKbx","executionInfo":{"status":"ok","timestamp":1762988208384,"user_tz":300,"elapsed":62,"user":{"displayName":"BRAYAN POMA HUAMAN","userId":"12837018889427630165"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"13753c48-c5e6-4a6e-ee50-3af687718f7f"},"source":["# ============================================================================\n","# ‚öôÔ∏è  CONFIGURACI√ìN DEL ENTRENAMIENTO\n","# ============================================================================\n","\n","print(\"\\n\" + \"=\"*80)\n","print(\"‚öôÔ∏è  CONFIGURANDO ENTRENAMIENTO\")\n","print(\"=\"*80 + \"\\n\")\n","\n","# Configuraci√≥n de argumentos de entrenamiento\n","training_args = TrainingArguments(\n","    # Directorios\n","    output_dir=config.CHECKPOINT_DIR,\n","    logging_dir=os.path.join(config.OUTPUT_DIR, 'logs'),\n","\n","    # Hiperpar√°metros\n","    learning_rate=config.LEARNING_RATE,\n","    per_device_train_batch_size=config.BATCH_SIZE,\n","    per_device_eval_batch_size=config.BATCH_SIZE,\n","    num_train_epochs=config.NUM_EPOCHS,\n","    warmup_steps=config.WARMUP_STEPS,\n","    weight_decay=config.WEIGHT_DECAY,\n","\n","    # Evaluaci√≥n y guardado\n","    eval_strategy=\"epoch\",\n","    save_strategy=\"epoch\",\n","    load_best_model_at_end=True,\n","    metric_for_best_model=\"f1_weighted\",  # Usar F1 weighted como m√©trica principal\n","    greater_is_better=True,\n","\n","    # Logging\n","    logging_steps=100,\n","    logging_strategy=\"steps\",\n","\n","    # Optimizaci√≥n\n","    fp16=torch.cuda.is_available(),  # Precisi√≥n mixta si hay GPU\n","    gradient_accumulation_steps=1,\n","\n","    # Otros\n","    seed=config.RANDOM_STATE,\n","    report_to=\"none\",  # Desactivar reportes externos\n","    disable_tqdm=False,  # Mantener barra de progreso\n",")\n","\n","# Inicializar Trainer\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=train_dataset,\n","    eval_dataset=val_dataset,\n","    compute_metrics=compute_detailed_metrics,\n","    callbacks=[\n","        EarlyStoppingCallback(\n","            early_stopping_patience=config.EARLY_STOPPING_PATIENCE\n","        )\n","    ]\n",")\n","\n","print(\"‚úÖ Configuraci√≥n de entrenamiento:\")\n","print(f\"   Learning rate: {config.LEARNING_RATE}\")\n","print(f\"   Batch size: {config.BATCH_SIZE}\")\n","print(f\"   Epochs: {config.NUM_EPOCHS}\")\n","print(f\"   Warmup steps: {config.WARMUP_STEPS}\")\n","print(f\"   Early stopping: {config.EARLY_STOPPING_PATIENCE} epochs\")\n","print(f\"   FP16 (mixed precision): {training_args.fp16}\")\n","print(f\"   M√©trica principal: f1_weighted\")\n","\n","print(\"\\n\" + \"=\"*80)\n","print(\"‚úÖ TRAINER CONFIGURADO Y LISTO\")\n","print(\"=\"*80 + \"\\n\")\n","\n","config.logger.info(\"Trainer configurado correctamente\")\n"],"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","================================================================================\n","‚öôÔ∏è  CONFIGURANDO ENTRENAMIENTO\n","================================================================================\n","\n","‚úÖ Configuraci√≥n de entrenamiento:\n","   Learning rate: 2e-05\n","   Batch size: 16\n","   Epochs: 3\n","   Warmup steps: 500\n","   Early stopping: 3 epochs\n","   FP16 (mixed precision): True\n","   M√©trica principal: f1_weighted\n","\n","================================================================================\n","‚úÖ TRAINER CONFIGURADO Y LISTO\n","================================================================================\n","\n"]}],"id":"W_6d3qt-IKbx"},{"cell_type":"code","metadata":{"id":"Xk-wOW2lIKbx","executionInfo":{"status":"ok","timestamp":1762993678842,"user_tz":300,"elapsed":664911,"user":{"displayName":"BRAYAN POMA HUAMAN","userId":"12837018889427630165"}},"colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"e6b5660a-ef31-4669-f812-5f8a9d95a68b"},"source":["# ============================================================================\n","# üöÄ ENTRENAMIENTO DEL MODELO\n","# ============================================================================\n","\n","print(\"\\n\" + \"=\"*80)\n","print(\"üöÄ INICIANDO ENTRENAMIENTO\")\n","print(\"=\"*80)\n","print(f\"\\nModelo: {config.MODEL_NAME}\")\n","print(f\"Datos de entrenamiento: {len(train_dataset):,} ejemplos\")\n","print(f\"Datos de validaci√≥n: {len(val_dataset):,} ejemplos\")\n","print(f\"\\nEsto puede tomar varios minutos/horas dependiendo de:\")\n","print(\"  - Tama√±o del dataset\")\n","print(\"  - N√∫mero de √©pocas\")\n","print(\"  - Hardware disponible (GPU/CPU)\")\n","print(\"\\n\" + \"=\"*80 + \"\\n\")\n","\n","try:\n","    # Registrar inicio\n","    start_time = datetime.now()\n","    config.logger.info(\"Iniciando entrenamiento...\")\n","\n","    # ENTRENAR\n","    train_result = trainer.train()\n","\n","    # Registrar finalizaci√≥n\n","    end_time = datetime.now()\n","    training_time = end_time - start_time\n","\n","    config.logger.info(f\"Entrenamiento completado en {training_time}\")\n","\n","    print(\"\\n\" + \"=\"*80)\n","    print(\"‚úÖ ENTRENAMIENTO COMPLETADO\")\n","    print(\"=\"*80)\n","    print(f\"\\nTiempo total: {training_time}\")\n","    print(f\"Mejor modelo guardado en: {config.CHECKPOINT_DIR}\")\n","\n","    # Mostrar m√©tricas finales de entrenamiento\n","    print(f\"\\nüìä M√©tricas finales de entrenamiento:\")\n","    print(f\"   Training loss: {train_result.training_loss:.4f}\")\n","\n","    # Evaluar en validation set\n","    print(\"\\n\" + \"-\"*80)\n","    print(\"üìä Evaluando en conjunto de validaci√≥n...\")\n","    val_metrics = trainer.evaluate()\n","    display_metrics(val_metrics, \"M√©tricas de Validaci√≥n\")\n","\n","    print(\"=\"*80 + \"\\n\")\n","\n","except KeyboardInterrupt:\n","    print(\"\\n\" + \"=\"*80)\n","    print(\"‚ö†Ô∏è  ENTRENAMIENTO INTERRUMPIDO POR EL USUARIO\")\n","    print(\"=\"*80)\n","    print(\"\\nEl modelo puede haber sido parcialmente entrenado.\")\n","    print(\"Los checkpoints guardados est√°n disponibles en:\")\n","    print(f\"  {config.CHECKPOINT_DIR}\")\n","    print(\"\\n\" + \"=\"*80 + \"\\n\")\n","    raise\n","\n","except Exception as e:\n","    print(\"\\n\" + \"=\"*80)\n","    print(\"‚ùå ERROR DURANTE EL ENTRENAMIENTO\")\n","    print(\"=\"*80)\n","    print(f\"\\n{str(e)}\\n\")\n","    print(\"Posibles causas:\")\n","    print(\"1. Memoria insuficiente (GPU/RAM)\")\n","    print(\"   Soluci√≥n: Reduce BATCH_SIZE en ModelConfig\")\n","    print(\"2. Datos corruptos o formato incorrecto\")\n","    print(\"3. Incompatibilidad de versiones\")\n","    print(\"\\nRevisa el archivo de log para m√°s detalles:\")\n","    print(f\"  {os.path.join(config.OUTPUT_DIR, 'training_*.log')}\")\n","    print(\"\\n\" + \"=\"*80 + \"\\n\")\n","    config.logger.error(f\"Error en entrenamiento: {str(e)}\", exc_info=True)\n","    raise\n"],"execution_count":10,"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","================================================================================\n","üöÄ INICIANDO ENTRENAMIENTO\n","================================================================================\n","\n","Modelo: bertin-project/bertin-roberta-base-spanish\n","Datos de entrenamiento: 220,937 ejemplos\n","Datos de validaci√≥n: 47,344 ejemplos\n","\n","Esto puede tomar varios minutos/horas dependiendo de:\n","  - Tama√±o del dataset\n","  - N√∫mero de √©pocas\n","  - Hardware disponible (GPU/CPU)\n","\n","================================================================================\n","\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='37577' max='41427' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [37577/41427 1:20:01 < 08:12, 7.83 it/s, Epoch 2.72/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1 Macro</th>\n","      <th>F1 Micro</th>\n","      <th>F1 Weighted</th>\n","      <th>Precision Macro</th>\n","      <th>Precision Micro</th>\n","      <th>Precision Weighted</th>\n","      <th>Recall Macro</th>\n","      <th>Recall Micro</th>\n","      <th>Recall Weighted</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.305000</td>\n","      <td>0.330462</td>\n","      <td>0.928798</td>\n","      <td>0.497080</td>\n","      <td>0.928798</td>\n","      <td>0.921912</td>\n","      <td>0.515937</td>\n","      <td>0.928798</td>\n","      <td>0.919186</td>\n","      <td>0.504121</td>\n","      <td>0.928798</td>\n","      <td>0.928798</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.258600</td>\n","      <td>0.287590</td>\n","      <td>0.936127</td>\n","      <td>0.584992</td>\n","      <td>0.936127</td>\n","      <td>0.932253</td>\n","      <td>0.603218</td>\n","      <td>0.936127</td>\n","      <td>0.931324</td>\n","      <td>0.590769</td>\n","      <td>0.936127</td>\n","      <td>0.936127</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='41427' max='41427' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [41427/41427 1:29:31, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1 Macro</th>\n","      <th>F1 Micro</th>\n","      <th>F1 Weighted</th>\n","      <th>Precision Macro</th>\n","      <th>Precision Micro</th>\n","      <th>Precision Weighted</th>\n","      <th>Recall Macro</th>\n","      <th>Recall Micro</th>\n","      <th>Recall Weighted</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.305000</td>\n","      <td>0.330462</td>\n","      <td>0.928798</td>\n","      <td>0.497080</td>\n","      <td>0.928798</td>\n","      <td>0.921912</td>\n","      <td>0.515937</td>\n","      <td>0.928798</td>\n","      <td>0.919186</td>\n","      <td>0.504121</td>\n","      <td>0.928798</td>\n","      <td>0.928798</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.258600</td>\n","      <td>0.287590</td>\n","      <td>0.936127</td>\n","      <td>0.584992</td>\n","      <td>0.936127</td>\n","      <td>0.932253</td>\n","      <td>0.603218</td>\n","      <td>0.936127</td>\n","      <td>0.931324</td>\n","      <td>0.590769</td>\n","      <td>0.936127</td>\n","      <td>0.936127</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.187200</td>\n","      <td>0.286277</td>\n","      <td>0.939654</td>\n","      <td>0.617387</td>\n","      <td>0.939654</td>\n","      <td>0.936650</td>\n","      <td>0.644770</td>\n","      <td>0.939654</td>\n","      <td>0.935782</td>\n","      <td>0.618170</td>\n","      <td>0.939654</td>\n","      <td>0.939654</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","================================================================================\n","‚úÖ ENTRENAMIENTO COMPLETADO\n","================================================================================\n","\n","Tiempo total: 1:29:33.782914\n","Mejor modelo guardado en: /content/drive/MyDrive/Colab Notebooks/PI_PEU/Robertabne/bertin-roberta-base-spanish_20251112_225626/checkpoints\n","\n","üìä M√©tricas finales de entrenamiento:\n","   Training loss: 0.3598\n","\n","--------------------------------------------------------------------------------\n","üìä Evaluando en conjunto de validaci√≥n...\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='2959' max='2959' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2959/2959 01:36]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","================================================================================\n","üìä M√âTRICAS DE VALIDACI√ìN\n","================================================================================\n","\n","üí• LOSS: 0.2863\n","üéØ ACCURACY: 0.9397\n","\n","--------------------------------------------------------------------------------\n","\n","M√©trica                     Macro        Micro     Weighted\n","------------------------------------------------------------\n","F1 Score                   0.6174       0.9397       0.9367\n","Precision                  0.6448       0.9397       0.9358\n","Recall                     0.6182       0.9397       0.9397\n","\n","================================================================================\n","\n","================================================================================\n","\n"]}],"id":"Xk-wOW2lIKbx"},{"cell_type":"code","metadata":{"id":"IzyrUTD6IKby","executionInfo":{"status":"ok","timestamp":1762993777607,"user_tz":300,"elapsed":12619,"user":{"displayName":"BRAYAN POMA HUAMAN","userId":"12837018889427630165"}},"colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"2104b0f2-192b-407e-fd79-6be1faf21008"},"source":["# ============================================================================\n","# üß™ EVALUACI√ìN EN TEST SET\n","# ============================================================================\n","\n","print(\"\\n\" + \"=\"*80)\n","print(\"üß™ EVALUACI√ìN EN TEST SET\")\n","print(\"=\"*80 + \"\\n\")\n","\n","try:\n","    config.logger.info(\"Evaluando en test set...\")\n","\n","    # Obtener predicciones en test set\n","    test_predictions = trainer.predict(test_dataset)\n","\n","    # Extraer m√©tricas\n","    test_metrics = test_predictions.metrics\n","\n","    # Mostrar m√©tricas\n","    display_metrics(test_metrics, \"M√©tricas de Test (Evaluaci√≥n Final)\")\n","\n","    # Guardar m√©tricas en archivo\n","    metrics_file = os.path.join(config.OUTPUT_DIR, 'test_metrics.json')\n","    with open(metrics_file, 'w', encoding='utf-8') as f:\n","        json.dump(test_metrics, f, indent=2)\n","\n","    config.logger.info(f\"M√©tricas de test guardadas en: {metrics_file}\")\n","\n","    # ========================================================================\n","    # AN√ÅLISIS DETALLADO\n","    # ========================================================================\n","\n","    print(\"\\n\" + \"=\"*80)\n","    print(\"üìà AN√ÅLISIS DETALLADO\")\n","    print(\"=\"*80 + \"\\n\")\n","\n","    # Obtener predicciones y etiquetas verdaderas\n","    y_pred = np.argmax(test_predictions.predictions, axis=1)\n","    y_true = test_predictions.label_ids\n","\n","    # Reporte de clasificaci√≥n por clase\n","    print(\"üìä Reporte de Clasificaci√≥n por Clase:\\n\")\n","\n","    # Crear reporte con nombres de clases\n","    target_names = [id2label[i] for i in range(len(id2label))]\n","    class_report = classification_report(\n","        y_true,\n","        y_pred,\n","        target_names=target_names,\n","        zero_division=0,\n","        digits=4\n","    )\n","    print(class_report)\n","\n","    # Guardar reporte completo\n","    report_file = os.path.join(config.OUTPUT_DIR, 'classification_report.txt')\n","    with open(report_file, 'w', encoding='utf-8') as f:\n","        f.write(\"REPORTE DE CLASIFICACI√ìN - TEST SET\\n\")\n","        f.write(\"=\"*80 + \"\\n\\n\")\n","        f.write(f\"Modelo: {config.MODEL_NAME}\\n\")\n","        f.write(f\"Fecha: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n","        f.write(f\"Dataset: {config.DATA_PATH}\\n\")\n","        f.write(\"\\n\" + \"=\"*80 + \"\\n\\n\")\n","        f.write(class_report)\n","\n","    print(f\"\\n‚úÖ Reporte completo guardado en: {report_file}\")\n","\n","    # ========================================================================\n","    # AN√ÅLISIS DE ERRORES\n","    # ========================================================================\n","\n","    print(\"\\n\" + \"=\"*80)\n","    print(\"üîç AN√ÅLISIS DE ERRORES\")\n","    print(\"=\"*80 + \"\\n\")\n","\n","    # Identificar predicciones incorrectas\n","    incorrect_mask = y_pred != y_true\n","    num_incorrect = incorrect_mask.sum()\n","    error_rate = num_incorrect / len(y_true) * 100\n","\n","    print(f\"Total de predicciones: {len(y_true):,}\")\n","    print(f\"Predicciones correctas: {(~incorrect_mask).sum():,}\")\n","    print(f\"Predicciones incorrectas: {num_incorrect:,}\")\n","    print(f\"Tasa de error: {error_rate:.2f}%\")\n","\n","    # Crear DataFrame con errores\n","    errors_df = test_df[incorrect_mask].copy()\n","    errors_df['predicted_label'] = [id2label[pred] for pred in y_pred[incorrect_mask]]\n","    errors_df['true_label'] = [id2label[true] for true in y_true[incorrect_mask]]\n","    errors_df['predicted_id'] = y_pred[incorrect_mask]\n","    errors_df['true_id'] = y_true[incorrect_mask]\n","\n","    # Agregar probabilidades\n","    probs = torch.nn.functional.softmax(torch.tensor(test_predictions.predictions), dim=-1)\n","    max_probs = probs.max(dim=-1).values.numpy()\n","    errors_df['confidence'] = max_probs[incorrect_mask]\n","\n","    # Guardar an√°lisis de errores\n","    errors_file = os.path.join(config.OUTPUT_DIR, 'error_analysis.csv')\n","    errors_df.to_csv(errors_file, index=False, encoding='utf-8')\n","\n","    print(f\"\\n‚úÖ An√°lisis de errores guardado en: {errors_file}\")\n","\n","    # Mostrar clases con m√°s errores\n","    if len(errors_df) > 0:\n","        print(\"\\nüìä Top 10 clases con m√°s errores de predicci√≥n:\")\n","        error_by_class = errors_df['true_label'].value_counts().head(10)\n","        for idx, (clase, count) in enumerate(error_by_class.items(), 1):\n","            print(f\"   {idx}. {clase}: {count} errores\")\n","\n","    print(\"\\n\" + \"=\"*80 + \"\\n\")\n","\n","    config.logger.info(\"Evaluaci√≥n en test completada\")\n","\n","except Exception as e:\n","    print(\"\\n\" + \"=\"*80)\n","    print(\"‚ùå ERROR EN LA EVALUACI√ìN\")\n","    print(\"=\"*80)\n","    print(f\"\\n{str(e)}\\n\")\n","    config.logger.error(f\"Error en evaluaci√≥n: {str(e)}\", exc_info=True)\n","    raise\n"],"execution_count":11,"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","================================================================================\n","üß™ EVALUACI√ìN EN TEST SET\n","================================================================================\n","\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='5552' max='2959' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2959/2959 03:02]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","================================================================================\n","üìä M√âTRICAS DE TEST (EVALUACI√ìN FINAL)\n","================================================================================\n","\n","üí• LOSS: 0.2834\n","üéØ ACCURACY: 0.9402\n","\n","--------------------------------------------------------------------------------\n","\n","M√©trica                     Macro        Micro     Weighted\n","------------------------------------------------------------\n","F1 Score                   0.6157       0.9402       0.9371\n","Precision                  0.6416       0.9402       0.9366\n","Recall                     0.6217       0.9402       0.9402\n","\n","================================================================================\n","\n","\n","================================================================================\n","üìà AN√ÅLISIS DETALLADO\n","================================================================================\n","\n","üìä Reporte de Clasificaci√≥n por Clase:\n","\n","              precision    recall  f1-score   support\n","\n","        0111     1.0000    1.0000    1.0000         3\n","        0112     1.0000    0.5000    0.6667         2\n","        0120     1.0000    1.0000    1.0000         9\n","        0211     1.0000    1.0000    1.0000         9\n","        0212     0.7143    1.0000    0.8333         5\n","        0213     0.5000    0.5000    0.5000         2\n","        0220     1.0000    1.0000    1.0000       145\n","        0311     1.0000    1.0000    1.0000         6\n","        0312     1.0000    0.8750    0.9333         8\n","        0313     0.7500    0.7500    0.7500         4\n","        1111     0.7692    0.9091    0.8333        11\n","        1113     1.0000    0.6667    0.8000         3\n","        1114     0.6842    0.8966    0.7761        29\n","        1131     0.0000    0.0000    0.0000         2\n","        1133     0.3333    1.0000    0.5000         3\n","        1143     0.0000    0.0000    0.0000         1\n","        1166     0.0000    0.0000    0.0000         3\n","        1167     0.0000    0.0000    0.0000         1\n","        1169     0.0000    0.0000    0.0000         2\n","        1211     0.0000    0.0000    0.0000         2\n","        1221     0.6000    0.7500    0.6667         4\n","        1321     0.0000    0.0000    0.0000         2\n","        1323     0.0000    0.0000    0.0000         2\n","        1341     0.0000    0.0000    0.0000         2\n","        1345     0.9091    0.9859    0.9459        71\n","        1346     0.7500    1.0000    0.8571         3\n","        1422     0.2941    0.8333    0.4348         6\n","        1499     0.0000    0.0000    0.0000         2\n","        2113     0.0000    0.0000    0.0000         3\n","        2114     0.6923    1.0000    0.8182         9\n","        2120     0.0000    0.0000    0.0000         2\n","        2131     0.8667    0.8125    0.8387        16\n","        2132     0.8163    0.9524    0.8791        42\n","        2141     1.0000    0.7826    0.8780        23\n","        2142     0.9891    0.9579    0.9733        95\n","        2143     0.8000    0.7619    0.7805        21\n","        2144     0.7857    0.7333    0.7586        15\n","        2145     0.7273    1.0000    0.8421         8\n","        2146     0.9167    0.9167    0.9167        12\n","        2149     0.7857    0.7333    0.7586        15\n","        2151     0.8182    0.9000    0.8571        10\n","        2152     1.0000    0.9000    0.9474        10\n","        2161     0.6522    0.9375    0.7692        32\n","        2162     0.0000    0.0000    0.0000        15\n","        2163     1.0000    0.3750    0.5455         8\n","        2166     0.8108    0.9524    0.8759        63\n","        2211     0.9623    0.9273    0.9444        55\n","        2212     0.7222    0.8667    0.7879        45\n","        2221     0.8690    1.0000    0.9299       146\n","        2222     0.9783    0.9184    0.9474        49\n","        2240     1.0000    1.0000    1.0000        18\n","        2251     0.9444    0.9444    0.9444        54\n","        2252     0.8235    0.8235    0.8235        17\n","        2254     0.0000    0.0000    0.0000         5\n","        2255     0.6667    1.0000    0.8000         8\n","        2256     0.0000    0.0000    0.0000         1\n","        2257     1.0000    1.0000    1.0000         1\n","        2311     0.9701    0.9630    0.9665       135\n","        2312     0.7778    0.6364    0.7000        11\n","        2320     0.0000    0.0000    0.0000         5\n","        2330     0.9668    0.9793    0.9730       387\n","        2341     0.9900    0.9840    0.9870       501\n","        2342     0.9725    0.9672    0.9699       183\n","        2351     1.0000    0.2222    0.3636         9\n","        2352     0.8000    0.8000    0.8000         5\n","        2353     0.8333    0.7143    0.7692         7\n","        2359     0.7200    0.8244    0.7687       131\n","        2411     0.9012    0.9627    0.9309       161\n","        2412     1.0000    0.1250    0.2222         8\n","        2421     0.5870    0.3750    0.4576        72\n","        2422     0.0000    0.0000    0.0000        11\n","        2431     0.0000    0.0000    0.0000         4\n","        2432     0.7500    1.0000    0.8571         3\n","        2511     0.7288    0.8776    0.7963        49\n","        2512     0.0000    0.0000    0.0000         9\n","        2513     0.0000    0.0000    0.0000         3\n","        2521     0.0000    0.0000    0.0000         4\n","        2611     0.9822    0.9822    0.9822       169\n","        2619     0.7500    0.7241    0.7368        29\n","        2631     0.8333    0.9375    0.8824        16\n","        2632     0.8571    1.0000    0.9231         6\n","        2634     0.9825    0.9655    0.9739        58\n","        2635     0.9375    0.9375    0.9375        16\n","        2636     0.0000    0.0000    0.0000         2\n","        2641     0.0000    0.0000    0.0000         2\n","        2642     0.7059    0.7059    0.7059        17\n","        2643     0.0000    0.0000    0.0000         2\n","        2651     0.5556    0.5556    0.5556         9\n","        2656     0.0000    0.0000    0.0000         2\n","        3111     0.3333    0.1250    0.1818         8\n","        3112     0.7500    0.7969    0.7727        64\n","        3113     0.8902    0.8111    0.8488        90\n","        3114     0.7727    0.7391    0.7556        23\n","        3115     0.8806    0.8252    0.8520       143\n","        3117     1.0000    0.5000    0.6667         4\n","        3118     0.6800    0.9444    0.7907        18\n","        3119     0.0000    0.0000    0.0000         4\n","        3121     0.4737    0.9000    0.6207        10\n","        3122     0.5323    0.7857    0.6346        42\n","        3123     0.6579    0.8333    0.7353        30\n","        3124     0.6750    0.6429    0.6585       126\n","        3125     0.5000    0.1250    0.2000         8\n","        3126     0.0000    0.0000    0.0000         5\n","        3129     0.1765    0.1200    0.1429        25\n","        3131     0.0000    0.0000    0.0000         1\n","        3132     1.0000    0.1111    0.2000         9\n","        3141     1.0000    0.2000    0.3333         5\n","        3142     0.0000    0.0000    0.0000         9\n","        3143     0.0000    0.0000    0.0000         2\n","        3145     0.0000    0.0000    0.0000         2\n","        3149     0.0000    0.0000    0.0000        23\n","        3151     0.0000    0.0000    0.0000         2\n","        3152     0.8485    0.8750    0.8615        32\n","        3153     0.0000    0.0000    0.0000         1\n","        3211     0.6667    0.5000    0.5714         4\n","        3212     0.8108    1.0000    0.8955        30\n","        3213     0.9400    0.9216    0.9307        51\n","        3215     1.0000    0.2500    0.4000         4\n","        3221     0.9897    0.8977    0.9415       215\n","        3230     0.8750    0.9130    0.8936        23\n","        3240     0.5455    0.7500    0.6316         8\n","        3251     0.6667    0.7500    0.7059        16\n","        3253     0.0000    0.0000    0.0000         1\n","        3255     0.6154    1.0000    0.7619        24\n","        3256     0.5000    0.1667    0.2500         6\n","        3257     0.4694    0.6970    0.5610        33\n","        3258     1.0000    0.5000    0.6667         2\n","        3259     0.0000    0.0000    0.0000         4\n","        3313     0.8214    0.6765    0.7419        34\n","        3314     0.8801    0.9427    0.9103       506\n","        3315     0.5000    0.2500    0.3333         4\n","        3316     0.0000    0.0000    0.0000         2\n","        3317     0.5333    0.6667    0.5926        12\n","        3321     0.7619    1.0000    0.8649        16\n","        3322     0.8905    0.8714    0.8809       140\n","        3323     0.8333    0.8333    0.8333         6\n","        3331     0.7143    0.7143    0.7143         7\n","        3332     0.6667    0.5714    0.6154         7\n","        3334     0.8750    0.9545    0.9130        22\n","        3339     0.5455    0.4000    0.4615        15\n","        3341     1.0000    0.6667    0.8000         3\n","        3411     0.6923    0.6923    0.6923        39\n","        3412     0.0000    0.0000    0.0000         2\n","        3413     0.7500    1.0000    0.8571        15\n","        3421     0.9091    1.0000    0.9524        10\n","        3422     0.8718    0.9444    0.9067        36\n","        3423     0.0000    0.0000    0.0000         2\n","        3431     0.8421    0.8889    0.8649        18\n","        3432     1.0000    0.7778    0.8750         9\n","        3434     0.7143    0.7143    0.7143         7\n","        3439     0.8571    0.9836    0.9160        61\n","        3511     0.3250    0.4062    0.3611        32\n","        3512     0.0000    0.0000    0.0000        11\n","        3513     0.4524    0.5000    0.4750        38\n","        3514     0.5000    0.5000    0.5000         6\n","        3521     0.7692    0.7692    0.7692        26\n","        3522     0.0000    0.0000    0.0000         2\n","        3523     0.5455    0.8571    0.6667         7\n","        4110     0.9247    0.8927    0.9085       289\n","        4120     0.9840    1.0000    0.9919       184\n","        4131     0.8235    0.8235    0.8235        17\n","        4132     1.0000    0.9412    0.9697        34\n","        4211     0.6905    0.6744    0.6824        43\n","        4212     1.0000    0.4000    0.5714         5\n","        4213     1.0000    1.0000    1.0000         7\n","        4214     0.9600    0.8571    0.9057        28\n","        4221     0.6000    0.3333    0.4286         9\n","        4222     0.8267    0.9394    0.8794        66\n","        4223     0.9412    0.6400    0.7619        25\n","        4224     0.8812    0.9468    0.9128        94\n","        4225     0.7368    0.7000    0.7179        20\n","        4229     0.0000    0.0000    0.0000         4\n","        4311     0.7500    0.6923    0.7200        13\n","        4312     0.8760    0.9262    0.9004       122\n","        4313     0.0000    0.0000    0.0000         3\n","        4321     0.9484    0.9266    0.9374       218\n","        4323     0.5000    0.6111    0.5500        18\n","        4411     0.9286    1.0000    0.9630        13\n","        4412     0.4286    0.3000    0.3529        10\n","        4414     0.0000    0.0000    0.0000         3\n","        4415     0.7500    0.7500    0.7500         8\n","        4416     0.7500    0.8000    0.7742        15\n","        4417     0.7574    0.8583    0.8047       120\n","        4419     0.9426    0.9269    0.9347       602\n","        5111     1.0000    0.5000    0.6667         2\n","        5112     0.6667    0.5000    0.5714         4\n","        5113     1.0000    1.0000    1.0000        13\n","        5120     0.9642    0.9663    0.9652      1365\n","        5131     0.9940    0.9851    0.9895       336\n","        5132     0.7500    1.0000    0.8571        12\n","        5141     0.9195    0.7921    0.8511       101\n","        5142     0.8000    0.9412    0.8649        85\n","        5211     0.9115    0.9225    0.9170       413\n","        5212     0.9747    0.9785    0.9766      3588\n","        5213     0.9699    0.9609    0.9654      1074\n","        5221     0.3684    0.5385    0.4375        13\n","        5222     1.0000    0.1429    0.2500         7\n","        5223     0.0000    0.0000    0.0000         5\n","        5230     0.9577    0.9444    0.9510       144\n","        5241     0.7931    0.6765    0.7302        34\n","        5243     0.8409    0.9250    0.8810        80\n","        5244     0.7917    0.7755    0.7835        49\n","        5245     0.7647    0.8298    0.7959        47\n","        5311     0.8103    0.7966    0.8034        59\n","        5312     0.9167    0.9706    0.9429       102\n","        5321     0.0000    0.0000    0.0000         2\n","        5322     0.6774    0.8750    0.7636        24\n","        5329     0.8387    0.8387    0.8387        31\n","        5412     0.8889    0.9600    0.9231        75\n","        5413     1.0000    0.6250    0.7692         8\n","        5414     0.7692    0.8824    0.8219       102\n","        5419     0.0000    0.0000    0.0000         8\n","        6111     0.9949    0.9717    0.9831       600\n","        6112     0.9781    0.9911    0.9846       451\n","        6113     0.0000    0.0000    0.0000         3\n","        6114     0.9991    1.0000    0.9995      6563\n","        6121     0.9846    0.9820    0.9833       779\n","        6122     0.9283    0.9673    0.9474       214\n","        6123     1.0000    1.0000    1.0000         4\n","        6210     0.7838    0.8529    0.8169        34\n","        6221     1.0000    0.6667    0.8000         9\n","        6222     0.9058    0.9665    0.9351       179\n","        6223     0.8571    0.3158    0.4615        19\n","        6224     0.7500    0.7500    0.7500         4\n","        6310     0.0000    0.0000    0.0000         2\n","        6320     0.0000    0.0000    0.0000         5\n","        7111     0.9338    0.9270    0.9304       274\n","        7112     0.0000    0.0000    0.0000         6\n","        7113     0.8158    0.8774    0.8455       106\n","        7119     0.8712    0.9161    0.8931       155\n","        7121     1.0000    0.3333    0.5000         3\n","        7122     0.0000    0.0000    0.0000         1\n","        7123     0.8750    0.6364    0.7368        11\n","        7125     0.0000    0.0000    0.0000         2\n","        7126     0.8182    0.9474    0.8780        19\n","        7127     0.9344    0.9828    0.9580        58\n","        7128     0.9545    1.0000    0.9767       126\n","        7129     0.8750    0.7568    0.8116        37\n","        7212     0.8610    0.9471    0.9020       170\n","        7213     0.0000    0.0000    0.0000         3\n","        7214     0.0000    0.0000    0.0000         7\n","        7221     0.7615    0.8218    0.7905       101\n","        7222     1.0000    0.3889    0.5600        18\n","        7223     0.6667    0.7500    0.7059        16\n","        7224     1.0000    0.5000    0.6667         4\n","        7231     0.8795    0.9125    0.8957       240\n","        7233     0.0000    0.0000    0.0000         6\n","        7234     0.4510    0.6571    0.5349        35\n","        7235     1.0000    0.8571    0.9231         7\n","        7311     0.7143    0.7143    0.7143         7\n","        7312     0.8500    0.9623    0.9027        53\n","        7313     0.8889    0.8276    0.8571        29\n","        7321     0.0000    0.0000    0.0000         1\n","        7322     0.9317    0.8929    0.9119       168\n","        7331     0.0000    0.0000    0.0000         4\n","        7332     0.7500    0.8000    0.7742        15\n","        7333     0.0000    0.0000    0.0000         3\n","        7341     0.7931    0.7188    0.7541        32\n","        7342     0.5294    0.9000    0.6667        10\n","        7351     0.8798    0.8972    0.8885       253\n","        7352     0.7841    0.8415    0.8118       164\n","        7353     0.5000    0.2000    0.2857         5\n","        7354     0.8095    0.8057    0.8076       211\n","        7355     0.6949    0.8723    0.7736        47\n","        7356     0.8889    0.8889    0.8889         9\n","        7361     0.6000    0.4286    0.5000        14\n","        7362     0.8657    0.9508    0.9062        61\n","        7391     0.0000    0.0000    0.0000         7\n","        7392     0.0000    0.0000    0.0000         4\n","        7399     0.7582    0.9324    0.8364        74\n","        7411     0.8080    0.8860    0.8452       114\n","        7412     0.0000    0.0000    0.0000         5\n","        7421     0.7872    0.8506    0.8177        87\n","        7422     0.8000    0.6667    0.7273        24\n","        7431     1.0000    0.4000    0.5714         5\n","        7432     0.0000    0.0000    0.0000         2\n","        7511     0.7436    0.8529    0.7945        34\n","        7512     0.6250    0.4545    0.5263        11\n","        7513     0.9398    0.9704    0.9549       338\n","        7514     0.8485    0.8235    0.8358        34\n","        7515     0.6207    0.5455    0.5806        33\n","        7517     1.0000    1.0000    1.0000         3\n","        7518     0.8551    0.9365    0.8939        63\n","        7519     0.6984    0.6984    0.6984        63\n","        8111     0.7544    0.8113    0.7818        53\n","        8112     0.5000    0.2857    0.3636        14\n","        8113     0.0000    0.0000    0.0000         2\n","        8114     0.0000    0.0000    0.0000         4\n","        8121     0.0000    0.0000    0.0000         3\n","        8131     0.6923    0.5625    0.6207        16\n","        8141     0.9032    0.9032    0.9032        31\n","        8142     0.5357    0.8824    0.6667        17\n","        8151     0.0000    0.0000    0.0000         4\n","        8152     0.0000    0.0000    0.0000         9\n","        8153     0.4286    0.2308    0.3000        13\n","        8154     0.0000    0.0000    0.0000         3\n","        8156     1.0000    0.2857    0.4444         7\n","        8159     0.0000    0.0000    0.0000         5\n","        8160     0.4500    0.6923    0.5455        13\n","        8171     0.6897    0.9524    0.8000        21\n","        8173     0.0000    0.0000    0.0000         3\n","        8181     0.7500    0.9000    0.8182        10\n","        8183     0.0000    0.0000    0.0000         4\n","        8189     0.5143    0.7826    0.6207        23\n","        8321     0.9883    0.9883    0.9883       940\n","        8322     0.9789    0.9588    0.9688       776\n","        8331     0.8962    0.9360    0.9157       203\n","        8332     0.9141    0.9551    0.9341       245\n","        8341     0.9459    0.8974    0.9211        39\n","        8342     0.6316    0.7869    0.7007        61\n","        8343     0.7449    0.6759    0.7087       108\n","        8351     0.0000    0.0000    0.0000         2\n","        8352     0.9024    0.9737    0.9367        38\n","        9111     0.9886    0.9986    0.9936       695\n","        9112     0.9441    0.9286    0.9363       546\n","        9121     0.9950    0.9852    0.9901       203\n","        9122     0.8649    0.9143    0.8889        35\n","        9124     1.0000    1.0000    1.0000         3\n","        9129     0.7500    0.7500    0.7500        16\n","        9211     0.9980    0.9985    0.9982      9856\n","        9212     0.6667    0.3077    0.4211        13\n","        9213     0.6829    0.8000    0.7368        35\n","        9214     0.7826    0.7500    0.7660        24\n","        9311     0.9185    0.9538    0.9358       130\n","        9312     0.9521    0.9298    0.9408       171\n","        9313     0.9838    0.9791    0.9814      1242\n","        9321     0.8391    0.8391    0.8391        87\n","        9329     1.0000    0.3333    0.5000         9\n","        9331     0.7647    0.8478    0.8041        46\n","        9332     0.0000    0.0000    0.0000         2\n","        9333     0.9642    0.9279    0.9457       319\n","        9334     0.9815    0.9636    0.9725        55\n","        9411     0.9071    0.8746    0.8905       279\n","        9412     0.9322    0.9419    0.9370       774\n","        9511     0.8947    0.9067    0.9007       150\n","        9512     0.6667    0.8235    0.7368        17\n","        9521     0.9605    0.9419    0.9511       155\n","        9522     0.6000    0.7500    0.6667        20\n","        9523     0.9655    0.8750    0.9180        32\n","        9524     0.7907    0.7907    0.7907        43\n","        9531     0.8649    0.8000    0.8312        40\n","        9533     0.9470    0.9565    0.9517       299\n","        9534     1.0000    0.3333    0.5000         6\n","        9535     0.9362    0.8844    0.9096       199\n","        9536     0.8333    0.8333    0.8333        12\n","        9537     0.8750    1.0000    0.9333         7\n","        9541     0.7931    0.6970    0.7419        33\n","        9542     0.0000    0.0000    0.0000         3\n","        9549     0.7245    0.7634    0.7435        93\n","        9611     0.5500    0.7333    0.6286        15\n","        9612     0.9029    0.9789    0.9394        95\n","        9613     0.7917    0.8261    0.8085        69\n","        9621     0.8978    0.9389    0.9179       131\n","        9622     0.9547    0.9372    0.9458       382\n","        9623     1.0000    1.0000    1.0000         3\n","        9624     0.0000    0.0000    0.0000         3\n","        9629     0.7114    0.6688    0.6894       951\n","\n","    accuracy                         0.9402     47344\n","   macro avg     0.6416    0.6217    0.6157     47344\n","weighted avg     0.9366    0.9402    0.9371     47344\n","\n","\n","‚úÖ Reporte completo guardado en: /content/drive/MyDrive/Colab Notebooks/PI_PEU/Robertabne/bertin-roberta-base-spanish_20251112_225626/classification_report.txt\n","\n","================================================================================\n","üîç AN√ÅLISIS DE ERRORES\n","================================================================================\n","\n","Total de predicciones: 47,344\n","Predicciones correctas: 44,514\n","Predicciones incorrectas: 2,830\n","Tasa de error: 5.98%\n","\n","‚úÖ An√°lisis de errores guardado en: /content/drive/MyDrive/Colab Notebooks/PI_PEU/Robertabne/bertin-roberta-base-spanish_20251112_225626/error_analysis.csv\n","\n","üìä Top 10 clases con m√°s errores de predicci√≥n:\n","   1. 9629: 315 errores\n","   2. 5212: 77 errores\n","   3. 5120: 46 errores\n","   4. 9412: 45 errores\n","   5. 2421: 45 errores\n","   6. 3124: 45 errores\n","   7. 4419: 44 errores\n","   8. 5213: 42 errores\n","   9. 7354: 41 errores\n","   10. 9112: 39 errores\n","\n","================================================================================\n","\n"]}],"id":"IzyrUTD6IKby"},{"cell_type":"code","metadata":{"id":"P_SQR_giIKby","executionInfo":{"status":"ok","timestamp":1762993779728,"user_tz":300,"elapsed":2112,"user":{"displayName":"BRAYAN POMA HUAMAN","userId":"12837018889427630165"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"e8c8cd31-9c0e-4c74-aec9-ed936797e2b8"},"source":["# ============================================================================\n","# üíæ GUARDADO COMPLETO DEL MODELO Y ARTEFACTOS\n","# ============================================================================\n","\n","print(\"\\n\" + \"=\"*80)\n","print(\"üíæ GUARDANDO MODELO Y ARTEFACTOS\")\n","print(\"=\"*80 + \"\\n\")\n","\n","try:\n","    config.logger.info(\"Guardando modelo final...\")\n","\n","    # 1. Guardar modelo y tokenizer\n","    trainer.save_model(config.MODEL_SAVE_DIR)\n","    tokenizer.save_pretrained(config.MODEL_SAVE_DIR)\n","\n","    print(f\"‚úÖ Modelo y tokenizer guardados en: {config.MODEL_SAVE_DIR}\")\n","    config.logger.info(f\"Modelo guardado en: {config.MODEL_SAVE_DIR}\")\n","\n","    # 2. Guardar artefactos (mapeos, configuraci√≥n, m√©tricas)\n","    artifacts = {\n","        'label2id': label2id,\n","        'id2label': id2label,\n","        'num_labels': len(label2id),\n","        'target_column': config.TARGET_COLUMN,\n","        'text_column': config.TEXT_COLUMN,\n","        'max_length': config.MAX_LENGTH,\n","        'model_name': config.MODEL_NAME,\n","        'model_type': config.model_type,\n","        'experiment_name': config.experiment_name,\n","        'training_date': datetime.now().isoformat(),\n","        'test_metrics': test_metrics,\n","        'val_metrics': val_metrics if 'val_metrics' in locals() else None,\n","        'training_time': str(training_time) if 'training_time' in locals() else None,\n","        'device': config.DEVICE,\n","    }\n","\n","    artifacts_file = os.path.join(config.OUTPUT_DIR, 'artifacts.pkl')\n","    with open(artifacts_file, 'wb') as f:\n","        pickle.dump(artifacts, f)\n","\n","    print(f\"‚úÖ Artefactos guardados en: {artifacts_file}\")\n","    config.logger.info(f\"Artefactos guardados en: {artifacts_file}\")\n","\n","    # 3. Guardar resumen en JSON (legible)\n","    summary = {\n","        'experiment_name': config.experiment_name,\n","        'model_name': config.MODEL_NAME,\n","        'model_type': config.model_type,\n","        'num_classes': len(label2id),\n","        'training_date': datetime.now().isoformat(),\n","        'data_path': config.DATA_PATH,\n","        'max_length': config.MAX_LENGTH,\n","        'batch_size': config.BATCH_SIZE,\n","        'learning_rate': config.LEARNING_RATE,\n","        'num_epochs': config.NUM_EPOCHS,\n","        'test_accuracy': test_metrics.get('test_accuracy', test_metrics.get('eval_accuracy', 0)),\n","        'test_f1_macro': test_metrics.get('test_f1_macro', test_metrics.get('eval_f1_macro', 0)),\n","        'test_f1_weighted': test_metrics.get('test_f1_weighted', test_metrics.get('eval_f1_weighted', 0)),\n","        'device_used': config.DEVICE,\n","    }\n","\n","    summary_file = os.path.join(config.OUTPUT_DIR, 'experiment_summary.json')\n","    with open(summary_file, 'w', encoding='utf-8') as f:\n","        json.dump(summary, f, indent=2, ensure_ascii=False)\n","\n","    print(f\"‚úÖ Resumen guardado en: {summary_file}\")\n","\n","    # 4. Crear archivo README\n","    readme_content = f\"\"\"# Experimento: {config.experiment_name}\n","\n","## Informaci√≥n del Modelo\n","- **Modelo Base**: {config.MODEL_NAME}\n","- **Tipo**: {config.model_type}\n","- **N√∫mero de Clases**: {len(label2id)}\n","- **Fecha de Entrenamiento**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n","\n","## Resultados (Test Set)\n","- **Accuracy**: {test_metrics.get('test_accuracy', test_metrics.get('eval_accuracy', 0)):.4f}\n","- **F1 Macro**: {test_metrics.get('test_f1_macro', test_metrics.get('eval_f1_macro', 0)):.4f}\n","- **F1 Weighted**: {test_metrics.get('test_f1_weighted', test_metrics.get('eval_f1_weighted', 0)):.4f}\n","- **Precision Weighted**: {test_metrics.get('test_precision_weighted', test_metrics.get('eval_precision_weighted', 0)):.4f}\n","- **Recall Weighted**: {test_metrics.get('test_recall_weighted', test_metrics.get('eval_recall_weighted', 0)):.4f}\n","\n","## Archivos Generados\n","- `final_model/`: Modelo entrenado y tokenizer\n","- `artifacts.pkl`: Mapeos y metadata\n","- `config.json`: Configuraci√≥n del entrenamiento\n","- `test_metrics.json`: M√©tricas completas de test\n","- `classification_report.txt`: Reporte detallado por clase\n","- `error_analysis.csv`: An√°lisis de errores\n","- `experiment_summary.json`: Resumen del experimento\n","\n","## C√≥mo Usar el Modelo\n","\n","```python\n","from transformers import AutoTokenizer, AutoModelForSequenceClassification\n","import pickle\n","\n","# Cargar modelo y tokenizer\n","model_path = \"{config.MODEL_SAVE_DIR}\"\n","model = AutoModelForSequenceClassification.from_pretrained(model_path)\n","tokenizer = AutoTokenizer.from_pretrained(model_path)\n","\n","# Cargar artefactos\n","with open('{artifacts_file}', 'rb') as f:\n","    artifacts = pickle.load(f)\n","\n","id2label = artifacts['id2label']\n","\n","# Hacer predicci√≥n\n","text = \"Tu texto aqu√≠\"\n","inputs = tokenizer(text, return_tensors='pt', max_length={config.MAX_LENGTH},\n","                   padding='max_length', truncation=True)\n","outputs = model(**inputs)\n","predicted_class = outputs.logits.argmax().item()\n","predicted_label = id2label[predicted_class]\n","print(f\"Predicci√≥n: {{predicted_label}}\")\n","```\n","\"\"\"\n","\n","    readme_file = os.path.join(config.OUTPUT_DIR, 'README.md')\n","    with open(readme_file, 'w', encoding='utf-8') as f:\n","        f.write(readme_content)\n","\n","    print(f\"‚úÖ README creado en: {readme_file}\")\n","\n","    # 5. Listar todos los archivos generados\n","    print(\"\\n\" + \"=\"*80)\n","    print(\"üìÅ ARCHIVOS GENERADOS\")\n","    print(\"=\"*80 + \"\\n\")\n","\n","    all_files = [\n","        ('Modelo final', config.MODEL_SAVE_DIR),\n","        ('Artefactos', artifacts_file),\n","        ('Configuraci√≥n', os.path.join(config.OUTPUT_DIR, 'config.json')),\n","        ('M√©tricas de test', os.path.join(config.OUTPUT_DIR, 'test_metrics.json')),\n","        ('Reporte de clasificaci√≥n', report_file),\n","        ('An√°lisis de errores', errors_file),\n","        ('Resumen del experimento', summary_file),\n","        ('README', readme_file),\n","        ('Info de clases', os.path.join(config.OUTPUT_DIR, 'class_info.json')),\n","    ]\n","\n","    for name, path in all_files:\n","        if os.path.exists(path):\n","            if os.path.isdir(path):\n","                print(f\"‚úÖ {name:.<40} {path}\")\n","            else:\n","                size = os.path.getsize(path) / 1024\n","                print(f\"‚úÖ {name:.<40} {path} ({size:.1f} KB)\")\n","\n","    print(\"\\n\" + \"=\"*80 + \"\\n\")\n","\n","    config.logger.info(\"Todos los archivos guardados exitosamente\")\n","\n","except Exception as e:\n","    print(\"\\n\" + \"=\"*80)\n","    print(\"‚ùå ERROR AL GUARDAR ARCHIVOS\")\n","    print(\"=\"*80)\n","    print(f\"\\n{str(e)}\\n\")\n","    config.logger.error(f\"Error al guardar: {str(e)}\", exc_info=True)\n","    raise\n"],"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","================================================================================\n","üíæ GUARDANDO MODELO Y ARTEFACTOS\n","================================================================================\n","\n","‚úÖ Modelo y tokenizer guardados en: /content/drive/MyDrive/Colab Notebooks/PI_PEU/Robertabne/bertin-roberta-base-spanish_20251112_225626/final_model\n","‚úÖ Artefactos guardados en: /content/drive/MyDrive/Colab Notebooks/PI_PEU/Robertabne/bertin-roberta-base-spanish_20251112_225626/artifacts.pkl\n","‚úÖ Resumen guardado en: /content/drive/MyDrive/Colab Notebooks/PI_PEU/Robertabne/bertin-roberta-base-spanish_20251112_225626/experiment_summary.json\n","‚úÖ README creado en: /content/drive/MyDrive/Colab Notebooks/PI_PEU/Robertabne/bertin-roberta-base-spanish_20251112_225626/README.md\n","\n","================================================================================\n","üìÅ ARCHIVOS GENERADOS\n","================================================================================\n","\n","‚úÖ Modelo final............................ /content/drive/MyDrive/Colab Notebooks/PI_PEU/Robertabne/bertin-roberta-base-spanish_20251112_225626/final_model\n","‚úÖ Artefactos.............................. /content/drive/MyDrive/Colab Notebooks/PI_PEU/Robertabne/bertin-roberta-base-spanish_20251112_225626/artifacts.pkl (6.2 KB)\n","‚úÖ Configuraci√≥n........................... /content/drive/MyDrive/Colab Notebooks/PI_PEU/Robertabne/bertin-roberta-base-spanish_20251112_225626/config.json (0.5 KB)\n","‚úÖ M√©tricas de test........................ /content/drive/MyDrive/Colab Notebooks/PI_PEU/Robertabne/bertin-roberta-base-spanish_20251112_225626/test_metrics.json (0.6 KB)\n","‚úÖ Reporte de clasificaci√≥n................ /content/drive/MyDrive/Colab Notebooks/PI_PEU/Robertabne/bertin-roberta-base-spanish_20251112_225626/classification_report.txt (19.4 KB)\n","‚úÖ An√°lisis de errores..................... /content/drive/MyDrive/Colab Notebooks/PI_PEU/Robertabne/bertin-roberta-base-spanish_20251112_225626/error_analysis.csv (1680.8 KB)\n","‚úÖ Resumen del experimento................. /content/drive/MyDrive/Colab Notebooks/PI_PEU/Robertabne/bertin-roberta-base-spanish_20251112_225626/experiment_summary.json (0.5 KB)\n","‚úÖ README.................................. /content/drive/MyDrive/Colab Notebooks/PI_PEU/Robertabne/bertin-roberta-base-spanish_20251112_225626/README.md (1.7 KB)\n","‚úÖ Info de clases.......................... /content/drive/MyDrive/Colab Notebooks/PI_PEU/Robertabne/bertin-roberta-base-spanish_20251112_225626/class_info.json (19.6 KB)\n","\n","================================================================================\n","\n"]}],"id":"P_SQR_giIKby"},{"cell_type":"code","metadata":{"id":"u4rxwj65IKby","executionInfo":{"status":"ok","timestamp":1762993779758,"user_tz":300,"elapsed":25,"user":{"displayName":"BRAYAN POMA HUAMAN","userId":"12837018889427630165"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"03d7fe42-78a8-4c9b-e631-1ba40bb54d72"},"source":["# ============================================================================\n","# üîÆ FUNCIONES DE PREDICCI√ìN E INFERENCIA\n","# ============================================================================\n","\n","def load_trained_model_for_inference(model_dir, artifacts_path, device=None):\n","    \"\"\"\n","    Carga el modelo entrenado para hacer predicciones\n","\n","    Args:\n","        model_dir: Directorio del modelo guardado\n","        artifacts_path: Ruta al archivo de artefactos\n","        device: Dispositivo ('cuda' o 'cpu'), None para auto-detectar\n","\n","    Returns:\n","        tuple: (model, tokenizer, artifacts)\n","    \"\"\"\n","    import torch\n","    from transformers import AutoTokenizer, AutoModelForSequenceClassification\n","    import pickle\n","\n","    if device is None:\n","        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","\n","    print(\"\\n\" + \"=\"*80)\n","    print(\"üìÇ CARGANDO MODELO PARA INFERENCIA\")\n","    print(\"=\"*80 + \"\\n\")\n","\n","    # Cargar tokenizer\n","    tokenizer = AutoTokenizer.from_pretrained(model_dir)\n","    print(f\"‚úÖ Tokenizer cargado\")\n","\n","    # Cargar modelo\n","    model = AutoModelForSequenceClassification.from_pretrained(model_dir)\n","    model.to(device)\n","    model.eval()  # Modo evaluaci√≥n\n","    print(f\"‚úÖ Modelo cargado en: {device}\")\n","\n","    # Cargar artefactos\n","    with open(artifacts_path, 'rb') as f:\n","        artifacts = pickle.load(f)\n","    print(f\"‚úÖ Artefactos cargados\")\n","    print(f\"   N√∫mero de clases: {artifacts['num_labels']}\")\n","\n","    print(\"\\n\" + \"=\"*80 + \"\\n\")\n","\n","    return model, tokenizer, artifacts\n","\n","\n","def predict_single(text, model, tokenizer, artifacts, device=None, top_k=5):\n","    \"\"\"\n","    Predice la clase de un texto individual\n","\n","    Args:\n","        text: Texto a clasificar\n","        model: Modelo entrenado\n","        tokenizer: Tokenizer\n","        artifacts: Diccionario de artefactos\n","        device: Dispositivo\n","        top_k: N√∫mero de predicciones principales a retornar\n","\n","    Returns:\n","        dict: Resultados de la predicci√≥n\n","    \"\"\"\n","    import torch\n","    import torch.nn.functional as F\n","\n","    if device is None:\n","        device = next(model.parameters()).device\n","\n","    # Tokenizar\n","    inputs = tokenizer(\n","        text,\n","        max_length=artifacts['max_length'],\n","        padding='max_length',\n","        truncation=True,\n","        return_tensors='pt'\n","    )\n","    inputs = {k: v.to(device) for k, v in inputs.items()}\n","\n","    # Predicci√≥n\n","    with torch.no_grad():\n","        outputs = model(**inputs)\n","        logits = outputs.logits\n","        probs = F.softmax(logits, dim=-1)\n","\n","    # Predicci√≥n principal\n","    predicted_idx = torch.argmax(probs, dim=-1).item()\n","    predicted_prob = probs[0][predicted_idx].item()\n","    predicted_label = artifacts['id2label'][str(predicted_idx)]\n","\n","    # Top-K predicciones\n","    top_probs, top_indices = torch.topk(probs[0], k=min(top_k, len(artifacts['id2label'])))\n","    top_predictions = [\n","        {\n","            'label': artifacts['id2label'][str(idx.item())],\n","            'probability': prob.item()\n","        }\n","        for prob, idx in zip(top_probs, top_indices)\n","    ]\n","\n","    return {\n","        'text': text,\n","        'predicted_label': predicted_label,\n","        'predicted_probability': predicted_prob,\n","        'top_predictions': top_predictions\n","    }\n","\n","\n","def predict_batch(texts, model, tokenizer, artifacts, device=None, batch_size=32):\n","    \"\"\"\n","    Predice las clases de m√∫ltiples textos\n","\n","    Args:\n","        texts: Lista de textos\n","        model: Modelo entrenado\n","        tokenizer: Tokenizer\n","        artifacts: Diccionario de artefactos\n","        device: Dispositivo\n","        batch_size: Tama√±o del lote\n","\n","    Returns:\n","        list: Lista de predicciones\n","    \"\"\"\n","    import torch\n","    import torch.nn.functional as F\n","    from tqdm.auto import tqdm\n","\n","    if device is None:\n","        device = next(model.parameters()).device\n","\n","    model.eval()\n","    predictions = []\n","\n","    # Procesar en lotes\n","    for i in tqdm(range(0, len(texts), batch_size), desc=\"Prediciendo\"):\n","        batch_texts = texts[i:i+batch_size]\n","\n","        # Tokenizar\n","        inputs = tokenizer(\n","            batch_texts,\n","            max_length=artifacts['max_length'],\n","            padding='max_length',\n","            truncation=True,\n","            return_tensors='pt'\n","        )\n","        inputs = {k: v.to(device) for k, v in inputs.items()}\n","\n","        # Predicci√≥n\n","        with torch.no_grad():\n","            outputs = model(**inputs)\n","            logits = outputs.logits\n","            probs = F.softmax(logits, dim=-1)\n","\n","        # Extraer predicciones\n","        predicted_indices = torch.argmax(probs, dim=-1).cpu().numpy()\n","        predicted_probs = torch.max(probs, dim=-1)[0].cpu().numpy()\n","\n","        for idx, prob in zip(predicted_indices, predicted_probs):\n","            predictions.append({\n","                'predicted_label': artifacts['id2label'][str(idx)],\n","                'probability': float(prob)\n","            })\n","\n","    return predictions\n","\n","\n","def interactive_prediction_mode(model, tokenizer, artifacts, device=None):\n","    \"\"\"\n","    Modo interactivo para probar el modelo\n","\n","    Args:\n","        model: Modelo entrenado\n","        tokenizer: Tokenizer\n","        artifacts: Diccionario de artefactos\n","        device: Dispositivo\n","    \"\"\"\n","    print(\"\\n\" + \"=\"*80)\n","    print(\"üß™ MODO DE PRUEBA INTERACTIVO\")\n","    print(\"=\"*80)\n","    print(\"\\nEscribe un texto para clasificar (o 'salir' para terminar)\")\n","    print(\"Comandos especiales: 'salir', 'exit', 'quit', 'q'\\n\")\n","\n","    while True:\n","        print(\"-\" * 80)\n","        text = input(\"\\nüìù Texto: \").strip()\n","\n","        if text.lower() in ['salir', 'exit', 'quit', 'q']:\n","            print(\"\\nüëã ¬°Hasta luego!\\n\")\n","            break\n","\n","        if not text:\n","            print(\"‚ö†Ô∏è  Por favor, ingresa un texto v√°lido\")\n","            continue\n","\n","        # Realizar predicci√≥n\n","        result = predict_single(text, model, tokenizer, artifacts, device)\n","\n","        # Mostrar resultados\n","        print(\"\\nüìä RESULTADO:\")\n","        print(f\"   üéØ Clase predicha: {result['predicted_label']}\")\n","        print(f\"   üìà Confianza: {result['predicted_probability']:.2%}\")\n","        print(f\"\\n   üîù Top 5 predicciones:\")\n","        for i, pred in enumerate(result['top_predictions'], 1):\n","            bar = \"‚ñà\" * int(pred['probability'] * 20)\n","            print(f\"      {i}. {pred['label']:<15} {pred['probability']:>6.2%} {bar}\")\n","        print()\n","\n","\n","print(\"‚úÖ Funciones de predicci√≥n cargadas\")\n"],"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["‚úÖ Funciones de predicci√≥n cargadas\n"]}],"id":"u4rxwj65IKby"},{"cell_type":"code","metadata":{"id":"HDavsX-dIKbz","executionInfo":{"status":"error","timestamp":1762993779877,"user_tz":300,"elapsed":114,"user":{"displayName":"BRAYAN POMA HUAMAN","userId":"12837018889427630165"}},"colab":{"base_uri":"https://localhost:8080/","height":488},"outputId":"2f7be674-721e-4401-9c1b-7aaf90ddafde"},"source":["# ============================================================================\n","# üí° EJEMPLO DE USO - PREDICCI√ìN CON EL MODELO ENTRENADO\n","# ============================================================================\n","\n","# Este c√≥digo muestra c√≥mo usar el modelo despu√©s del entrenamiento\n","# Puedes ejecutarlo en este notebook o en uno nuevo\n","\n","print(\"\\n\" + \"=\"*80)\n","print(\"üí° EJEMPLOS DE USO\")\n","print(\"=\"*80 + \"\\n\")\n","\n","# ============================================================================\n","# OPCI√ìN 1: Usar el modelo reci√©n entrenado (en este notebook)\n","# ============================================================================\n","\n","print(\"üìù OPCI√ìN 1: Predicci√≥n individual con modelo actual\\n\")\n","\n","# Ejemplo de textos para probar\n","ejemplos_texto = [\n","    \"vendedor de abarrotes en bodega\",\n","    \"profesor de matem√°ticas en colegio secundario\",\n","    \"conductor de taxi\"\n","]\n","\n","print(\"Ejemplos de predicci√≥n:\\n\")\n","for texto in ejemplos_texto:\n","    result = predict_single(texto, model, tokenizer, artifacts, config.DEVICE)\n","    print(f\"Texto: {texto}\")\n","    print(f\"Predicci√≥n: {result['predicted_label']} (confianza: {result['predicted_probability']:.2%})\\n\")\n","\n","print(\"-\" * 80 + \"\\n\")\n","\n","# ============================================================================\n","# OPCI√ìN 2: Cargar modelo guardado (en una nueva sesi√≥n)\n","# ============================================================================\n","\n","print(\"üìù OPCI√ìN 2: C√≥digo para cargar el modelo en una nueva sesi√≥n\\n\")\n","\n","codigo_ejemplo = f'''\n","# C√≥digo para usar en un notebook/script nuevo:\n","\n","# 1. Cargar el modelo\n","model_inference, tokenizer_inference, artifacts_inference = load_trained_model_for_inference(\n","    model_dir=\"{config.MODEL_SAVE_DIR}\",\n","    artifacts_path=\"{os.path.join(config.OUTPUT_DIR, 'artifacts.pkl')}\"\n",")\n","\n","# 2. Hacer predicci√≥n individual\n","texto = \"alba√±il de construcci√≥n\"\n","result = predict_single(\n","    text=texto,\n","    model=model_inference,\n","    tokenizer=tokenizer_inference,\n","    artifacts=artifacts_inference\n",")\n","print(f\"Predicci√≥n: {{result['predicted_label']}}\")\n","print(f\"Confianza: {{result['predicted_probability']:.2%}}\")\n","\n","# 3. Hacer predicci√≥n por lotes\n","textos = [\"texto 1\", \"texto 2\", \"texto 3\"]\n","predictions = predict_batch(\n","    texts=textos,\n","    model=model_inference,\n","    tokenizer=tokenizer_inference,\n","    artifacts=artifacts_inference,\n","    batch_size=32\n",")\n","\n","# 4. Modo interactivo\n","interactive_prediction_mode(\n","    model=model_inference,\n","    tokenizer=tokenizer_inference,\n","    artifacts=artifacts_inference\n",")\n","'''\n","\n","print(codigo_ejemplo)\n","\n","print(\"=\" * 80 + \"\\n\")\n"],"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","================================================================================\n","üí° EJEMPLOS DE USO\n","================================================================================\n","\n","üìù OPCI√ìN 1: Predicci√≥n individual con modelo actual\n","\n","Ejemplos de predicci√≥n:\n","\n"]},{"output_type":"error","ename":"KeyError","evalue":"'193'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-3118623678.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Ejemplos de predicci√≥n:\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtexto\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mejemplos_texto\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_single\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0martifacts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Texto: {texto}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Predicci√≥n: {result['predicted_label']} (confianza: {result['predicted_probability']:.2%})\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipython-input-925818954.py\u001b[0m in \u001b[0;36mpredict_single\u001b[0;34m(text, model, tokenizer, artifacts, device, top_k)\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0mpredicted_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0mpredicted_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpredicted_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m     \u001b[0mpredicted_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0martifacts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id2label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;31m# Top-K predicciones\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: '193'"]}],"id":"HDavsX-dIKbz"},{"cell_type":"code","metadata":{"id":"IwaxuCtxIKbz","executionInfo":{"status":"aborted","timestamp":1762993779925,"user_tz":300,"elapsed":39,"user":{"displayName":"BRAYAN POMA HUAMAN","userId":"12837018889427630165"}}},"source":["# ============================================================================\n","# üéÆ MODO INTERACTIVO - PROBAR EL MODELO\n","# ============================================================================\n","\n","# Descomenta y ejecuta esta celda para probar el modelo interactivamente\n","\n","# interactive_prediction_mode(\n","#     model=model,\n","#     tokenizer=tokenizer,\n","#     artifacts=artifacts,\n","#     device=config.DEVICE\n","# )\n","\n","print(\"\\nüí° Descomenta el c√≥digo arriba para activar el modo interactivo\\n\")\n"],"execution_count":null,"outputs":[],"id":"IwaxuCtxIKbz"},{"cell_type":"markdown","metadata":{"id":"BkxBmMG2IKbz"},"source":["---\n","\n","# üéâ ¬°ENTRENAMIENTO COMPLETADO!\n","\n","## üìä Resumen de Resultados\n","\n","Tu modelo ha sido entrenado exitosamente. Revisa:\n","\n","1. **M√©tricas de Test**: Accuracy, F1, Precision, Recall (macro, micro, weighted)\n","2. **Archivos Generados**: Todos los archivos est√°n en el directorio de salida\n","3. **README**: Instrucciones detalladas de uso\n","\n","## üöÄ Pr√≥ximos Pasos\n","\n","### Para entrenar otro modelo:\n","1. Cambia `MODEL_NAME` en `ModelConfig`\n","2. Ejecuta todas las celdas nuevamente\n","\n","### Para usar el modelo:\n","1. Usa las funciones de predicci√≥n en este notebook\n","2. O carga el modelo en un script nuevo (ver ejemplos arriba)\n","\n","### Para mejorar los resultados:\n","- Ajusta los hiperpar√°metros en `ModelConfig`\n","- Aumenta `NUM_EPOCHS`\n","- Experimenta con diferentes `LEARNING_RATE`\n","- Aumenta `MAX_LENGTH` si tus textos son largos\n","\n","---\n","\n","## üìö Modelos Soportados\n","\n","Este script funciona con:\n","- ‚úÖ `FacebookAI/xlm-roberta-base` (Multiling√ºe)\n","- ‚úÖ `dccuchile/bert-base-spanish-wwm-cased` (Espa√±ol)\n","- ‚úÖ Cualquier modelo de Hugging Face compatible con `AutoModelForSequenceClassification`\n","\n","---\n","\n","**¬øPreguntas o errores?** Revisa:\n","- El archivo de log en el directorio de salida\n","- Los mensajes de error detallados en cada celda\n","- La documentaci√≥n de transformers: https://huggingface.co/docs/transformers\n"],"id":"BkxBmMG2IKbz"}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.0"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"911ac04675ab4199852695fa05f00797":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7862035c21a84927b8028392fc13a589","IPY_MODEL_be38dc7bd5694b21a8527d36cf406648","IPY_MODEL_c7091898b28344febdfe2ec9ace23106"],"layout":"IPY_MODEL_0375010933204f9b8e406e61756ec5be"}},"7862035c21a84927b8028392fc13a589":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f525472bdbf648ae9df1e7f981dc2ec3","placeholder":"‚Äã","style":"IPY_MODEL_b000138d29134636a32198a2ea337c80","value":"tokenizer_config.json:‚Äá"}},"be38dc7bd5694b21a8527d36cf406648":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ac5b07d12bb24954a4e5c2236be880b1","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e72e57d1493744588eaae99734c2d1e6","value":1}},"c7091898b28344febdfe2ec9ace23106":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3018cb1086c04aabb1fa4abfb3162075","placeholder":"‚Äã","style":"IPY_MODEL_c534251e33b742d5ab73ef2795219e2c","value":"‚Äá1.12k/?‚Äá[00:00&lt;00:00,‚Äá35.8kB/s]"}},"0375010933204f9b8e406e61756ec5be":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f525472bdbf648ae9df1e7f981dc2ec3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b000138d29134636a32198a2ea337c80":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ac5b07d12bb24954a4e5c2236be880b1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"e72e57d1493744588eaae99734c2d1e6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3018cb1086c04aabb1fa4abfb3162075":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c534251e33b742d5ab73ef2795219e2c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9b86774e14cf4d2ea10e2931f39c70b6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f78c692fc732426c9b38ef9d8f43fc60","IPY_MODEL_885eee9420f04e0bbc9259fc6a2eff43","IPY_MODEL_7a99f623dd3b473c8deaa277df7221ba"],"layout":"IPY_MODEL_6b85658cf90b4cb7ae5b128593a30b9d"}},"f78c692fc732426c9b38ef9d8f43fc60":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9522c40242b44d0fad48f841eb113fc3","placeholder":"‚Äã","style":"IPY_MODEL_c5daef87f9314a188d9a331bb3c5359f","value":"vocab.json:‚Äá"}},"885eee9420f04e0bbc9259fc6a2eff43":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1dda9ab1ff6e4107a04eda07c78961fe","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2bfa143afa7444c5986d8edcc7e1edca","value":1}},"7a99f623dd3b473c8deaa277df7221ba":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cd0998bfe8fb43ecb0dcd1aca389f316","placeholder":"‚Äã","style":"IPY_MODEL_07e416cd8ffa48ec9d037657830ea11a","value":"‚Äá851k/?‚Äá[00:00&lt;00:00,‚Äá10.9MB/s]"}},"6b85658cf90b4cb7ae5b128593a30b9d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9522c40242b44d0fad48f841eb113fc3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c5daef87f9314a188d9a331bb3c5359f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1dda9ab1ff6e4107a04eda07c78961fe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"2bfa143afa7444c5986d8edcc7e1edca":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"cd0998bfe8fb43ecb0dcd1aca389f316":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"07e416cd8ffa48ec9d037657830ea11a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f60333e117eb439c9fba97908f0ee718":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c524e6bff6c34d0b9ec97847bbf9f087","IPY_MODEL_85bdafe751304a0d9ee13861534cb03e","IPY_MODEL_fe20159971d2412dbc32fcf0db3f78d3"],"layout":"IPY_MODEL_fc9994da0115411892022b617076de1e"}},"c524e6bff6c34d0b9ec97847bbf9f087":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_778b74759d874d578af4f7972c75764b","placeholder":"‚Äã","style":"IPY_MODEL_5c8e625ec02c49dcb69642e4f1b7f112","value":"merges.txt:‚Äá"}},"85bdafe751304a0d9ee13861534cb03e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a4d6d91c27264442b96543ba669d5dc7","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a4d66b6debc345c999fa02e7b37d2fc6","value":1}},"fe20159971d2412dbc32fcf0db3f78d3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8c825ff3358749fea7f7bfb6a754a44b","placeholder":"‚Äã","style":"IPY_MODEL_dba98dfc296b44389de6e24df0443522","value":"‚Äá509k/?‚Äá[00:00&lt;00:00,‚Äá13.8MB/s]"}},"fc9994da0115411892022b617076de1e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"778b74759d874d578af4f7972c75764b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5c8e625ec02c49dcb69642e4f1b7f112":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a4d6d91c27264442b96543ba669d5dc7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"a4d66b6debc345c999fa02e7b37d2fc6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8c825ff3358749fea7f7bfb6a754a44b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dba98dfc296b44389de6e24df0443522":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f99a755e0bb047bb923135b1a9134ea7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8893b1bd0565466aa20ca63d8c89f1c0","IPY_MODEL_75911875344a46ebb004d97fa60b4952","IPY_MODEL_64b1be07b65347f2802b5ba9683a90ac"],"layout":"IPY_MODEL_05e68c7cbf85497491201fadcc802a84"}},"8893b1bd0565466aa20ca63d8c89f1c0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9c9ed7435beb41ed8e886f3ea9e1c206","placeholder":"‚Äã","style":"IPY_MODEL_4e2552fae4954a2e852bc791b9ac24bf","value":"tokenizer.json:‚Äá"}},"75911875344a46ebb004d97fa60b4952":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_009f4156efc140228cf5856b907addd6","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6b7c3c8561c44ecb928c9b072e91de56","value":1}},"64b1be07b65347f2802b5ba9683a90ac":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f991153bf87b49658c8de171335c50e9","placeholder":"‚Äã","style":"IPY_MODEL_1b079b42eaf34918bc01be5cfcdbc3f6","value":"‚Äá2.21M/?‚Äá[00:00&lt;00:00,‚Äá35.3MB/s]"}},"05e68c7cbf85497491201fadcc802a84":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9c9ed7435beb41ed8e886f3ea9e1c206":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4e2552fae4954a2e852bc791b9ac24bf":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"009f4156efc140228cf5856b907addd6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"6b7c3c8561c44ecb928c9b072e91de56":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f991153bf87b49658c8de171335c50e9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1b079b42eaf34918bc01be5cfcdbc3f6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"68cef520e72f44499cd46c077b7433de":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8a9ef415eb774e6493ae4c6777b0716d","IPY_MODEL_5ca5bfa4b77d4957b86c283d45f2207f","IPY_MODEL_c2f1d9c6e95f4174ad8527799d6bcf77"],"layout":"IPY_MODEL_29e37dc9d30a4461b93f46d3707bc478"}},"8a9ef415eb774e6493ae4c6777b0716d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ceed5f8a67e34875b732a85f66e1ff0d","placeholder":"‚Äã","style":"IPY_MODEL_67be2b89f2e24a90ab39b73c8710caa2","value":"special_tokens_map.json:‚Äá100%"}},"5ca5bfa4b77d4957b86c283d45f2207f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_dc5e684ecb1a4cb4b943a955e0094b55","max":772,"min":0,"orientation":"horizontal","style":"IPY_MODEL_647e1690452a44ecb5c4034d8ce16521","value":772}},"c2f1d9c6e95f4174ad8527799d6bcf77":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7f4bd80f44694ea0ae4d16e601b7f7cb","placeholder":"‚Äã","style":"IPY_MODEL_aa12dfb99c5a4702847eafa65d66b25d","value":"‚Äá772/772‚Äá[00:00&lt;00:00,‚Äá16.7kB/s]"}},"29e37dc9d30a4461b93f46d3707bc478":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ceed5f8a67e34875b732a85f66e1ff0d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"67be2b89f2e24a90ab39b73c8710caa2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"dc5e684ecb1a4cb4b943a955e0094b55":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"647e1690452a44ecb5c4034d8ce16521":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7f4bd80f44694ea0ae4d16e601b7f7cb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aa12dfb99c5a4702847eafa65d66b25d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d563d61a3a4a4ea2a5de306ab9bb8a9f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_14b2252e80864a41b4fc2fe293e67353","IPY_MODEL_cc22a9432c0149eb8a35fe18387b46ce","IPY_MODEL_a419f90b2e444163be201a4e7f66b0f4"],"layout":"IPY_MODEL_4de92f8077b74aca857936188a2d821c"}},"14b2252e80864a41b4fc2fe293e67353":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dc215a291b5c42c5b69ad9e19f89168c","placeholder":"‚Äã","style":"IPY_MODEL_a4e1b0abdee645e5b27b9cbf9b2bdc37","value":"config.json:‚Äá100%"}},"cc22a9432c0149eb8a35fe18387b46ce":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7288499473bc4b10bc0ef129d698fb78","max":674,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f321cfb4233b4ceb90fe6ceb92b5ca94","value":674}},"a419f90b2e444163be201a4e7f66b0f4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8cf50382e8c342aaa773bf34c6abf26e","placeholder":"‚Äã","style":"IPY_MODEL_24bd48289b284d18ae3ccc1456922a1c","value":"‚Äá674/674‚Äá[00:00&lt;00:00,‚Äá22.3kB/s]"}},"4de92f8077b74aca857936188a2d821c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dc215a291b5c42c5b69ad9e19f89168c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a4e1b0abdee645e5b27b9cbf9b2bdc37":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7288499473bc4b10bc0ef129d698fb78":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f321cfb4233b4ceb90fe6ceb92b5ca94":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8cf50382e8c342aaa773bf34c6abf26e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"24bd48289b284d18ae3ccc1456922a1c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"774663d1fa114882a10c377949dbdea3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3fb9e84936204c338c02cbb00aadbb31","IPY_MODEL_5b10469357c04250bdce90d4e256e06b","IPY_MODEL_e7fb913d2c794d1b99661496fd324150"],"layout":"IPY_MODEL_f381dd7ae35f4341857935ec22a47749"}},"3fb9e84936204c338c02cbb00aadbb31":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_03c85293c0af4f45bf202b83b6ee4417","placeholder":"‚Äã","style":"IPY_MODEL_96f859c725de47088e71d93ef7752659","value":"model.safetensors:‚Äá100%"}},"5b10469357c04250bdce90d4e256e06b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a38dd13e616c428eae0474d367226548","max":498808924,"min":0,"orientation":"horizontal","style":"IPY_MODEL_266f400b91ca47a7860ca4d1c6d048a0","value":498808924}},"e7fb913d2c794d1b99661496fd324150":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_42b63e4bc9164db18e42e285b7b81514","placeholder":"‚Äã","style":"IPY_MODEL_70e1b4736a674773b8716e04acd17524","value":"‚Äá499M/499M‚Äá[00:05&lt;00:00,‚Äá197MB/s]"}},"f381dd7ae35f4341857935ec22a47749":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"03c85293c0af4f45bf202b83b6ee4417":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"96f859c725de47088e71d93ef7752659":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a38dd13e616c428eae0474d367226548":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"266f400b91ca47a7860ca4d1c6d048a0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"42b63e4bc9164db18e42e285b7b81514":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"70e1b4736a674773b8716e04acd17524":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":5}