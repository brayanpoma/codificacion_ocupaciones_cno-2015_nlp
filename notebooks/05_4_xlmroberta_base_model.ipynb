{"cells":[{"cell_type":"markdown","metadata":{"id":"HZsUKvPcIKbi"},"source":["# üöÄ Entrenamiento de Modelos Transformer para Clasificaci√≥n de Ocupaciones ENAHO\n","\n","---\n","\n","## üìã Descripci√≥n\n","Script robusto y universal para entrenar modelos de clasificaci√≥n de texto.\n","\n","### üéØ Modelos Soportados:\n","- **BETO**: `dccuchile/bert-base-spanish-wwm-cased` (Espa√±ol)\n","- **XLM-RoBERTa**: `FacebookAI/xlm-roberta-base` (Multiling√ºe)\n","\n","### ‚ú® Caracter√≠sticas:\n","- ‚úÖ Cambio de modelo con una sola variable\n","- ‚úÖ M√©tricas detalladas (macro, micro, weighted)\n","- ‚úÖ Manejo robusto de errores\n","- ‚úÖ Logging detallado para debugging\n","- ‚úÖ Validaci√≥n de datos en cada paso\n","- ‚úÖ Guardado completo de modelo y artefactos\n","- ‚úÖ Funciones de predicci√≥n e inferencia\n","\n","---\n","\n","**Autor**: Sistema de Clasificaci√≥n ENAHO  \n","**Fecha**: 2025  \n","**Entorno**: VSCode con Jupyter Notebook  \n"],"id":"HZsUKvPcIKbi"},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5jXhWE22Ii01","executionInfo":{"status":"ok","timestamp":1762972039896,"user_tz":300,"elapsed":28421,"user":{"displayName":"Jesbil Betsy Valladolid Garcia","userId":"11256541342152996128"}},"outputId":"4f7d3ba2-7ee8-4862-d969-01f177e68537"},"id":"5jXhWE22Ii01","execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9LksZDJXIKbq","executionInfo":{"status":"ok","timestamp":1762972039900,"user_tz":300,"elapsed":20,"user":{"displayName":"Jesbil Betsy Valladolid Garcia","userId":"11256541342152996128"}},"outputId":"49513c9d-7cde-4d6a-834a-2252b891ad6a"},"source":["# ============================================================================\n","# INSTALACI√ìN DE DEPENDENCIAS (Ejecutar solo una vez)\n","# ============================================================================\n","\n","# Descomenta si necesitas instalar las librer√≠as\n","# !pip install transformers==4.36.0 datasets==2.15.0 scikit-learn==1.3.2\n","# !pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n","# !pip install accelerate sentencepiece\n","\n","print(\"‚úÖ Si las librer√≠as ya est√°n instaladas, puedes continuar\")\n"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["‚úÖ Si las librer√≠as ya est√°n instaladas, puedes continuar\n"]}],"id":"9LksZDJXIKbq"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YAmxPXboIKbr","executionInfo":{"status":"ok","timestamp":1762972103671,"user_tz":300,"elapsed":63769,"user":{"displayName":"Jesbil Betsy Valladolid Garcia","userId":"11256541342152996128"}},"outputId":"c1dd389f-e6bf-4dcb-b794-09efae881582"},"source":["# ============================================================================\n","# IMPORTACIONES Y VERIFICACI√ìN DEL ENTORNO\n","# ============================================================================\n","\n","import sys\n","import os\n","import warnings\n","import logging\n","from datetime import datetime\n","from pathlib import Path\n","\n","# Data & ML\n","import pandas as pd\n","import numpy as np\n","import torch\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import (\n","    accuracy_score,\n","    precision_recall_fscore_support,\n","    classification_report,\n","    confusion_matrix\n",")\n","\n","# Transformers\n","from transformers import (\n","    AutoTokenizer,\n","    AutoModelForSequenceClassification,\n","    TrainingArguments,\n","    Trainer,\n","    EarlyStoppingCallback\n",")\n","from torch.utils.data import Dataset\n","\n","# Utilities\n","from tqdm.auto import tqdm\n","import pickle\n","import json\n","\n","warnings.filterwarnings('ignore')\n","\n","# ============================================================================\n","# CONFIGURACI√ìN DE LOGGING\n","# ============================================================================\n","\n","def setup_logging(output_dir):\n","    \"\"\"Configura el sistema de logging para debugging\"\"\"\n","    os.makedirs(output_dir, exist_ok=True)\n","    log_file = os.path.join(output_dir, f'training_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.log')\n","\n","    logging.basicConfig(\n","        level=logging.INFO,\n","        format='%(asctime)s - %(levelname)s - %(message)s',\n","        handlers=[\n","            logging.FileHandler(log_file, encoding='utf-8'),\n","            logging.StreamHandler(sys.stdout)\n","        ]\n","    )\n","    return logging.getLogger(__name__)\n","\n","# ============================================================================\n","# VERIFICACI√ìN DE GPU\n","# ============================================================================\n","\n","print(\"\\n\" + \"=\"*80)\n","print(\"üîç VERIFICACI√ìN DEL ENTORNO\")\n","print(\"=\"*80)\n","\n","print(f\"\\nüì¶ Versiones:\")\n","print(f\"   Python: {sys.version.split()[0]}\")\n","print(f\"   PyTorch: {torch.__version__}\")\n","print(f\"   CUDA disponible: {torch.cuda.is_available()}\")\n","\n","if torch.cuda.is_available():\n","    print(f\"\\nüéÆ GPU Detectada:\")\n","    print(f\"   Dispositivo: {torch.cuda.get_device_name(0)}\")\n","    print(f\"   Memoria total: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n","    print(f\"   Memoria libre: {(torch.cuda.get_device_properties(0).total_memory - torch.cuda.memory_allocated(0)) / 1e9:.2f} GB\")\n","else:\n","    print(\"\\n‚ö†Ô∏è  GPU no detectada - El entrenamiento ser√° lento\")\n","    print(\"   Considera usar Google Colab o configurar CUDA\")\n","\n","print(\"\\n\" + \"=\"*80)\n","print(\"‚úÖ Importaciones completadas correctamente\")\n","print(\"=\"*80 + \"\\n\")\n"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","================================================================================\n","üîç VERIFICACI√ìN DEL ENTORNO\n","================================================================================\n","\n","üì¶ Versiones:\n","   Python: 3.12.12\n","   PyTorch: 2.8.0+cu126\n","   CUDA disponible: True\n","\n","üéÆ GPU Detectada:\n","   Dispositivo: Tesla T4\n","   Memoria total: 15.83 GB\n","   Memoria libre: 15.83 GB\n","\n","================================================================================\n","‚úÖ Importaciones completadas correctamente\n","================================================================================\n","\n"]}],"id":"YAmxPXboIKbr"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":591},"id":"xfu88qZ_IKbs","executionInfo":{"status":"ok","timestamp":1762972108259,"user_tz":300,"elapsed":4591,"user":{"displayName":"Jesbil Betsy Valladolid Garcia","userId":"11256541342152996128"}},"outputId":"40adef2f-8b3c-410d-c15d-9d284c29b7e6"},"source":["# ============================================================================\n","# ‚öôÔ∏è  CONFIGURACI√ìN PRINCIPAL - MODIFICA AQU√ç\n","# ============================================================================\n","\n","class ModelConfig:\n","    \"\"\"\n","    Configuraci√≥n centralizada del modelo y entrenamiento\n","\n","    IMPORTANTE: Solo necesitas cambiar MODEL_NAME para entrenar un modelo diferente\n","    \"\"\"\n","\n","    # ========================================================================\n","    # üéØ SELECCI√ìN DEL MODELO - CAMBIA SOLO ESTA L√çNEA\n","    # ========================================================================\n","\n","    MODEL_NAME = \"FacebookAI/xlm-roberta-base\"  # Opci√≥n 1: XLM-RoBERTa (multiling√ºe)\n","    # MODEL_NAME = \"dccuchile/bert-base-spanish-wwm-cased\"  # Opci√≥n 2: BETO (espa√±ol)\n","\n","    # ========================================================================\n","    # üìÇ RUTAS DE DATOS\n","    # ========================================================================\n","\n","    # Ruta al archivo de datos (ajusta seg√∫n tu ubicaci√≥n)\n","    DATA_PATH = \"/content/drive/MyDrive/PI_PEU/BASE_LIMPIA_VF.parquet\"  # Cambia esta ruta\n","\n","    # Directorio base para outputs\n","    BASE_OUTPUT_DIR = \"/content/drive/MyDrive/PI_PEU/xlmRoberta\"\n","\n","    # ========================================================================\n","    # üìä COLUMNAS DEL DATASET\n","    # ========================================================================\n","\n","    TEXT_COLUMN = \"texto_final\"  # Columna con el texto\n","    TARGET_COLUMN = \"p505r4\"     # Columna objetivo (clase)\n","\n","    # ========================================================================\n","    # üéõÔ∏è  HIPERPAR√ÅMETROS DE ENTRENAMIENTO\n","    # ========================================================================\n","\n","    # Tokenizaci√≥n\n","    MAX_LENGTH = 128  # Longitud m√°xima de tokens\n","\n","    # Entrenamiento\n","    BATCH_SIZE = 16          # Ajusta seg√∫n tu GPU (16, 32, 64)\n","    LEARNING_RATE = 2e-5     # Tasa de aprendizaje\n","    NUM_EPOCHS = 3           # N√∫mero de √©pocas\n","    WARMUP_STEPS = 500       # Pasos de warmup\n","    WEIGHT_DECAY = 0.01      # Regularizaci√≥n\n","\n","    # Divisi√≥n de datos\n","    TEST_SIZE = 0.15         # 15% para test\n","    VAL_SIZE = 0.15          # 15% para validaci√≥n\n","    RANDOM_STATE = 2025      # Semilla para reproducibilidad\n","\n","    # Filtrado de clases raras\n","    MIN_SAMPLES_PER_CLASS = 10  # M√≠nimo de muestras por clase\n","\n","    # Early stopping\n","    EARLY_STOPPING_PATIENCE = 3\n","\n","    # ========================================================================\n","    # üîß CONFIGURACI√ìN AUTOM√ÅTICA (NO MODIFICAR)\n","    # ========================================================================\n","\n","    def __init__(self):\n","        \"\"\"Inicializa configuraci√≥n y crea directorios\"\"\"\n","        # Detectar tipo de modelo del nombre\n","        if \"roberta\" in self.MODEL_NAME.lower():\n","            self.model_type = \"xlm-roberta\"\n","        elif \"bert\" in self.MODEL_NAME.lower():\n","            self.model_type = \"bert\"\n","        else:\n","            self.model_type = \"transformer\"\n","\n","        # Crear nombre descriptivo para el experimento\n","        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n","        model_short_name = self.MODEL_NAME.split('/')[-1]\n","        self.experiment_name = f\"{model_short_name}_{timestamp}\"\n","\n","        # Configurar directorios\n","        self.OUTPUT_DIR = os.path.join(self.BASE_OUTPUT_DIR, self.experiment_name)\n","        self.MODEL_SAVE_DIR = os.path.join(self.OUTPUT_DIR, \"final_model\")\n","        self.CHECKPOINT_DIR = os.path.join(self.OUTPUT_DIR, \"checkpoints\")\n","\n","        # Crear directorios\n","        for dir_path in [self.OUTPUT_DIR, self.MODEL_SAVE_DIR, self.CHECKPOINT_DIR]:\n","            os.makedirs(dir_path, exist_ok=True)\n","\n","        # Device\n","        self.DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","\n","        # Configurar logging\n","        self.logger = setup_logging(self.OUTPUT_DIR)\n","        self.logger.info(f\"Experimento iniciado: {self.experiment_name}\")\n","        self.logger.info(f\"Modelo seleccionado: {self.MODEL_NAME}\")\n","        self.logger.info(f\"Dispositivo: {self.DEVICE}\")\n","\n","    def display_config(self):\n","        \"\"\"Muestra la configuraci√≥n actual\"\"\"\n","        print(\"\\n\" + \"=\"*80)\n","        print(\"‚öôÔ∏è  CONFIGURACI√ìN DEL MODELO\")\n","        print(\"=\"*80)\n","        print(f\"\\nü§ñ Modelo: {self.MODEL_NAME}\")\n","        print(f\"   Tipo: {self.model_type}\")\n","        print(f\"   Experimento: {self.experiment_name}\")\n","        print(f\"\\nüìÇ Rutas:\")\n","        print(f\"   Datos: {self.DATA_PATH}\")\n","        print(f\"   Output: {self.OUTPUT_DIR}\")\n","        print(f\"   Modelo final: {self.MODEL_SAVE_DIR}\")\n","        print(f\"\\nüìä Datos:\")\n","        print(f\"   Columna texto: {self.TEXT_COLUMN}\")\n","        print(f\"   Columna target: {self.TARGET_COLUMN}\")\n","        print(f\"   Max length: {self.MAX_LENGTH}\")\n","        print(f\"\\nüéõÔ∏è  Entrenamiento:\")\n","        print(f\"   Batch size: {self.BATCH_SIZE}\")\n","        print(f\"   Learning rate: {self.LEARNING_RATE}\")\n","        print(f\"   Epochs: {self.NUM_EPOCHS}\")\n","        print(f\"   Early stopping: {self.EARLY_STOPPING_PATIENCE} epochs\")\n","        print(f\"\\nüíæ Divisi√≥n de datos:\")\n","        print(f\"   Test: {self.TEST_SIZE*100:.0f}%\")\n","        print(f\"   Validaci√≥n: {self.VAL_SIZE*100:.0f}%\")\n","        print(f\"   Train: {(1-self.TEST_SIZE-self.VAL_SIZE)*100:.0f}%\")\n","        print(\"\\n\" + \"=\"*80 + \"\\n\")\n","\n","    def save_config(self):\n","        \"\"\"Guarda la configuraci√≥n en JSON\"\"\"\n","        config_dict = {\n","            'model_name': self.MODEL_NAME,\n","            'model_type': self.model_type,\n","            'experiment_name': self.experiment_name,\n","            'data_path': self.DATA_PATH,\n","            'text_column': self.TEXT_COLUMN,\n","            'target_column': self.TARGET_COLUMN,\n","            'max_length': self.MAX_LENGTH,\n","            'batch_size': self.BATCH_SIZE,\n","            'learning_rate': self.LEARNING_RATE,\n","            'num_epochs': self.NUM_EPOCHS,\n","            'test_size': self.TEST_SIZE,\n","            'val_size': self.VAL_SIZE,\n","            'random_state': self.RANDOM_STATE,\n","            'min_samples_per_class': self.MIN_SAMPLES_PER_CLASS,\n","            'device': self.DEVICE,\n","            'timestamp': datetime.now().isoformat()\n","        }\n","\n","        config_path = os.path.join(self.OUTPUT_DIR, 'config.json')\n","        with open(config_path, 'w', encoding='utf-8') as f:\n","            json.dump(config_dict, f, indent=2, ensure_ascii=False)\n","\n","        self.logger.info(f\"Configuraci√≥n guardada en: {config_path}\")\n","        return config_path\n","\n","\n","# Inicializar configuraci√≥n\n","config = ModelConfig()\n","config.display_config()\n","config.save_config()\n"],"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","================================================================================\n","‚öôÔ∏è  CONFIGURACI√ìN DEL MODELO\n","================================================================================\n","\n","ü§ñ Modelo: FacebookAI/xlm-roberta-base\n","   Tipo: xlm-roberta\n","   Experimento: xlm-roberta-base_20251112_182822\n","\n","üìÇ Rutas:\n","   Datos: /content/drive/MyDrive/PI_PEU/BASE_LIMPIA_VF.parquet\n","   Output: /content/drive/MyDrive/PI_PEU/xlmRoberta/xlm-roberta-base_20251112_182822\n","   Modelo final: /content/drive/MyDrive/PI_PEU/xlmRoberta/xlm-roberta-base_20251112_182822/final_model\n","\n","üìä Datos:\n","   Columna texto: texto_final\n","   Columna target: p505r4\n","   Max length: 128\n","\n","üéõÔ∏è  Entrenamiento:\n","   Batch size: 16\n","   Learning rate: 2e-05\n","   Epochs: 3\n","   Early stopping: 3 epochs\n","\n","üíæ Divisi√≥n de datos:\n","   Test: 15%\n","   Validaci√≥n: 15%\n","   Train: 70%\n","\n","================================================================================\n","\n"]},{"output_type":"execute_result","data":{"text/plain":["'/content/drive/MyDrive/PI_PEU/xlmRoberta/xlm-roberta-base_20251112_182822/config.json'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":4}],"id":"xfu88qZ_IKbs"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qfG0DkcRIKbt","executionInfo":{"status":"ok","timestamp":1762972120641,"user_tz":300,"elapsed":12361,"user":{"displayName":"Jesbil Betsy Valladolid Garcia","userId":"11256541342152996128"}},"outputId":"3abe8b19-c4d0-46f7-e879-c1bb18df9167"},"source":["# ============================================================================\n","# üìÇ CARGA Y VALIDACI√ìN DE DATOS\n","# ============================================================================\n","\n","class DataLoader:\n","    \"\"\"Cargador y validador de datos con manejo robusto de errores\"\"\"\n","\n","    def __init__(self, config):\n","        self.config = config\n","        self.logger = config.logger\n","\n","    def load_data(self):\n","        \"\"\"\n","        Carga datos desde archivo con validaci√≥n\n","\n","        Returns:\n","            pd.DataFrame: Datos cargados\n","        \"\"\"\n","        try:\n","            self.logger.info(f\"Cargando datos desde: {self.config.DATA_PATH}\")\n","\n","            # Verificar que el archivo existe\n","            if not os.path.exists(self.config.DATA_PATH):\n","                raise FileNotFoundError(\n","                    f\"‚ùå El archivo no existe: {self.config.DATA_PATH}\\n\"\n","                    f\"   Por favor, verifica la ruta en ModelConfig.DATA_PATH\"\n","                )\n","\n","            # Cargar seg√∫n extensi√≥n\n","            file_ext = os.path.splitext(self.config.DATA_PATH)[1].lower()\n","\n","            if file_ext == '.parquet':\n","                df = pd.read_parquet(self.config.DATA_PATH)\n","            elif file_ext == '.csv':\n","                df = pd.read_csv(self.config.DATA_PATH)\n","            elif file_ext in ['.xlsx', '.xls']:\n","                df = pd.read_excel(self.config.DATA_PATH)\n","            else:\n","                raise ValueError(\n","                    f\"‚ùå Formato no soportado: {file_ext}\\n\"\n","                    f\"   Formatos v√°lidos: .parquet, .csv, .xlsx, .xls\"\n","                )\n","\n","            self.logger.info(f\"‚úÖ Datos cargados: {df.shape[0]:,} filas x {df.shape[1]} columnas\")\n","\n","            return df\n","\n","        except Exception as e:\n","            self.logger.error(f\"‚ùå Error al cargar datos: {str(e)}\")\n","            raise\n","\n","    def validate_data(self, df):\n","        \"\"\"\n","        Valida que los datos tengan las columnas necesarias\n","\n","        Args:\n","            df: DataFrame a validar\n","\n","        Raises:\n","            ValueError: Si faltan columnas requeridas\n","        \"\"\"\n","        self.logger.info(\"Validando estructura de datos...\")\n","\n","        # Verificar columnas requeridas\n","        required_cols = [self.config.TEXT_COLUMN, self.config.TARGET_COLUMN]\n","        missing_cols = [col for col in required_cols if col not in df.columns]\n","\n","        if missing_cols:\n","            available_cols = list(df.columns)\n","            raise ValueError(\n","                f\"‚ùå Columnas faltantes: {missing_cols}\\n\"\n","                f\"   Columnas disponibles: {available_cols}\\n\"\n","                f\"   Verifica TEXT_COLUMN y TARGET_COLUMN en ModelConfig\"\n","            )\n","\n","        # Validar datos no nulos\n","        null_text = df[self.config.TEXT_COLUMN].isna().sum()\n","        null_target = df[self.config.TARGET_COLUMN].isna().sum()\n","\n","        self.logger.info(\n","            f\"   Valores nulos - Texto: {null_text:,}, Target: {null_target:,}\"\n","        )\n","\n","        # Validar textos vac√≠os\n","        empty_text = (df[self.config.TEXT_COLUMN].str.strip() == '').sum()\n","        if empty_text > 0:\n","            self.logger.warning(f\"   ‚ö†Ô∏è  Textos vac√≠os: {empty_text:,}\")\n","\n","        self.logger.info(\"‚úÖ Validaci√≥n completada\")\n","\n","    def filter_valid_records(self, df):\n","        \"\"\"\n","        Filtra registros v√°lidos (no nulos, no vac√≠os)\n","\n","        Args:\n","            df: DataFrame original\n","\n","        Returns:\n","            pd.DataFrame: DataFrame filtrado\n","        \"\"\"\n","        self.logger.info(\"Filtrando registros v√°lidos...\")\n","\n","        initial_count = len(df)\n","\n","        # Filtrar nulos y vac√≠os\n","        df_clean = df[\n","            df[self.config.TEXT_COLUMN].notna() &\n","            df[self.config.TARGET_COLUMN].notna() &\n","            (df[self.config.TEXT_COLUMN].str.strip() != '')\n","        ].copy()\n","\n","        final_count = len(df_clean)\n","        removed = initial_count - final_count\n","\n","        self.logger.info(\n","            f\"   Registros iniciales: {initial_count:,}\\n\"\n","            f\"   Registros v√°lidos: {final_count:,}\\n\"\n","            f\"   Removidos: {removed:,} ({removed/initial_count*100:.2f}%)\"\n","        )\n","\n","        if final_count == 0:\n","            raise ValueError(\n","                \"‚ùå No quedan registros v√°lidos despu√©s del filtrado\\n\"\n","                \"   Verifica la calidad de tus datos\"\n","            )\n","\n","        return df_clean\n","\n","    def filter_rare_classes(self, df):\n","        \"\"\"\n","        Filtra clases con pocas muestras\n","\n","        Args:\n","            df: DataFrame\n","\n","        Returns:\n","            pd.DataFrame: DataFrame filtrado\n","        \"\"\"\n","        self.logger.info(\n","            f\"Filtrando clases con < {self.config.MIN_SAMPLES_PER_CLASS} muestras...\"\n","        )\n","\n","        # Contar muestras por clase\n","        class_counts = df[self.config.TARGET_COLUMN].value_counts()\n","\n","        # Identificar clases v√°lidas\n","        valid_classes = class_counts[class_counts >= self.config.MIN_SAMPLES_PER_CLASS].index\n","        rare_classes = class_counts[class_counts < self.config.MIN_SAMPLES_PER_CLASS]\n","\n","        # Filtrar\n","        df_filtered = df[df[self.config.TARGET_COLUMN].isin(valid_classes)].copy()\n","\n","        self.logger.info(\n","            f\"   Clases originales: {len(class_counts):,}\\n\"\n","            f\"   Clases mantenidas: {len(valid_classes):,}\\n\"\n","            f\"   Clases removidas: {len(rare_classes):,}\\n\"\n","            f\"   Registros antes: {len(df):,}\\n\"\n","            f\"   Registros despu√©s: {len(df_filtered):,}\"\n","        )\n","\n","        if len(df_filtered) == 0:\n","            raise ValueError(\n","                f\"‚ùå No quedan registros despu√©s de filtrar clases raras\\n\"\n","                f\"   Considera reducir MIN_SAMPLES_PER_CLASS\"\n","            )\n","\n","        return df_filtered\n","\n","    def create_label_mapping(self, df):\n","        \"\"\"\n","        Crea mapeo de etiquetas a √≠ndices\n","\n","        Args:\n","            df: DataFrame\n","\n","        Returns:\n","            tuple: (df_with_labels, label2id, id2label)\n","        \"\"\"\n","        self.logger.info(\"Creando mapeo de etiquetas...\")\n","\n","        # Obtener clases √∫nicas ordenadas\n","        unique_labels = sorted(df[self.config.TARGET_COLUMN].unique())\n","\n","        # Crear mapeos\n","        label2id = {label: idx for idx, label in enumerate(unique_labels)}\n","        id2label = {idx: label for label, idx in label2id.items()}\n","\n","        # Agregar columna de √≠ndices num√©ricos\n","        df['label_id'] = df[self.config.TARGET_COLUMN].map(label2id)\n","\n","        # Verificar que no hay nulos (no deber√≠a pasar)\n","        if df['label_id'].isna().any():\n","            raise ValueError(\"‚ùå Error en el mapeo de etiquetas\")\n","\n","        self.logger.info(\n","            f\"‚úÖ Mapeo creado: {len(label2id)} clases (√≠ndices 0-{len(label2id)-1})\"\n","        )\n","\n","        # Mostrar distribuci√≥n de clases\n","        class_dist = df[self.config.TARGET_COLUMN].value_counts()\n","        self.logger.info(\n","            f\"   Clase m√°s frecuente: {class_dist.index[0]} ({class_dist.iloc[0]:,} muestras)\\n\"\n","            f\"   Clase menos frecuente: {class_dist.index[-1]} ({class_dist.iloc[-1]:,} muestras)\\n\"\n","            f\"   Promedio por clase: {class_dist.mean():.1f}\"\n","        )\n","\n","        return df, label2id, id2label\n","\n","    def split_data(self, df):\n","        \"\"\"\n","        Divide datos en train, validation y test con estratificaci√≥n\n","\n","        Args:\n","            df: DataFrame\n","\n","        Returns:\n","            tuple: (train_df, val_df, test_df)\n","        \"\"\"\n","        self.logger.info(\"Dividiendo datos...\")\n","\n","        try:\n","            # Primero separar test\n","            train_val, test = train_test_split(\n","                df,\n","                test_size=self.config.TEST_SIZE,\n","                random_state=self.config.RANDOM_STATE,\n","                stratify=df['label_id']\n","            )\n","\n","            # Luego separar train y validation\n","            val_size_adjusted = self.config.VAL_SIZE / (1 - self.config.TEST_SIZE)\n","            train, val = train_test_split(\n","                train_val,\n","                test_size=val_size_adjusted,\n","                random_state=self.config.RANDOM_STATE,\n","                stratify=train_val['label_id']\n","            )\n","\n","            self.logger.info(\n","                f\"‚úÖ Divisi√≥n completada:\\n\"\n","                f\"   Train: {len(train):,} ({len(train)/len(df)*100:.1f}%)\\n\"\n","                f\"   Validation: {len(val):,} ({len(val)/len(df)*100:.1f}%)\\n\"\n","                f\"   Test: {len(test):,} ({len(test)/len(df)*100:.1f}%)\"\n","            )\n","\n","            return train, val, test\n","\n","        except ValueError as e:\n","            self.logger.error(\n","                f\"‚ùå Error al dividir datos: {str(e)}\\n\"\n","                f\"   Puede ser que algunas clases tengan muy pocas muestras\\n\"\n","                f\"   Considera aumentar MIN_SAMPLES_PER_CLASS\"\n","            )\n","            raise\n","\n","\n","# ============================================================================\n","# EJECUTAR CARGA DE DATOS\n","# ============================================================================\n","\n","print(\"\\n\" + \"=\"*80)\n","print(\"üìÇ CARGANDO Y PREPARANDO DATOS\")\n","print(\"=\"*80 + \"\\n\")\n","\n","try:\n","    # Inicializar cargador\n","    data_loader = DataLoader(config)\n","\n","    # Cargar datos\n","    df_raw = data_loader.load_data()\n","\n","    # Validar estructura\n","    data_loader.validate_data(df_raw)\n","\n","    # Filtrar registros v√°lidos\n","    df_valid = data_loader.filter_valid_records(df_raw)\n","\n","    # Filtrar clases raras\n","    df_filtered = data_loader.filter_rare_classes(df_valid)\n","\n","    # Crear mapeo de etiquetas\n","    df_final, label2id, id2label = data_loader.create_label_mapping(df_filtered)\n","\n","    # Dividir datos\n","    train_df, val_df, test_df = data_loader.split_data(df_final)\n","\n","    print(\"\\n\" + \"=\"*80)\n","    print(\"‚úÖ DATOS PREPARADOS EXITOSAMENTE\")\n","    print(\"=\"*80 + \"\\n\")\n","\n","    # Guardar informaci√≥n de las clases\n","    class_info = {\n","        'num_classes': len(label2id),\n","        'label2id': label2id,\n","        'id2label': id2label,\n","        'class_distribution': df_final[config.TARGET_COLUMN].value_counts().to_dict()\n","    }\n","\n","    with open(os.path.join(config.OUTPUT_DIR, 'class_info.json'), 'w', encoding='utf-8') as f:\n","        json.dump(class_info, f, indent=2, ensure_ascii=False)\n","\n","except Exception as e:\n","    print(\"\\n\" + \"=\"*80)\n","    print(\"‚ùå ERROR EN LA CARGA DE DATOS\")\n","    print(\"=\"*80)\n","    print(f\"\\n{str(e)}\\n\")\n","    print(\"Por favor, revisa:\")\n","    print(\"1. La ruta del archivo en ModelConfig.DATA_PATH\")\n","    print(\"2. Los nombres de columnas en TEXT_COLUMN y TARGET_COLUMN\")\n","    print(\"3. La calidad de tus datos (nulos, vac√≠os, etc.)\")\n","    print(\"\\n\" + \"=\"*80 + \"\\n\")\n","    raise\n"],"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","================================================================================\n","üìÇ CARGANDO Y PREPARANDO DATOS\n","================================================================================\n","\n","\n","================================================================================\n","‚úÖ DATOS PREPARADOS EXITOSAMENTE\n","================================================================================\n","\n"]}],"id":"qfG0DkcRIKbt"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":544,"referenced_widgets":["32bae97cace44aabb0dc03ad08588d09","fc02c43bfbd141e6a757113b8ef4b6b4","87db80cc1dff4f37bdcbcd3b45796290","272882e7331f4da7be0230e599d9e867","99fbb1306d30488c9307d4b5806ba6db","d2a3184597644764a7cc34a1df13a3fd","25bc6d6813954c3d8a3aa0d956cde4c3","a0be01901f9944b5a85223df2590cf9b","cb5c23760624453d982d0dffe7855f17","c3ecb479e8f2414090d688d54f540ef0","ae54ed7928ce47239ba7f5159461309e","cad02f843ae7463f9416ab49ecd9f70c","09bc69c015ce45b29aa1f729a75f48e1","d4443d28a9cb492b98fb282695fef0d9","97952aa0e7524bc1b2454126f168d8e4","c5c5d604ca3343f8b36a8522d4f99da6","2fbeba450b864c779b47a69c3ad967b2","c41b53d575034f63aba6b519c7a51e8c","42a8fbb19c964fa4b332eb97f40f2a2f","f8cf6b9f78e245129b343c2d368af8b9","6241638fcb6f406498b5d65fc33a7362","f04e82680e45493e88988aec46103590","91d50cdb9c77454eb1c9cdf7fbca2c25","9558fbf395aa44209ac2318f7566ab54","628642a94cd040c6b9580c800183b692","728b9edd48df45879eefd69c0daf3bb0","da9a944371c941a5b6a410e3f41dfe89","5c7c89932a0d4544aea8f21c2c208de9","b220144bcb51405da3f607910e066328","27d809132f5142f98655e2648da11dc6","4b3192c8942d4fa4a642b7f4abfb8b24","9915a04f3ca946119ac3e5ead7689f8f","280ac7237b5d496d8501c40758c551f9","95a3574877904eb88b3d2c188c90fd59","c1875c95a7ae42ad8bf3ff994f8f75d6","83a5c3ce94f9457ea94da8e254dd998a","16652eb12aaf4a1aac23ebc0b46c5322","f67096bcd49d4ca0ad2649f1d7718b28","cc842f1a529149d1b2251ae6a04b2bf8","dda99051c5dc48cbb17499e902175ccd","259bf166c2204b8ca98d8fefc92d55a2","0d5b30eb06684c9ebfe928c8555fdfdc","f6ef00970aeb49a18835153faf48bfd7","67e1072170a8418da3ebf0a8f770776b"]},"id":"K4LnQZmXIKbv","executionInfo":{"status":"ok","timestamp":1762972125458,"user_tz":300,"elapsed":4802,"user":{"displayName":"Jesbil Betsy Valladolid Garcia","userId":"11256541342152996128"}},"outputId":"16d1807d-14dd-4c7d-be69-50e3155d0a84"},"source":["# ============================================================================\n","# üî§ DATASET Y TOKENIZACI√ìN\n","# ============================================================================\n","\n","class TextClassificationDataset(Dataset):\n","    \"\"\"\n","    Dataset personalizado para clasificaci√≥n de texto\n","    Compatible con cualquier modelo de Hugging Face\n","    \"\"\"\n","\n","    def __init__(self, texts, labels, tokenizer, max_length):\n","        \"\"\"\n","        Args:\n","            texts: Lista de textos\n","            labels: Lista de etiquetas (√≠ndices num√©ricos)\n","            tokenizer: Tokenizer de Hugging Face\n","            max_length: Longitud m√°xima de tokens\n","        \"\"\"\n","        self.texts = texts\n","        self.labels = labels\n","        self.tokenizer = tokenizer\n","        self.max_length = max_length\n","\n","    def __len__(self):\n","        return len(self.texts)\n","\n","    def __getitem__(self, idx):\n","        \"\"\"\n","        Obtiene un ejemplo tokenizado\n","\n","        Returns:\n","            dict: Diccionario con input_ids, attention_mask y labels\n","        \"\"\"\n","        text = str(self.texts[idx])\n","        label = int(self.labels[idx])\n","\n","        # Tokenizar\n","        encoding = self.tokenizer(\n","            text,\n","            max_length=self.max_length,\n","            padding='max_length',\n","            truncation=True,\n","            return_tensors='pt'\n","        )\n","\n","        return {\n","            'input_ids': encoding['input_ids'].flatten(),\n","            'attention_mask': encoding['attention_mask'].flatten(),\n","            'labels': torch.tensor(label, dtype=torch.long)\n","        }\n","\n","\n","# ============================================================================\n","# INICIALIZAR TOKENIZER Y DATASETS\n","# ============================================================================\n","\n","print(\"\\n\" + \"=\"*80)\n","print(\"üî§ INICIALIZANDO TOKENIZER Y DATASETS\")\n","print(\"=\"*80 + \"\\n\")\n","\n","try:\n","    # Cargar tokenizer\n","    config.logger.info(f\"Cargando tokenizer: {config.MODEL_NAME}\")\n","    tokenizer = AutoTokenizer.from_pretrained(config.MODEL_NAME)\n","\n","    print(f\"‚úÖ Tokenizer cargado: {config.MODEL_NAME}\")\n","    print(f\"   Vocabulario: {len(tokenizer):,} tokens\")\n","    print(f\"   Tipo: {tokenizer.__class__.__name__}\")\n","\n","    # Crear datasets\n","    config.logger.info(\"Creando datasets...\")\n","\n","    train_dataset = TextClassificationDataset(\n","        texts=train_df[config.TEXT_COLUMN].tolist(),\n","        labels=train_df['label_id'].tolist(),\n","        tokenizer=tokenizer,\n","        max_length=config.MAX_LENGTH\n","    )\n","\n","    val_dataset = TextClassificationDataset(\n","        texts=val_df[config.TEXT_COLUMN].tolist(),\n","        labels=val_df['label_id'].tolist(),\n","        tokenizer=tokenizer,\n","        max_length=config.MAX_LENGTH\n","    )\n","\n","    test_dataset = TextClassificationDataset(\n","        texts=test_df[config.TEXT_COLUMN].tolist(),\n","        labels=test_df['label_id'].tolist(),\n","        tokenizer=tokenizer,\n","        max_length=config.MAX_LENGTH\n","    )\n","\n","    print(f\"\\n‚úÖ Datasets creados:\")\n","    print(f\"   Train: {len(train_dataset):,} ejemplos\")\n","    print(f\"   Validation: {len(val_dataset):,} ejemplos\")\n","    print(f\"   Test: {len(test_dataset):,} ejemplos\")\n","\n","    # Verificar un ejemplo\n","    sample = train_dataset[0]\n","    print(f\"\\nüìù Ejemplo de muestra tokenizada:\")\n","    print(f\"   Input IDs shape: {sample['input_ids'].shape}\")\n","    print(f\"   Attention mask shape: {sample['attention_mask'].shape}\")\n","    print(f\"   Label: {sample['labels'].item()}\")\n","\n","    print(\"\\n\" + \"=\"*80)\n","    print(\"‚úÖ TOKENIZACI√ìN COMPLETADA\")\n","    print(\"=\"*80 + \"\\n\")\n","\n","except Exception as e:\n","    print(\"\\n\" + \"=\"*80)\n","    print(\"‚ùå ERROR EN LA TOKENIZACI√ìN\")\n","    print(\"=\"*80)\n","    print(f\"\\n{str(e)}\\n\")\n","    print(\"Posibles causas:\")\n","    print(\"1. El modelo no est√° disponible (verifica MODEL_NAME)\")\n","    print(\"2. No hay conexi√≥n a internet para descargar el tokenizer\")\n","    print(\"3. Problema con los datos de entrada\")\n","    print(\"\\n\" + \"=\"*80 + \"\\n\")\n","    raise\n"],"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","================================================================================\n","üî§ INICIALIZANDO TOKENIZER Y DATASETS\n","================================================================================\n","\n"]},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"32bae97cace44aabb0dc03ad08588d09"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/615 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cad02f843ae7463f9416ab49ecd9f70c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"91d50cdb9c77454eb1c9cdf7fbca2c25"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json: 0.00B [00:00, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"95a3574877904eb88b3d2c188c90fd59"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["‚úÖ Tokenizer cargado: FacebookAI/xlm-roberta-base\n","   Vocabulario: 250,002 tokens\n","   Tipo: XLMRobertaTokenizerFast\n","\n","‚úÖ Datasets creados:\n","   Train: 220,937 ejemplos\n","   Validation: 47,344 ejemplos\n","   Test: 47,344 ejemplos\n","\n","üìù Ejemplo de muestra tokenizada:\n","   Input IDs shape: torch.Size([128])\n","   Attention mask shape: torch.Size([128])\n","   Label: 356\n","\n","================================================================================\n","‚úÖ TOKENIZACI√ìN COMPLETADA\n","================================================================================\n","\n"]}],"id":"K4LnQZmXIKbv"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EcEm9PKOIKbw","executionInfo":{"status":"ok","timestamp":1762972125545,"user_tz":300,"elapsed":11,"user":{"displayName":"Jesbil Betsy Valladolid Garcia","userId":"11256541342152996128"}},"outputId":"2bd8b26c-368b-4279-9063-ac355e0261c8"},"source":["# ============================================================================\n","# üìä M√âTRICAS DETALLADAS\n","# ============================================================================\n","\n","def compute_detailed_metrics(eval_pred):\n","    \"\"\"\n","    Calcula m√©tricas detalladas: Accuracy, Precision, Recall, F1\n","    Con variantes: macro, micro y weighted\n","\n","    Args:\n","        eval_pred: Predicciones del modelo (predictions, label_ids)\n","\n","    Returns:\n","        dict: Diccionario con todas las m√©tricas\n","    \"\"\"\n","    predictions, labels = eval_pred\n","\n","    # Obtener predicciones (argmax si son logits)\n","    if predictions.ndim > 1:\n","        preds = np.argmax(predictions, axis=1)\n","    else:\n","        preds = predictions\n","\n","    # Accuracy\n","    accuracy = accuracy_score(labels, preds)\n","\n","    # Precision, Recall, F1 con diferentes promedios\n","    # Macro: promedio sin ponderar (todas las clases tienen el mismo peso)\n","    precision_macro, recall_macro, f1_macro, _ = precision_recall_fscore_support(\n","        labels, preds, average='macro', zero_division=0\n","    )\n","\n","    # Micro: agregado global (considera todas las muestras por igual)\n","    precision_micro, recall_micro, f1_micro, _ = precision_recall_fscore_support(\n","        labels, preds, average='micro', zero_division=0\n","    )\n","\n","    # Weighted: promedio ponderado por soporte de cada clase\n","    precision_weighted, recall_weighted, f1_weighted, _ = precision_recall_fscore_support(\n","        labels, preds, average='weighted', zero_division=0\n","    )\n","\n","    return {\n","        # Accuracy (solo una versi√≥n)\n","        'accuracy': accuracy,\n","\n","        # F1 Score\n","        'f1_macro': f1_macro,\n","        'f1_micro': f1_micro,\n","        'f1_weighted': f1_weighted,\n","\n","        # Precision\n","        'precision_macro': precision_macro,\n","        'precision_micro': precision_micro,\n","        'precision_weighted': precision_weighted,\n","\n","        # Recall\n","        'recall_macro': recall_macro,\n","        'recall_micro': recall_micro,\n","        'recall_weighted': recall_weighted,\n","    }\n","\n","\n","\n","def display_metrics(metrics, title=\"M√©tricas\"):\n","    \"\"\"Muestra las m√©tricas de forma organizada\"\"\"\n","    print(\"\\n\" + \"=\"*80)\n","    print(f\"üìä {title.upper()}\")\n","    print(\"=\"*80 + \"\\n\")\n","\n","    # Mostrar Loss si existe\n","    loss = (\n","        metrics.get('test_loss') or\n","        metrics.get('eval_loss') or\n","        metrics.get('loss', None)\n","    )\n","    if loss is not None:\n","        print(f\"üí• LOSS: {loss:.4f}\")\n","\n","    # Accuracy\n","    acc = (\n","        metrics.get('test_accuracy') or\n","        metrics.get('eval_accuracy') or\n","        metrics.get('accuracy', 0)\n","    )\n","    print(f\"üéØ ACCURACY: {acc:.4f}\")\n","    print(\"\\n\" + \"-\"*80)\n","\n","    # Tabla\n","    print(f\"\\n{'M√©trica':<20} {'Macro':>12} {'Micro':>12} {'Weighted':>12}\")\n","    print(\"-\"*60)\n","\n","    def get_m(name):\n","        return (\n","            metrics.get(f'test_{name}') or\n","            metrics.get(f'eval_{name}') or\n","            metrics.get(name, 0)\n","        )\n","\n","    print(f\"{'F1 Score':<20} {get_m('f1_macro'):>12.4f} {get_m('f1_micro'):>12.4f} {get_m('f1_weighted'):>12.4f}\")\n","    print(f\"{'Precision':<20} {get_m('precision_macro'):>12.4f} {get_m('precision_micro'):>12.4f} {get_m('precision_weighted'):>12.4f}\")\n","    print(f\"{'Recall':<20} {get_m('recall_macro'):>12.4f} {get_m('recall_micro'):>12.4f} {get_m('recall_weighted'):>12.4f}\")\n","\n","    print(\"\\n\" + \"=\"*80 + \"\\n\")\n","\n","\n","print(\"‚úÖ Funciones de m√©tricas cargadas (con loss incluido)\")\n"],"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["‚úÖ Funciones de m√©tricas cargadas (con loss incluido)\n"]}],"id":"EcEm9PKOIKbw"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":399,"referenced_widgets":["3209b1138d2146d9a1568529e3963592","9ef71108f1314133b08835cb0f1ca859","8c30fdb441514ab3aff6665be5d31c6b","a2c438f121554f528a7b871f76179bc5","0c951e26f6704ec6a684b6231f96ccac","e6918e58440b453bb8b77e3e8e435650","45fe822eb2d14c06ba7cccf6bf5f82d7","168b7e1435e7433c8411c1b26c349d5d","95159ed217984eb7bc1f2fb1d66f6bc6","859104f788034bc2abd43f1869641d4d","158f7ea3dfed4e258fa382b134843c6b"]},"id":"qXtQxEM-IKbw","executionInfo":{"status":"ok","timestamp":1762972138620,"user_tz":300,"elapsed":13079,"user":{"displayName":"Jesbil Betsy Valladolid Garcia","userId":"11256541342152996128"}},"outputId":"d849c427-7bc0-40e6-a7ad-170e0317eb18"},"source":["# ============================================================================\n","# ü§ñ INICIALIZACI√ìN DEL MODELO\n","# ============================================================================\n","\n","print(\"\\n\" + \"=\"*80)\n","print(\"ü§ñ INICIALIZANDO MODELO\")\n","print(\"=\"*80 + \"\\n\")\n","\n","try:\n","    config.logger.info(f\"Cargando modelo: {config.MODEL_NAME}\")\n","\n","    # Cargar modelo\n","    model = AutoModelForSequenceClassification.from_pretrained(\n","        config.MODEL_NAME,\n","        num_labels=len(label2id),\n","        id2label=id2label,\n","        label2id=label2id,\n","        problem_type=\"single_label_classification\"\n","    )\n","\n","    # Mover a GPU si est√° disponible\n","    model.to(config.DEVICE)\n","\n","    # Informaci√≥n del modelo\n","    num_params = sum(p.numel() for p in model.parameters())\n","    num_trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n","\n","    print(f\"‚úÖ Modelo cargado: {config.MODEL_NAME}\")\n","    print(f\"   Tipo: {model.__class__.__name__}\")\n","    print(f\"   N√∫mero de clases: {len(label2id)}\")\n","    print(f\"   Par√°metros totales: {num_params:,}\")\n","    print(f\"   Par√°metros entrenables: {num_trainable:,}\")\n","    print(f\"   Dispositivo: {config.DEVICE}\")\n","\n","    if torch.cuda.is_available():\n","        print(f\"   Memoria GPU asignada: {torch.cuda.memory_allocated(0) / 1e9:.2f} GB\")\n","\n","    config.logger.info(f\"Modelo inicializado con {num_params:,} par√°metros\")\n","\n","    print(\"\\n\" + \"=\"*80)\n","    print(\"‚úÖ MODELO LISTO PARA ENTRENAMIENTO\")\n","    print(\"=\"*80 + \"\\n\")\n","\n","except Exception as e:\n","    print(\"\\n\" + \"=\"*80)\n","    print(\"‚ùå ERROR AL CARGAR EL MODELO\")\n","    print(\"=\"*80)\n","    print(f\"\\n{str(e)}\\n\")\n","    print(\"Posibles causas:\")\n","    print(\"1. El nombre del modelo es incorrecto\")\n","    print(\"2. No hay conexi√≥n a internet para descargar el modelo\")\n","    print(\"3. No hay suficiente memoria GPU/RAM\")\n","    print(\"4. Incompatibilidad de versiones de transformers\")\n","    print(\"\\nModelos v√°lidos:\")\n","    print(\"- FacebookAI/xlm-roberta-base\")\n","    print(\"- dccuchile/bert-base-spanish-wwm-cased\")\n","    print(\"\\n\" + \"=\"*80 + \"\\n\")\n","    raise\n"],"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","================================================================================\n","ü§ñ INICIALIZANDO MODELO\n","================================================================================\n","\n"]},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/1.12G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3209b1138d2146d9a1568529e3963592"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["‚úÖ Modelo cargado: FacebookAI/xlm-roberta-base\n","   Tipo: XLMRobertaForSequenceClassification\n","   N√∫mero de clases: 357\n","   Par√°metros totales: 278,318,181\n","   Par√°metros entrenables: 278,318,181\n","   Dispositivo: cuda\n","   Memoria GPU asignada: 1.11 GB\n","\n","================================================================================\n","‚úÖ MODELO LISTO PARA ENTRENAMIENTO\n","================================================================================\n","\n"]}],"id":"qXtQxEM-IKbw"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"W_6d3qt-IKbx","executionInfo":{"status":"ok","timestamp":1762972138758,"user_tz":300,"elapsed":118,"user":{"displayName":"Jesbil Betsy Valladolid Garcia","userId":"11256541342152996128"}},"outputId":"dc85718a-574f-4eef-cc6d-eb074c84d30d"},"source":["# ============================================================================\n","# ‚öôÔ∏è  CONFIGURACI√ìN DEL ENTRENAMIENTO\n","# ============================================================================\n","\n","print(\"\\n\" + \"=\"*80)\n","print(\"‚öôÔ∏è  CONFIGURANDO ENTRENAMIENTO\")\n","print(\"=\"*80 + \"\\n\")\n","\n","# Configuraci√≥n de argumentos de entrenamiento\n","training_args = TrainingArguments(\n","    # Directorios\n","    output_dir=config.CHECKPOINT_DIR,\n","    logging_dir=os.path.join(config.OUTPUT_DIR, 'logs'),\n","\n","    # Hiperpar√°metros\n","    learning_rate=config.LEARNING_RATE,\n","    per_device_train_batch_size=config.BATCH_SIZE,\n","    per_device_eval_batch_size=config.BATCH_SIZE,\n","    num_train_epochs=config.NUM_EPOCHS,\n","    warmup_steps=config.WARMUP_STEPS,\n","    weight_decay=config.WEIGHT_DECAY,\n","\n","    # Evaluaci√≥n y guardado\n","    eval_strategy=\"epoch\",\n","    save_strategy=\"epoch\",\n","    load_best_model_at_end=True,\n","    metric_for_best_model=\"f1_weighted\",  # Usar F1 weighted como m√©trica principal\n","    greater_is_better=True,\n","\n","    # Logging\n","    logging_steps=100,\n","    logging_strategy=\"steps\",\n","\n","    # Optimizaci√≥n\n","    fp16=torch.cuda.is_available(),  # Precisi√≥n mixta si hay GPU\n","    gradient_accumulation_steps=1,\n","\n","    # Otros\n","    seed=config.RANDOM_STATE,\n","    report_to=\"none\",  # Desactivar reportes externos\n","    disable_tqdm=False,  # Mantener barra de progreso\n",")\n","\n","# Inicializar Trainer\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=train_dataset,\n","    eval_dataset=val_dataset,\n","    compute_metrics=compute_detailed_metrics,\n","    callbacks=[\n","        EarlyStoppingCallback(\n","            early_stopping_patience=config.EARLY_STOPPING_PATIENCE\n","        )\n","    ]\n",")\n","\n","print(\"‚úÖ Configuraci√≥n de entrenamiento:\")\n","print(f\"   Learning rate: {config.LEARNING_RATE}\")\n","print(f\"   Batch size: {config.BATCH_SIZE}\")\n","print(f\"   Epochs: {config.NUM_EPOCHS}\")\n","print(f\"   Warmup steps: {config.WARMUP_STEPS}\")\n","print(f\"   Early stopping: {config.EARLY_STOPPING_PATIENCE} epochs\")\n","print(f\"   FP16 (mixed precision): {training_args.fp16}\")\n","print(f\"   M√©trica principal: f1_weighted\")\n","\n","print(\"\\n\" + \"=\"*80)\n","print(\"‚úÖ TRAINER CONFIGURADO Y LISTO\")\n","print(\"=\"*80 + \"\\n\")\n","\n","config.logger.info(\"Trainer configurado correctamente\")\n"],"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","================================================================================\n","‚öôÔ∏è  CONFIGURANDO ENTRENAMIENTO\n","================================================================================\n","\n","‚úÖ Configuraci√≥n de entrenamiento:\n","   Learning rate: 2e-05\n","   Batch size: 16\n","   Epochs: 3\n","   Warmup steps: 500\n","   Early stopping: 3 epochs\n","   FP16 (mixed precision): True\n","   M√©trica principal: f1_weighted\n","\n","================================================================================\n","‚úÖ TRAINER CONFIGURADO Y LISTO\n","================================================================================\n","\n"]}],"id":"W_6d3qt-IKbx"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"Xk-wOW2lIKbx","executionInfo":{"status":"ok","timestamp":1762979630553,"user_tz":300,"elapsed":7491779,"user":{"displayName":"Jesbil Betsy Valladolid Garcia","userId":"11256541342152996128"}},"outputId":"3b5c8112-d8f3-4df9-9132-344a89a4d766"},"source":["# ============================================================================\n","# üöÄ ENTRENAMIENTO DEL MODELO\n","# ============================================================================\n","\n","print(\"\\n\" + \"=\"*80)\n","print(\"üöÄ INICIANDO ENTRENAMIENTO\")\n","print(\"=\"*80)\n","print(f\"\\nModelo: {config.MODEL_NAME}\")\n","print(f\"Datos de entrenamiento: {len(train_dataset):,} ejemplos\")\n","print(f\"Datos de validaci√≥n: {len(val_dataset):,} ejemplos\")\n","print(f\"\\nEsto puede tomar varios minutos/horas dependiendo de:\")\n","print(\"  - Tama√±o del dataset\")\n","print(\"  - N√∫mero de √©pocas\")\n","print(\"  - Hardware disponible (GPU/CPU)\")\n","print(\"\\n\" + \"=\"*80 + \"\\n\")\n","\n","try:\n","    # Registrar inicio\n","    start_time = datetime.now()\n","    config.logger.info(\"Iniciando entrenamiento...\")\n","\n","    # ENTRENAR\n","    train_result = trainer.train()\n","\n","    # Registrar finalizaci√≥n\n","    end_time = datetime.now()\n","    training_time = end_time - start_time\n","\n","    config.logger.info(f\"Entrenamiento completado en {training_time}\")\n","\n","    print(\"\\n\" + \"=\"*80)\n","    print(\"‚úÖ ENTRENAMIENTO COMPLETADO\")\n","    print(\"=\"*80)\n","    print(f\"\\nTiempo total: {training_time}\")\n","    print(f\"Mejor modelo guardado en: {config.CHECKPOINT_DIR}\")\n","\n","    # Mostrar m√©tricas finales de entrenamiento\n","    print(f\"\\nüìä M√©tricas finales de entrenamiento:\")\n","    print(f\"   Training loss: {train_result.training_loss:.4f}\")\n","\n","    # Evaluar en validation set\n","    print(\"\\n\" + \"-\"*80)\n","    print(\"üìä Evaluando en conjunto de validaci√≥n...\")\n","    val_metrics = trainer.evaluate()\n","    display_metrics(val_metrics, \"M√©tricas de Validaci√≥n\")\n","\n","    print(\"=\"*80 + \"\\n\")\n","\n","except KeyboardInterrupt:\n","    print(\"\\n\" + \"=\"*80)\n","    print(\"‚ö†Ô∏è  ENTRENAMIENTO INTERRUMPIDO POR EL USUARIO\")\n","    print(\"=\"*80)\n","    print(\"\\nEl modelo puede haber sido parcialmente entrenado.\")\n","    print(\"Los checkpoints guardados est√°n disponibles en:\")\n","    print(f\"  {config.CHECKPOINT_DIR}\")\n","    print(\"\\n\" + \"=\"*80 + \"\\n\")\n","    raise\n","\n","except Exception as e:\n","    print(\"\\n\" + \"=\"*80)\n","    print(\"‚ùå ERROR DURANTE EL ENTRENAMIENTO\")\n","    print(\"=\"*80)\n","    print(f\"\\n{str(e)}\\n\")\n","    print(\"Posibles causas:\")\n","    print(\"1. Memoria insuficiente (GPU/RAM)\")\n","    print(\"   Soluci√≥n: Reduce BATCH_SIZE en ModelConfig\")\n","    print(\"2. Datos corruptos o formato incorrecto\")\n","    print(\"3. Incompatibilidad de versiones\")\n","    print(\"\\nRevisa el archivo de log para m√°s detalles:\")\n","    print(f\"  {os.path.join(config.OUTPUT_DIR, 'training_*.log')}\")\n","    print(\"\\n\" + \"=\"*80 + \"\\n\")\n","    config.logger.error(f\"Error en entrenamiento: {str(e)}\", exc_info=True)\n","    raise\n"],"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","================================================================================\n","üöÄ INICIANDO ENTRENAMIENTO\n","================================================================================\n","\n","Modelo: FacebookAI/xlm-roberta-base\n","Datos de entrenamiento: 220,937 ejemplos\n","Datos de validaci√≥n: 47,344 ejemplos\n","\n","Esto puede tomar varios minutos/horas dependiendo de:\n","  - Tama√±o del dataset\n","  - N√∫mero de √©pocas\n","  - Hardware disponible (GPU/CPU)\n","\n","================================================================================\n","\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='41427' max='41427' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [41427/41427 2:02:59, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1 Macro</th>\n","      <th>F1 Micro</th>\n","      <th>F1 Weighted</th>\n","      <th>Precision Macro</th>\n","      <th>Precision Micro</th>\n","      <th>Precision Weighted</th>\n","      <th>Recall Macro</th>\n","      <th>Recall Micro</th>\n","      <th>Recall Weighted</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.354800</td>\n","      <td>0.373263</td>\n","      <td>0.919229</td>\n","      <td>0.414479</td>\n","      <td>0.919229</td>\n","      <td>0.908641</td>\n","      <td>0.429819</td>\n","      <td>0.919229</td>\n","      <td>0.905562</td>\n","      <td>0.427376</td>\n","      <td>0.919229</td>\n","      <td>0.919229</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.315000</td>\n","      <td>0.308430</td>\n","      <td>0.932663</td>\n","      <td>0.514334</td>\n","      <td>0.932663</td>\n","      <td>0.927288</td>\n","      <td>0.532307</td>\n","      <td>0.932663</td>\n","      <td>0.926565</td>\n","      <td>0.529108</td>\n","      <td>0.932663</td>\n","      <td>0.932663</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.296300</td>\n","      <td>0.292726</td>\n","      <td>0.937310</td>\n","      <td>0.548037</td>\n","      <td>0.937310</td>\n","      <td>0.933028</td>\n","      <td>0.561578</td>\n","      <td>0.937310</td>\n","      <td>0.931313</td>\n","      <td>0.557026</td>\n","      <td>0.937310</td>\n","      <td>0.937310</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","================================================================================\n","‚úÖ ENTRENAMIENTO COMPLETADO\n","================================================================================\n","\n","Tiempo total: 2:03:02.044670\n","Mejor modelo guardado en: /content/drive/MyDrive/PI_PEU/xlmRoberta/xlm-roberta-base_20251112_182822/checkpoints\n","\n","üìä M√©tricas finales de entrenamiento:\n","   Training loss: 0.4604\n","\n","--------------------------------------------------------------------------------\n","üìä Evaluando en conjunto de validaci√≥n...\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='2959' max='2959' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2959/2959 01:49]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","================================================================================\n","üìä M√âTRICAS DE VALIDACI√ìN\n","================================================================================\n","\n","üí• LOSS: 0.2927\n","üéØ ACCURACY: 0.9373\n","\n","--------------------------------------------------------------------------------\n","\n","M√©trica                     Macro        Micro     Weighted\n","------------------------------------------------------------\n","F1 Score                   0.5480       0.9373       0.9330\n","Precision                  0.5616       0.9373       0.9313\n","Recall                     0.5570       0.9373       0.9373\n","\n","================================================================================\n","\n","================================================================================\n","\n"]}],"id":"Xk-wOW2lIKbx"},{"cell_type":"code","metadata":{"id":"IzyrUTD6IKby","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1762979734879,"user_tz":300,"elapsed":104323,"user":{"displayName":"Jesbil Betsy Valladolid Garcia","userId":"11256541342152996128"}},"outputId":"2c6abea7-0759-4e16-e161-03ea39ec5b09"},"source":["# ============================================================================\n","# üß™ EVALUACI√ìN EN TEST SET\n","# ============================================================================\n","\n","print(\"\\n\" + \"=\"*80)\n","print(\"üß™ EVALUACI√ìN EN TEST SET\")\n","print(\"=\"*80 + \"\\n\")\n","\n","try:\n","    config.logger.info(\"Evaluando en test set...\")\n","\n","    # Obtener predicciones en test set\n","    test_predictions = trainer.predict(test_dataset)\n","\n","    # Extraer m√©tricas\n","    test_metrics = test_predictions.metrics\n","\n","    # Mostrar m√©tricas\n","    display_metrics(test_metrics, \"M√©tricas de Test (Evaluaci√≥n Final)\")\n","\n","    # Guardar m√©tricas en archivo\n","    metrics_file = os.path.join(config.OUTPUT_DIR, 'test_metrics.json')\n","    with open(metrics_file, 'w', encoding='utf-8') as f:\n","        json.dump(test_metrics, f, indent=2)\n","\n","    config.logger.info(f\"M√©tricas de test guardadas en: {metrics_file}\")\n","\n","    # ========================================================================\n","    # AN√ÅLISIS DETALLADO\n","    # ========================================================================\n","\n","    print(\"\\n\" + \"=\"*80)\n","    print(\"üìà AN√ÅLISIS DETALLADO\")\n","    print(\"=\"*80 + \"\\n\")\n","\n","    # Obtener predicciones y etiquetas verdaderas\n","    y_pred = np.argmax(test_predictions.predictions, axis=1)\n","    y_true = test_predictions.label_ids\n","\n","    # Reporte de clasificaci√≥n por clase\n","    print(\"üìä Reporte de Clasificaci√≥n por Clase:\\n\")\n","\n","    # Crear reporte con nombres de clases\n","    target_names = [id2label[i] for i in range(len(id2label))]\n","    class_report = classification_report(\n","        y_true,\n","        y_pred,\n","        target_names=target_names,\n","        zero_division=0,\n","        digits=4\n","    )\n","    print(class_report)\n","\n","    # Guardar reporte completo\n","    report_file = os.path.join(config.OUTPUT_DIR, 'classification_report.txt')\n","    with open(report_file, 'w', encoding='utf-8') as f:\n","        f.write(\"REPORTE DE CLASIFICACI√ìN - TEST SET\\n\")\n","        f.write(\"=\"*80 + \"\\n\\n\")\n","        f.write(f\"Modelo: {config.MODEL_NAME}\\n\")\n","        f.write(f\"Fecha: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n","        f.write(f\"Dataset: {config.DATA_PATH}\\n\")\n","        f.write(\"\\n\" + \"=\"*80 + \"\\n\\n\")\n","        f.write(class_report)\n","\n","    print(f\"\\n‚úÖ Reporte completo guardado en: {report_file}\")\n","\n","    # ========================================================================\n","    # AN√ÅLISIS DE ERRORES\n","    # ========================================================================\n","\n","    print(\"\\n\" + \"=\"*80)\n","    print(\"üîç AN√ÅLISIS DE ERRORES\")\n","    print(\"=\"*80 + \"\\n\")\n","\n","    # Identificar predicciones incorrectas\n","    incorrect_mask = y_pred != y_true\n","    num_incorrect = incorrect_mask.sum()\n","    error_rate = num_incorrect / len(y_true) * 100\n","\n","    print(f\"Total de predicciones: {len(y_true):,}\")\n","    print(f\"Predicciones correctas: {(~incorrect_mask).sum():,}\")\n","    print(f\"Predicciones incorrectas: {num_incorrect:,}\")\n","    print(f\"Tasa de error: {error_rate:.2f}%\")\n","\n","    # Crear DataFrame con errores\n","    errors_df = test_df[incorrect_mask].copy()\n","    errors_df['predicted_label'] = [id2label[pred] for pred in y_pred[incorrect_mask]]\n","    errors_df['true_label'] = [id2label[true] for true in y_true[incorrect_mask]]\n","    errors_df['predicted_id'] = y_pred[incorrect_mask]\n","    errors_df['true_id'] = y_true[incorrect_mask]\n","\n","    # Agregar probabilidades\n","    probs = torch.nn.functional.softmax(torch.tensor(test_predictions.predictions), dim=-1)\n","    max_probs = probs.max(dim=-1).values.numpy()\n","    errors_df['confidence'] = max_probs[incorrect_mask]\n","\n","    # Guardar an√°lisis de errores\n","    errors_file = os.path.join(config.OUTPUT_DIR, 'error_analysis.csv')\n","    errors_df.to_csv(errors_file, index=False, encoding='utf-8')\n","\n","    print(f\"\\n‚úÖ An√°lisis de errores guardado en: {errors_file}\")\n","\n","    # Mostrar clases con m√°s errores\n","    if len(errors_df) > 0:\n","        print(\"\\nüìä Top 10 clases con m√°s errores de predicci√≥n:\")\n","        error_by_class = errors_df['true_label'].value_counts().head(10)\n","        for idx, (clase, count) in enumerate(error_by_class.items(), 1):\n","            print(f\"   {idx}. {clase}: {count} errores\")\n","\n","    print(\"\\n\" + \"=\"*80 + \"\\n\")\n","\n","    config.logger.info(\"Evaluaci√≥n en test completada\")\n","\n","except Exception as e:\n","    print(\"\\n\" + \"=\"*80)\n","    print(\"‚ùå ERROR EN LA EVALUACI√ìN\")\n","    print(\"=\"*80)\n","    print(f\"\\n{str(e)}\\n\")\n","    config.logger.error(f\"Error en evaluaci√≥n: {str(e)}\", exc_info=True)\n","    raise\n"],"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","================================================================================\n","üß™ EVALUACI√ìN EN TEST SET\n","================================================================================\n","\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","================================================================================\n","üìä M√âTRICAS DE TEST (EVALUACI√ìN FINAL)\n","================================================================================\n","\n","üí• LOSS: 0.2929\n","üéØ ACCURACY: 0.9363\n","\n","--------------------------------------------------------------------------------\n","\n","M√©trica                     Macro        Micro     Weighted\n","------------------------------------------------------------\n","F1 Score                   0.5391       0.9363       0.9318\n","Precision                  0.5564       0.9363       0.9303\n","Recall                     0.5488       0.9363       0.9363\n","\n","================================================================================\n","\n","\n","================================================================================\n","üìà AN√ÅLISIS DETALLADO\n","================================================================================\n","\n","üìä Reporte de Clasificaci√≥n por Clase:\n","\n","              precision    recall  f1-score   support\n","\n","        0111     0.0000    0.0000    0.0000         3\n","        0112     0.0000    0.0000    0.0000         2\n","        0120     1.0000    0.7778    0.8750         9\n","        0211     0.5294    1.0000    0.6923         9\n","        0212     0.4000    0.4000    0.4000         5\n","        0213     0.0000    0.0000    0.0000         2\n","        0220     0.9864    1.0000    0.9932       145\n","        0311     1.0000    0.5000    0.6667         6\n","        0312     0.4667    0.8750    0.6087         8\n","        0313     0.0000    0.0000    0.0000         4\n","        1111     0.7143    0.9091    0.8000        11\n","        1113     1.0000    0.6667    0.8000         3\n","        1114     0.7429    0.8966    0.8125        29\n","        1131     0.0000    0.0000    0.0000         2\n","        1133     0.0000    0.0000    0.0000         3\n","        1143     0.0000    0.0000    0.0000         1\n","        1166     0.0000    0.0000    0.0000         3\n","        1167     0.0000    0.0000    0.0000         1\n","        1169     0.0000    0.0000    0.0000         2\n","        1211     0.0000    0.0000    0.0000         2\n","        1221     0.0000    0.0000    0.0000         4\n","        1321     0.0000    0.0000    0.0000         2\n","        1323     0.0000    0.0000    0.0000         2\n","        1341     0.0000    0.0000    0.0000         2\n","        1345     0.8875    1.0000    0.9404        71\n","        1346     1.0000    0.3333    0.5000         3\n","        1422     0.1935    1.0000    0.3243         6\n","        1499     0.0000    0.0000    0.0000         2\n","        2113     0.0000    0.0000    0.0000         3\n","        2114     0.8182    1.0000    0.9000         9\n","        2120     0.0000    0.0000    0.0000         2\n","        2131     0.9286    0.8125    0.8667        16\n","        2132     0.8367    0.9762    0.9011        42\n","        2141     0.9474    0.7826    0.8571        23\n","        2142     0.9889    0.9368    0.9622        95\n","        2143     0.6400    0.7619    0.6957        21\n","        2144     0.7857    0.7333    0.7586        15\n","        2145     0.8000    1.0000    0.8889         8\n","        2146     0.8462    0.9167    0.8800        12\n","        2149     0.8333    0.6667    0.7407        15\n","        2151     0.8000    0.8000    0.8000        10\n","        2152     0.9000    0.9000    0.9000        10\n","        2161     0.6522    0.9375    0.7692        32\n","        2162     0.0000    0.0000    0.0000        15\n","        2163     1.0000    0.2500    0.4000         8\n","        2166     0.8108    0.9524    0.8759        63\n","        2211     0.9623    0.9273    0.9444        55\n","        2212     0.8000    0.8889    0.8421        45\n","        2221     0.8488    1.0000    0.9182       146\n","        2222     0.9600    0.9796    0.9697        49\n","        2240     0.7826    1.0000    0.8780        18\n","        2251     0.9464    0.9815    0.9636        54\n","        2252     0.8333    0.8824    0.8571        17\n","        2254     0.0000    0.0000    0.0000         5\n","        2255     0.5000    1.0000    0.6667         8\n","        2256     0.0000    0.0000    0.0000         1\n","        2257     0.0000    0.0000    0.0000         1\n","        2311     0.9774    0.9630    0.9701       135\n","        2312     0.6154    0.7273    0.6667        11\n","        2320     0.0000    0.0000    0.0000         5\n","        2330     0.9596    0.9819    0.9706       387\n","        2341     0.9880    0.9840    0.9860       501\n","        2342     0.9670    0.9617    0.9644       183\n","        2351     0.6667    0.2222    0.3333         9\n","        2352     1.0000    0.4000    0.5714         5\n","        2353     0.7500    0.4286    0.5455         7\n","        2359     0.7660    0.8244    0.7941       131\n","        2411     0.9112    0.9565    0.9333       161\n","        2412     0.0000    0.0000    0.0000         8\n","        2421     0.5800    0.4028    0.4754        72\n","        2422     0.0000    0.0000    0.0000        11\n","        2431     0.0000    0.0000    0.0000         4\n","        2432     1.0000    0.3333    0.5000         3\n","        2511     0.7097    0.8980    0.7928        49\n","        2512     0.0000    0.0000    0.0000         9\n","        2513     0.0000    0.0000    0.0000         3\n","        2521     0.0000    0.0000    0.0000         4\n","        2611     0.9881    0.9822    0.9852       169\n","        2619     0.6552    0.6552    0.6552        29\n","        2631     0.6957    1.0000    0.8205        16\n","        2632     1.0000    0.6667    0.8000         6\n","        2634     0.9194    0.9828    0.9500        58\n","        2635     0.9375    0.9375    0.9375        16\n","        2636     0.0000    0.0000    0.0000         2\n","        2641     0.0000    0.0000    0.0000         2\n","        2642     0.7333    0.6471    0.6875        17\n","        2643     0.0000    0.0000    0.0000         2\n","        2651     0.6000    0.3333    0.4286         9\n","        2656     0.0000    0.0000    0.0000         2\n","        3111     1.0000    0.1250    0.2222         8\n","        3112     0.6800    0.7969    0.7338        64\n","        3113     0.8706    0.8222    0.8457        90\n","        3114     0.8000    0.6957    0.7442        23\n","        3115     0.9070    0.8182    0.8603       143\n","        3117     0.0000    0.0000    0.0000         4\n","        3118     0.6957    0.8889    0.7805        18\n","        3119     0.0000    0.0000    0.0000         4\n","        3121     0.0000    0.0000    0.0000        10\n","        3122     0.5079    0.7619    0.6095        42\n","        3123     0.6250    0.8333    0.7143        30\n","        3124     0.6190    0.7222    0.6667       126\n","        3125     0.0000    0.0000    0.0000         8\n","        3126     0.0000    0.0000    0.0000         5\n","        3129     0.2667    0.3200    0.2909        25\n","        3131     0.0000    0.0000    0.0000         1\n","        3132     0.0000    0.0000    0.0000         9\n","        3141     0.0000    0.0000    0.0000         5\n","        3142     0.0000    0.0000    0.0000         9\n","        3143     0.0000    0.0000    0.0000         2\n","        3145     0.0000    0.0000    0.0000         2\n","        3149     0.0000    0.0000    0.0000        23\n","        3151     0.0000    0.0000    0.0000         2\n","        3152     0.8000    0.8750    0.8358        32\n","        3153     0.0000    0.0000    0.0000         1\n","        3211     0.0000    0.0000    0.0000         4\n","        3212     0.7500    1.0000    0.8571        30\n","        3213     0.9592    0.9216    0.9400        51\n","        3215     0.0000    0.0000    0.0000         4\n","        3221     0.9793    0.8791    0.9265       215\n","        3230     0.9167    0.9565    0.9362        23\n","        3240     0.3333    0.1250    0.1818         8\n","        3251     0.5909    0.8125    0.6842        16\n","        3253     0.0000    0.0000    0.0000         1\n","        3255     0.5854    1.0000    0.7385        24\n","        3256     0.0000    0.0000    0.0000         6\n","        3257     0.3871    0.3636    0.3750        33\n","        3258     0.0000    0.0000    0.0000         2\n","        3259     0.0000    0.0000    0.0000         4\n","        3313     0.7667    0.6765    0.7188        34\n","        3314     0.8864    0.9407    0.9128       506\n","        3315     0.0000    0.0000    0.0000         4\n","        3316     0.0000    0.0000    0.0000         2\n","        3317     0.5000    0.7500    0.6000        12\n","        3321     0.8333    0.9375    0.8824        16\n","        3322     0.9000    0.8357    0.8667       140\n","        3323     0.7500    0.5000    0.6000         6\n","        3331     0.6667    0.5714    0.6154         7\n","        3332     0.5714    0.5714    0.5714         7\n","        3334     0.8696    0.9091    0.8889        22\n","        3339     0.4706    0.5333    0.5000        15\n","        3341     0.0000    0.0000    0.0000         3\n","        3411     0.7105    0.6923    0.7013        39\n","        3412     0.0000    0.0000    0.0000         2\n","        3413     0.7143    1.0000    0.8333        15\n","        3421     1.0000    1.0000    1.0000        10\n","        3422     0.8537    0.9722    0.9091        36\n","        3423     0.0000    0.0000    0.0000         2\n","        3431     0.8421    0.8889    0.8649        18\n","        3432     1.0000    0.7778    0.8750         9\n","        3434     0.8000    0.5714    0.6667         7\n","        3439     0.8676    0.9672    0.9147        61\n","        3511     0.2045    0.2812    0.2368        32\n","        3512     0.0000    0.0000    0.0000        11\n","        3513     0.4222    0.5000    0.4578        38\n","        3514     0.0000    0.0000    0.0000         6\n","        3521     0.7917    0.7308    0.7600        26\n","        3522     0.0000    0.0000    0.0000         2\n","        3523     0.6667    0.8571    0.7500         7\n","        4110     0.9253    0.8997    0.9123       289\n","        4120     0.9838    0.9891    0.9864       184\n","        4131     0.8333    0.8824    0.8571        17\n","        4132     1.0000    0.9412    0.9697        34\n","        4211     0.7000    0.6512    0.6747        43\n","        4212     0.0000    0.0000    0.0000         5\n","        4213     1.0000    0.8571    0.9231         7\n","        4214     0.9167    0.7857    0.8462        28\n","        4221     0.0000    0.0000    0.0000         9\n","        4222     0.8649    0.9697    0.9143        66\n","        4223     0.8947    0.6800    0.7727        25\n","        4224     0.8824    0.9574    0.9184        94\n","        4225     0.8947    0.8500    0.8718        20\n","        4229     0.0000    0.0000    0.0000         4\n","        4311     0.6667    0.3077    0.4211        13\n","        4312     0.8846    0.9426    0.9127       122\n","        4313     0.0000    0.0000    0.0000         3\n","        4321     0.9358    0.9358    0.9358       218\n","        4323     0.4800    0.6667    0.5581        18\n","        4411     0.9286    1.0000    0.9630        13\n","        4412     1.0000    0.2000    0.3333        10\n","        4414     0.0000    0.0000    0.0000         3\n","        4415     0.7500    0.7500    0.7500         8\n","        4416     0.7500    0.8000    0.7742        15\n","        4417     0.7343    0.8750    0.7985       120\n","        4419     0.9400    0.9369    0.9384       602\n","        5111     0.0000    0.0000    0.0000         2\n","        5112     0.0000    0.0000    0.0000         4\n","        5113     1.0000    1.0000    1.0000        13\n","        5120     0.9641    0.9648    0.9645      1365\n","        5131     0.9970    0.9851    0.9910       336\n","        5132     0.7333    0.9167    0.8148        12\n","        5141     0.9213    0.8119    0.8632       101\n","        5142     0.7895    0.8824    0.8333        85\n","        5211     0.9179    0.9201    0.9190       413\n","        5212     0.9711    0.9822    0.9766      3588\n","        5213     0.9700    0.9628    0.9664      1074\n","        5221     0.5000    0.3077    0.3810        13\n","        5222     0.0000    0.0000    0.0000         7\n","        5223     0.0000    0.0000    0.0000         5\n","        5230     0.9517    0.9583    0.9550       144\n","        5241     0.9091    0.5882    0.7143        34\n","        5243     0.8652    0.9625    0.9112        80\n","        5244     0.7600    0.7755    0.7677        49\n","        5245     0.7647    0.8298    0.7959        47\n","        5311     0.8065    0.8475    0.8264        59\n","        5312     0.9252    0.9706    0.9474       102\n","        5321     0.0000    0.0000    0.0000         2\n","        5322     0.5946    0.9167    0.7213        24\n","        5329     0.8519    0.7419    0.7931        31\n","        5412     0.8780    0.9600    0.9172        75\n","        5413     1.0000    0.7500    0.8571         8\n","        5414     0.7778    0.8922    0.8311       102\n","        5419     0.0000    0.0000    0.0000         8\n","        6111     0.9830    0.9650    0.9739       600\n","        6112     0.9737    0.9845    0.9791       451\n","        6113     0.0000    0.0000    0.0000         3\n","        6114     0.9991    1.0000    0.9995      6563\n","        6121     0.9833    0.9820    0.9827       779\n","        6122     0.9364    0.9626    0.9493       214\n","        6123     1.0000    0.2500    0.4000         4\n","        6210     0.6818    0.8824    0.7692        34\n","        6221     0.6000    0.6667    0.6316         9\n","        6222     0.8821    0.9609    0.9198       179\n","        6223     0.5000    0.1579    0.2400        19\n","        6224     1.0000    0.7500    0.8571         4\n","        6310     0.0000    0.0000    0.0000         2\n","        6320     0.0000    0.0000    0.0000         5\n","        7111     0.9338    0.9270    0.9304       274\n","        7112     0.0000    0.0000    0.0000         6\n","        7113     0.8868    0.8868    0.8868       106\n","        7119     0.8696    0.9032    0.8861       155\n","        7121     0.0000    0.0000    0.0000         3\n","        7122     0.0000    0.0000    0.0000         1\n","        7123     1.0000    0.6364    0.7778        11\n","        7125     0.0000    0.0000    0.0000         2\n","        7126     0.7500    0.9474    0.8372        19\n","        7127     0.8000    0.9655    0.8750        58\n","        7128     0.9545    1.0000    0.9767       126\n","        7129     0.8485    0.7568    0.8000        37\n","        7212     0.8750    0.9471    0.9096       170\n","        7213     0.0000    0.0000    0.0000         3\n","        7214     0.0000    0.0000    0.0000         7\n","        7221     0.7679    0.8515    0.8075       101\n","        7222     0.7778    0.3889    0.5185        18\n","        7223     0.5238    0.6875    0.5946        16\n","        7224     0.0000    0.0000    0.0000         4\n","        7231     0.8479    0.9292    0.8867       240\n","        7233     1.0000    0.1667    0.2857         6\n","        7234     0.4043    0.5429    0.4634        35\n","        7235     1.0000    0.8571    0.9231         7\n","        7311     1.0000    0.4286    0.6000         7\n","        7312     0.9107    0.9623    0.9358        53\n","        7313     0.8667    0.8966    0.8814        29\n","        7321     0.0000    0.0000    0.0000         1\n","        7322     0.9325    0.9048    0.9184       168\n","        7331     0.0000    0.0000    0.0000         4\n","        7332     0.9167    0.7333    0.8148        15\n","        7333     0.0000    0.0000    0.0000         3\n","        7341     0.8214    0.7188    0.7667        32\n","        7342     0.4444    0.8000    0.5714        10\n","        7351     0.8920    0.8814    0.8867       253\n","        7352     0.7952    0.8049    0.8000       164\n","        7353     0.0000    0.0000    0.0000         5\n","        7354     0.7578    0.8009    0.7788       211\n","        7355     0.6567    0.9362    0.7719        47\n","        7356     0.7273    0.8889    0.8000         9\n","        7361     0.6667    0.1429    0.2353        14\n","        7362     0.8310    0.9672    0.8939        61\n","        7391     0.0000    0.0000    0.0000         7\n","        7392     0.0000    0.0000    0.0000         4\n","        7399     0.6832    0.9324    0.7886        74\n","        7411     0.8182    0.8684    0.8426       114\n","        7412     0.0000    0.0000    0.0000         5\n","        7421     0.7308    0.8736    0.7958        87\n","        7422     0.8571    0.7500    0.8000        24\n","        7431     0.0000    0.0000    0.0000         5\n","        7432     0.0000    0.0000    0.0000         2\n","        7511     0.7143    0.5882    0.6452        34\n","        7512     0.7143    0.4545    0.5556        11\n","        7513     0.9266    0.9704    0.9480       338\n","        7514     0.7879    0.7647    0.7761        34\n","        7515     0.4706    0.4848    0.4776        33\n","        7517     1.0000    1.0000    1.0000         3\n","        7518     0.9077    0.9365    0.9219        63\n","        7519     0.6184    0.7460    0.6763        63\n","        8111     0.6825    0.8113    0.7414        53\n","        8112     0.3333    0.0714    0.1176        14\n","        8113     0.0000    0.0000    0.0000         2\n","        8114     0.0000    0.0000    0.0000         4\n","        8121     0.0000    0.0000    0.0000         3\n","        8131     0.7500    0.3750    0.5000        16\n","        8141     0.8438    0.8710    0.8571        31\n","        8142     0.5217    0.7059    0.6000        17\n","        8151     0.0000    0.0000    0.0000         4\n","        8152     0.0000    0.0000    0.0000         9\n","        8153     0.3750    0.2308    0.2857        13\n","        8154     0.0000    0.0000    0.0000         3\n","        8156     0.0000    0.0000    0.0000         7\n","        8159     0.0000    0.0000    0.0000         5\n","        8160     0.2778    0.3846    0.3226        13\n","        8171     0.6786    0.9048    0.7755        21\n","        8173     0.0000    0.0000    0.0000         3\n","        8181     0.6667    0.4000    0.5000        10\n","        8183     0.0000    0.0000    0.0000         4\n","        8189     0.4359    0.7391    0.5484        23\n","        8321     0.9872    0.9840    0.9856       940\n","        8322     0.9763    0.9549    0.9655       776\n","        8331     0.8962    0.9360    0.9157       203\n","        8332     0.9234    0.9347    0.9290       245\n","        8341     0.8780    0.9231    0.9000        39\n","        8342     0.6071    0.8361    0.7034        61\n","        8343     0.8085    0.7037    0.7525       108\n","        8351     0.0000    0.0000    0.0000         2\n","        8352     0.7872    0.9737    0.8706        38\n","        9111     0.9900    0.9986    0.9943       695\n","        9112     0.9397    0.9414    0.9405       546\n","        9121     0.9900    0.9803    0.9851       203\n","        9122     0.8718    0.9714    0.9189        35\n","        9124     0.0000    0.0000    0.0000         3\n","        9129     0.7333    0.6875    0.7097        16\n","        9211     0.9978    0.9982    0.9980      9856\n","        9212     0.0000    0.0000    0.0000        13\n","        9213     0.6591    0.8286    0.7342        35\n","        9214     0.8182    0.7500    0.7826        24\n","        9311     0.9044    0.9462    0.9248       130\n","        9312     0.9753    0.9240    0.9489       171\n","        9313     0.9823    0.9823    0.9823      1242\n","        9321     0.7115    0.8506    0.7749        87\n","        9329     0.0000    0.0000    0.0000         9\n","        9331     0.7119    0.9130    0.8000        46\n","        9332     0.0000    0.0000    0.0000         2\n","        9333     0.9643    0.9310    0.9474       319\n","        9334     0.9643    0.9818    0.9730        55\n","        9411     0.8955    0.8602    0.8775       279\n","        9412     0.9245    0.9328    0.9286       774\n","        9511     0.8710    0.9000    0.8852       150\n","        9512     0.6190    0.7647    0.6842        17\n","        9521     0.9236    0.9355    0.9295       155\n","        9522     0.6111    0.5500    0.5789        20\n","        9523     0.9310    0.8438    0.8852        32\n","        9524     0.7255    0.8605    0.7872        43\n","        9531     0.7805    0.8000    0.7901        40\n","        9533     0.9529    0.9465    0.9497       299\n","        9534     1.0000    0.3333    0.5000         6\n","        9535     0.9095    0.9095    0.9095       199\n","        9536     0.8333    0.8333    0.8333        12\n","        9537     0.7000    1.0000    0.8235         7\n","        9541     0.6500    0.3939    0.4906        33\n","        9542     0.0000    0.0000    0.0000         3\n","        9549     0.7143    0.7527    0.7330        93\n","        9611     0.7143    0.6667    0.6897        15\n","        9612     0.9029    0.9789    0.9394        95\n","        9613     0.8028    0.8261    0.8143        69\n","        9621     0.8786    0.9389    0.9077       131\n","        9622     0.9469    0.9346    0.9407       382\n","        9623     0.0000    0.0000    0.0000         3\n","        9624     0.0000    0.0000    0.0000         3\n","        9629     0.7237    0.6362    0.6771       951\n","\n","    accuracy                         0.9363     47344\n","   macro avg     0.5564    0.5488    0.5391     47344\n","weighted avg     0.9303    0.9363    0.9318     47344\n","\n","\n","‚úÖ Reporte completo guardado en: /content/drive/MyDrive/PI_PEU/xlmRoberta/xlm-roberta-base_20251112_182822/classification_report.txt\n","\n","================================================================================\n","üîç AN√ÅLISIS DE ERRORES\n","================================================================================\n","\n","Total de predicciones: 47,344\n","Predicciones correctas: 44,328\n","Predicciones incorrectas: 3,016\n","Tasa de error: 6.37%\n","\n","‚úÖ An√°lisis de errores guardado en: /content/drive/MyDrive/PI_PEU/xlmRoberta/xlm-roberta-base_20251112_182822/error_analysis.csv\n","\n","üìä Top 10 clases con m√°s errores de predicci√≥n:\n","   1. 9629: 346 errores\n","   2. 5212: 64 errores\n","   3. 9412: 52 errores\n","   4. 5120: 48 errores\n","   5. 2421: 43 errores\n","   6. 7354: 42 errores\n","   7. 5213: 40 errores\n","   8. 9411: 39 errores\n","   9. 4419: 38 errores\n","   10. 8322: 35 errores\n","\n","================================================================================\n","\n"]}],"id":"IzyrUTD6IKby"},{"cell_type":"code","metadata":{"id":"P_SQR_giIKby","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1762979773135,"user_tz":300,"elapsed":38252,"user":{"displayName":"Jesbil Betsy Valladolid Garcia","userId":"11256541342152996128"}},"outputId":"2950f6fb-9c8c-4e68-ee6c-ac473b2e6a66"},"source":["# ============================================================================\n","# üíæ GUARDADO COMPLETO DEL MODELO Y ARTEFACTOS\n","# ============================================================================\n","\n","print(\"\\n\" + \"=\"*80)\n","print(\"üíæ GUARDANDO MODELO Y ARTEFACTOS\")\n","print(\"=\"*80 + \"\\n\")\n","\n","try:\n","    config.logger.info(\"Guardando modelo final...\")\n","\n","    # 1. Guardar modelo y tokenizer\n","    trainer.save_model(config.MODEL_SAVE_DIR)\n","    tokenizer.save_pretrained(config.MODEL_SAVE_DIR)\n","\n","    print(f\"‚úÖ Modelo y tokenizer guardados en: {config.MODEL_SAVE_DIR}\")\n","    config.logger.info(f\"Modelo guardado en: {config.MODEL_SAVE_DIR}\")\n","\n","    # 2. Guardar artefactos (mapeos, configuraci√≥n, m√©tricas)\n","    artifacts = {\n","        'label2id': label2id,\n","        'id2label': id2label,\n","        'num_labels': len(label2id),\n","        'target_column': config.TARGET_COLUMN,\n","        'text_column': config.TEXT_COLUMN,\n","        'max_length': config.MAX_LENGTH,\n","        'model_name': config.MODEL_NAME,\n","        'model_type': config.model_type,\n","        'experiment_name': config.experiment_name,\n","        'training_date': datetime.now().isoformat(),\n","        'test_metrics': test_metrics,\n","        'val_metrics': val_metrics if 'val_metrics' in locals() else None,\n","        'training_time': str(training_time) if 'training_time' in locals() else None,\n","        'device': config.DEVICE,\n","    }\n","\n","    artifacts_file = os.path.join(config.OUTPUT_DIR, 'artifacts.pkl')\n","    with open(artifacts_file, 'wb') as f:\n","        pickle.dump(artifacts, f)\n","\n","    print(f\"‚úÖ Artefactos guardados en: {artifacts_file}\")\n","    config.logger.info(f\"Artefactos guardados en: {artifacts_file}\")\n","\n","    # 3. Guardar resumen en JSON (legible)\n","    summary = {\n","        'experiment_name': config.experiment_name,\n","        'model_name': config.MODEL_NAME,\n","        'model_type': config.model_type,\n","        'num_classes': len(label2id),\n","        'training_date': datetime.now().isoformat(),\n","        'data_path': config.DATA_PATH,\n","        'max_length': config.MAX_LENGTH,\n","        'batch_size': config.BATCH_SIZE,\n","        'learning_rate': config.LEARNING_RATE,\n","        'num_epochs': config.NUM_EPOCHS,\n","        'test_accuracy': test_metrics.get('test_accuracy', test_metrics.get('eval_accuracy', 0)),\n","        'test_f1_macro': test_metrics.get('test_f1_macro', test_metrics.get('eval_f1_macro', 0)),\n","        'test_f1_weighted': test_metrics.get('test_f1_weighted', test_metrics.get('eval_f1_weighted', 0)),\n","        'device_used': config.DEVICE,\n","    }\n","\n","    summary_file = os.path.join(config.OUTPUT_DIR, 'experiment_summary.json')\n","    with open(summary_file, 'w', encoding='utf-8') as f:\n","        json.dump(summary, f, indent=2, ensure_ascii=False)\n","\n","    print(f\"‚úÖ Resumen guardado en: {summary_file}\")\n","\n","    # 4. Crear archivo README\n","    readme_content = f\"\"\"# Experimento: {config.experiment_name}\n","\n","## Informaci√≥n del Modelo\n","- **Modelo Base**: {config.MODEL_NAME}\n","- **Tipo**: {config.model_type}\n","- **N√∫mero de Clases**: {len(label2id)}\n","- **Fecha de Entrenamiento**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n","\n","## Resultados (Test Set)\n","- **Accuracy**: {test_metrics.get('test_accuracy', test_metrics.get('eval_accuracy', 0)):.4f}\n","- **F1 Macro**: {test_metrics.get('test_f1_macro', test_metrics.get('eval_f1_macro', 0)):.4f}\n","- **F1 Weighted**: {test_metrics.get('test_f1_weighted', test_metrics.get('eval_f1_weighted', 0)):.4f}\n","- **Precision Weighted**: {test_metrics.get('test_precision_weighted', test_metrics.get('eval_precision_weighted', 0)):.4f}\n","- **Recall Weighted**: {test_metrics.get('test_recall_weighted', test_metrics.get('eval_recall_weighted', 0)):.4f}\n","\n","## Archivos Generados\n","- `final_model/`: Modelo entrenado y tokenizer\n","- `artifacts.pkl`: Mapeos y metadata\n","- `config.json`: Configuraci√≥n del entrenamiento\n","- `test_metrics.json`: M√©tricas completas de test\n","- `classification_report.txt`: Reporte detallado por clase\n","- `error_analysis.csv`: An√°lisis de errores\n","- `experiment_summary.json`: Resumen del experimento\n","\n","## C√≥mo Usar el Modelo\n","\n","```python\n","from transformers import AutoTokenizer, AutoModelForSequenceClassification\n","import pickle\n","\n","# Cargar modelo y tokenizer\n","model_path = \"{config.MODEL_SAVE_DIR}\"\n","model = AutoModelForSequenceClassification.from_pretrained(model_path)\n","tokenizer = AutoTokenizer.from_pretrained(model_path)\n","\n","# Cargar artefactos\n","with open('{artifacts_file}', 'rb') as f:\n","    artifacts = pickle.load(f)\n","\n","id2label = artifacts['id2label']\n","\n","# Hacer predicci√≥n\n","text = \"Tu texto aqu√≠\"\n","inputs = tokenizer(text, return_tensors='pt', max_length={config.MAX_LENGTH},\n","                   padding='max_length', truncation=True)\n","outputs = model(**inputs)\n","predicted_class = outputs.logits.argmax().item()\n","predicted_label = id2label[predicted_class]\n","print(f\"Predicci√≥n: {{predicted_label}}\")\n","```\n","\"\"\"\n","\n","    readme_file = os.path.join(config.OUTPUT_DIR, 'README.md')\n","    with open(readme_file, 'w', encoding='utf-8') as f:\n","        f.write(readme_content)\n","\n","    print(f\"‚úÖ README creado en: {readme_file}\")\n","\n","    # 5. Listar todos los archivos generados\n","    print(\"\\n\" + \"=\"*80)\n","    print(\"üìÅ ARCHIVOS GENERADOS\")\n","    print(\"=\"*80 + \"\\n\")\n","\n","    all_files = [\n","        ('Modelo final', config.MODEL_SAVE_DIR),\n","        ('Artefactos', artifacts_file),\n","        ('Configuraci√≥n', os.path.join(config.OUTPUT_DIR, 'config.json')),\n","        ('M√©tricas de test', os.path.join(config.OUTPUT_DIR, 'test_metrics.json')),\n","        ('Reporte de clasificaci√≥n', report_file),\n","        ('An√°lisis de errores', errors_file),\n","        ('Resumen del experimento', summary_file),\n","        ('README', readme_file),\n","        ('Info de clases', os.path.join(config.OUTPUT_DIR, 'class_info.json')),\n","    ]\n","\n","    for name, path in all_files:\n","        if os.path.exists(path):\n","            if os.path.isdir(path):\n","                print(f\"‚úÖ {name:.<40} {path}\")\n","            else:\n","                size = os.path.getsize(path) / 1024\n","                print(f\"‚úÖ {name:.<40} {path} ({size:.1f} KB)\")\n","\n","    print(\"\\n\" + \"=\"*80 + \"\\n\")\n","\n","    config.logger.info(\"Todos los archivos guardados exitosamente\")\n","\n","except Exception as e:\n","    print(\"\\n\" + \"=\"*80)\n","    print(\"‚ùå ERROR AL GUARDAR ARCHIVOS\")\n","    print(\"=\"*80)\n","    print(f\"\\n{str(e)}\\n\")\n","    config.logger.error(f\"Error al guardar: {str(e)}\", exc_info=True)\n","    raise\n"],"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","================================================================================\n","üíæ GUARDANDO MODELO Y ARTEFACTOS\n","================================================================================\n","\n","‚úÖ Modelo y tokenizer guardados en: /content/drive/MyDrive/PI_PEU/xlmRoberta/xlm-roberta-base_20251112_182822/final_model\n","‚úÖ Artefactos guardados en: /content/drive/MyDrive/PI_PEU/xlmRoberta/xlm-roberta-base_20251112_182822/artifacts.pkl\n","‚úÖ Resumen guardado en: /content/drive/MyDrive/PI_PEU/xlmRoberta/xlm-roberta-base_20251112_182822/experiment_summary.json\n","‚úÖ README creado en: /content/drive/MyDrive/PI_PEU/xlmRoberta/xlm-roberta-base_20251112_182822/README.md\n","\n","================================================================================\n","üìÅ ARCHIVOS GENERADOS\n","================================================================================\n","\n","‚úÖ Modelo final............................ /content/drive/MyDrive/PI_PEU/xlmRoberta/xlm-roberta-base_20251112_182822/final_model\n","‚úÖ Artefactos.............................. /content/drive/MyDrive/PI_PEU/xlmRoberta/xlm-roberta-base_20251112_182822/artifacts.pkl (6.2 KB)\n","‚úÖ Configuraci√≥n........................... /content/drive/MyDrive/PI_PEU/xlmRoberta/xlm-roberta-base_20251112_182822/config.json (0.5 KB)\n","‚úÖ M√©tricas de test........................ /content/drive/MyDrive/PI_PEU/xlmRoberta/xlm-roberta-base_20251112_182822/test_metrics.json (0.6 KB)\n","‚úÖ Reporte de clasificaci√≥n................ /content/drive/MyDrive/PI_PEU/xlmRoberta/xlm-roberta-base_20251112_182822/classification_report.txt (19.4 KB)\n","‚úÖ An√°lisis de errores..................... /content/drive/MyDrive/PI_PEU/xlmRoberta/xlm-roberta-base_20251112_182822/error_analysis.csv (1787.7 KB)\n","‚úÖ Resumen del experimento................. /content/drive/MyDrive/PI_PEU/xlmRoberta/xlm-roberta-base_20251112_182822/experiment_summary.json (0.5 KB)\n","‚úÖ README.................................. /content/drive/MyDrive/PI_PEU/xlmRoberta/xlm-roberta-base_20251112_182822/README.md (1.6 KB)\n","‚úÖ Info de clases.......................... /content/drive/MyDrive/PI_PEU/xlmRoberta/xlm-roberta-base_20251112_182822/class_info.json (19.6 KB)\n","\n","================================================================================\n","\n"]}],"id":"P_SQR_giIKby"},{"cell_type":"code","metadata":{"id":"u4rxwj65IKby","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1762979773148,"user_tz":300,"elapsed":14,"user":{"displayName":"Jesbil Betsy Valladolid Garcia","userId":"11256541342152996128"}},"outputId":"786c2451-2cc3-4f92-da5c-27a186cc409f"},"source":["# ============================================================================\n","# üîÆ FUNCIONES DE PREDICCI√ìN E INFERENCIA\n","# ============================================================================\n","\n","def load_trained_model_for_inference(model_dir, artifacts_path, device=None):\n","    \"\"\"\n","    Carga el modelo entrenado para hacer predicciones\n","\n","    Args:\n","        model_dir: Directorio del modelo guardado\n","        artifacts_path: Ruta al archivo de artefactos\n","        device: Dispositivo ('cuda' o 'cpu'), None para auto-detectar\n","\n","    Returns:\n","        tuple: (model, tokenizer, artifacts)\n","    \"\"\"\n","    import torch\n","    from transformers import AutoTokenizer, AutoModelForSequenceClassification\n","    import pickle\n","\n","    if device is None:\n","        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","\n","    print(\"\\n\" + \"=\"*80)\n","    print(\"üìÇ CARGANDO MODELO PARA INFERENCIA\")\n","    print(\"=\"*80 + \"\\n\")\n","\n","    # Cargar tokenizer\n","    tokenizer = AutoTokenizer.from_pretrained(model_dir)\n","    print(f\"‚úÖ Tokenizer cargado\")\n","\n","    # Cargar modelo\n","    model = AutoModelForSequenceClassification.from_pretrained(model_dir)\n","    model.to(device)\n","    model.eval()  # Modo evaluaci√≥n\n","    print(f\"‚úÖ Modelo cargado en: {device}\")\n","\n","    # Cargar artefactos\n","    with open(artifacts_path, 'rb') as f:\n","        artifacts = pickle.load(f)\n","    print(f\"‚úÖ Artefactos cargados\")\n","    print(f\"   N√∫mero de clases: {artifacts['num_labels']}\")\n","\n","    print(\"\\n\" + \"=\"*80 + \"\\n\")\n","\n","    return model, tokenizer, artifacts\n","\n","\n","def predict_single(text, model, tokenizer, artifacts, device=None, top_k=5):\n","    \"\"\"\n","    Predice la clase de un texto individual\n","\n","    Args:\n","        text: Texto a clasificar\n","        model: Modelo entrenado\n","        tokenizer: Tokenizer\n","        artifacts: Diccionario de artefactos\n","        device: Dispositivo\n","        top_k: N√∫mero de predicciones principales a retornar\n","\n","    Returns:\n","        dict: Resultados de la predicci√≥n\n","    \"\"\"\n","    import torch\n","    import torch.nn.functional as F\n","\n","    if device is None:\n","        device = next(model.parameters()).device\n","\n","    # Tokenizar\n","    inputs = tokenizer(\n","        text,\n","        max_length=artifacts['max_length'],\n","        padding='max_length',\n","        truncation=True,\n","        return_tensors='pt'\n","    )\n","    inputs = {k: v.to(device) for k, v in inputs.items()}\n","\n","    # Predicci√≥n\n","    with torch.no_grad():\n","        outputs = model(**inputs)\n","        logits = outputs.logits\n","        probs = F.softmax(logits, dim=-1)\n","\n","    # Predicci√≥n principal\n","    predicted_idx = torch.argmax(probs, dim=-1).item()\n","    predicted_prob = probs[0][predicted_idx].item()\n","    predicted_label = artifacts['id2label'][str(predicted_idx)]\n","\n","    # Top-K predicciones\n","    top_probs, top_indices = torch.topk(probs[0], k=min(top_k, len(artifacts['id2label'])))\n","    top_predictions = [\n","        {\n","            'label': artifacts['id2label'][str(idx.item())],\n","            'probability': prob.item()\n","        }\n","        for prob, idx in zip(top_probs, top_indices)\n","    ]\n","\n","    return {\n","        'text': text,\n","        'predicted_label': predicted_label,\n","        'predicted_probability': predicted_prob,\n","        'top_predictions': top_predictions\n","    }\n","\n","\n","def predict_batch(texts, model, tokenizer, artifacts, device=None, batch_size=32):\n","    \"\"\"\n","    Predice las clases de m√∫ltiples textos\n","\n","    Args:\n","        texts: Lista de textos\n","        model: Modelo entrenado\n","        tokenizer: Tokenizer\n","        artifacts: Diccionario de artefactos\n","        device: Dispositivo\n","        batch_size: Tama√±o del lote\n","\n","    Returns:\n","        list: Lista de predicciones\n","    \"\"\"\n","    import torch\n","    import torch.nn.functional as F\n","    from tqdm.auto import tqdm\n","\n","    if device is None:\n","        device = next(model.parameters()).device\n","\n","    model.eval()\n","    predictions = []\n","\n","    # Procesar en lotes\n","    for i in tqdm(range(0, len(texts), batch_size), desc=\"Prediciendo\"):\n","        batch_texts = texts[i:i+batch_size]\n","\n","        # Tokenizar\n","        inputs = tokenizer(\n","            batch_texts,\n","            max_length=artifacts['max_length'],\n","            padding='max_length',\n","            truncation=True,\n","            return_tensors='pt'\n","        )\n","        inputs = {k: v.to(device) for k, v in inputs.items()}\n","\n","        # Predicci√≥n\n","        with torch.no_grad():\n","            outputs = model(**inputs)\n","            logits = outputs.logits\n","            probs = F.softmax(logits, dim=-1)\n","\n","        # Extraer predicciones\n","        predicted_indices = torch.argmax(probs, dim=-1).cpu().numpy()\n","        predicted_probs = torch.max(probs, dim=-1)[0].cpu().numpy()\n","\n","        for idx, prob in zip(predicted_indices, predicted_probs):\n","            predictions.append({\n","                'predicted_label': artifacts['id2label'][str(idx)],\n","                'probability': float(prob)\n","            })\n","\n","    return predictions\n","\n","\n","def interactive_prediction_mode(model, tokenizer, artifacts, device=None):\n","    \"\"\"\n","    Modo interactivo para probar el modelo\n","\n","    Args:\n","        model: Modelo entrenado\n","        tokenizer: Tokenizer\n","        artifacts: Diccionario de artefactos\n","        device: Dispositivo\n","    \"\"\"\n","    print(\"\\n\" + \"=\"*80)\n","    print(\"üß™ MODO DE PRUEBA INTERACTIVO\")\n","    print(\"=\"*80)\n","    print(\"\\nEscribe un texto para clasificar (o 'salir' para terminar)\")\n","    print(\"Comandos especiales: 'salir', 'exit', 'quit', 'q'\\n\")\n","\n","    while True:\n","        print(\"-\" * 80)\n","        text = input(\"\\nüìù Texto: \").strip()\n","\n","        if text.lower() in ['salir', 'exit', 'quit', 'q']:\n","            print(\"\\nüëã ¬°Hasta luego!\\n\")\n","            break\n","\n","        if not text:\n","            print(\"‚ö†Ô∏è  Por favor, ingresa un texto v√°lido\")\n","            continue\n","\n","        # Realizar predicci√≥n\n","        result = predict_single(text, model, tokenizer, artifacts, device)\n","\n","        # Mostrar resultados\n","        print(\"\\nüìä RESULTADO:\")\n","        print(f\"   üéØ Clase predicha: {result['predicted_label']}\")\n","        print(f\"   üìà Confianza: {result['predicted_probability']:.2%}\")\n","        print(f\"\\n   üîù Top 5 predicciones:\")\n","        for i, pred in enumerate(result['top_predictions'], 1):\n","            bar = \"‚ñà\" * int(pred['probability'] * 20)\n","            print(f\"      {i}. {pred['label']:<15} {pred['probability']:>6.2%} {bar}\")\n","        print()\n","\n","\n","print(\"‚úÖ Funciones de predicci√≥n cargadas\")\n"],"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["‚úÖ Funciones de predicci√≥n cargadas\n"]}],"id":"u4rxwj65IKby"},{"cell_type":"code","metadata":{"id":"HDavsX-dIKbz","colab":{"base_uri":"https://localhost:8080/","height":488},"executionInfo":{"status":"error","timestamp":1762979773469,"user_tz":300,"elapsed":319,"user":{"displayName":"Jesbil Betsy Valladolid Garcia","userId":"11256541342152996128"}},"outputId":"2a91e63b-1ef1-4717-b1ea-042c8135842c"},"source":["# ============================================================================\n","# üí° EJEMPLO DE USO - PREDICCI√ìN CON EL MODELO ENTRENADO\n","# ============================================================================\n","\n","# Este c√≥digo muestra c√≥mo usar el modelo despu√©s del entrenamiento\n","# Puedes ejecutarlo en este notebook o en uno nuevo\n","\n","print(\"\\n\" + \"=\"*80)\n","print(\"üí° EJEMPLOS DE USO\")\n","print(\"=\"*80 + \"\\n\")\n","\n","# ============================================================================\n","# OPCI√ìN 1: Usar el modelo reci√©n entrenado (en este notebook)\n","# ============================================================================\n","\n","print(\"üìù OPCI√ìN 1: Predicci√≥n individual con modelo actual\\n\")\n","\n","# Ejemplo de textos para probar\n","ejemplos_texto = [\n","    \"vendedor de abarrotes en bodega\",\n","    \"profesor de matem√°ticas en colegio secundario\",\n","    \"conductor de taxi\"\n","]\n","\n","print(\"Ejemplos de predicci√≥n:\\n\")\n","for texto in ejemplos_texto:\n","    result = predict_single(texto, model, tokenizer, artifacts, config.DEVICE)\n","    print(f\"Texto: {texto}\")\n","    print(f\"Predicci√≥n: {result['predicted_label']} (confianza: {result['predicted_probability']:.2%})\\n\")\n","\n","print(\"-\" * 80 + \"\\n\")\n","\n","# ============================================================================\n","# OPCI√ìN 2: Cargar modelo guardado (en una nueva sesi√≥n)\n","# ============================================================================\n","\n","print(\"üìù OPCI√ìN 2: C√≥digo para cargar el modelo en una nueva sesi√≥n\\n\")\n","\n","codigo_ejemplo = f'''\n","# C√≥digo para usar en un notebook/script nuevo:\n","\n","# 1. Cargar el modelo\n","model_inference, tokenizer_inference, artifacts_inference = load_trained_model_for_inference(\n","    model_dir=\"{config.MODEL_SAVE_DIR}\",\n","    artifacts_path=\"{os.path.join(config.OUTPUT_DIR, 'artifacts.pkl')}\"\n",")\n","\n","# 2. Hacer predicci√≥n individual\n","texto = \"alba√±il de construcci√≥n\"\n","result = predict_single(\n","    text=texto,\n","    model=model_inference,\n","    tokenizer=tokenizer_inference,\n","    artifacts=artifacts_inference\n",")\n","print(f\"Predicci√≥n: {{result['predicted_label']}}\")\n","print(f\"Confianza: {{result['predicted_probability']:.2%}}\")\n","\n","# 3. Hacer predicci√≥n por lotes\n","textos = [\"texto 1\", \"texto 2\", \"texto 3\"]\n","predictions = predict_batch(\n","    texts=textos,\n","    model=model_inference,\n","    tokenizer=tokenizer_inference,\n","    artifacts=artifacts_inference,\n","    batch_size=32\n",")\n","\n","# 4. Modo interactivo\n","interactive_prediction_mode(\n","    model=model_inference,\n","    tokenizer=tokenizer_inference,\n","    artifacts=artifacts_inference\n",")\n","'''\n","\n","print(codigo_ejemplo)\n","\n","print(\"=\" * 80 + \"\\n\")\n"],"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","================================================================================\n","üí° EJEMPLOS DE USO\n","================================================================================\n","\n","üìù OPCI√ìN 1: Predicci√≥n individual con modelo actual\n","\n","Ejemplos de predicci√≥n:\n","\n"]},{"output_type":"error","ename":"KeyError","evalue":"'193'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-3118623678.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Ejemplos de predicci√≥n:\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtexto\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mejemplos_texto\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_single\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0martifacts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Texto: {texto}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Predicci√≥n: {result['predicted_label']} (confianza: {result['predicted_probability']:.2%})\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipython-input-925818954.py\u001b[0m in \u001b[0;36mpredict_single\u001b[0;34m(text, model, tokenizer, artifacts, device, top_k)\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0mpredicted_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0mpredicted_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpredicted_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m     \u001b[0mpredicted_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0martifacts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id2label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;31m# Top-K predicciones\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: '193'"]}],"id":"HDavsX-dIKbz"},{"cell_type":"code","metadata":{"id":"IwaxuCtxIKbz","executionInfo":{"status":"aborted","timestamp":1762979773637,"user_tz":300,"elapsed":2,"user":{"displayName":"Jesbil Betsy Valladolid Garcia","userId":"11256541342152996128"}}},"source":["# ============================================================================\n","# üéÆ MODO INTERACTIVO - PROBAR EL MODELO\n","# ============================================================================\n","\n","# Descomenta y ejecuta esta celda para probar el modelo interactivamente\n","\n","# interactive_prediction_mode(\n","#     model=model,\n","#     tokenizer=tokenizer,\n","#     artifacts=artifacts,\n","#     device=config.DEVICE\n","# )\n","\n","print(\"\\nüí° Descomenta el c√≥digo arriba para activar el modo interactivo\\n\")\n"],"execution_count":null,"outputs":[],"id":"IwaxuCtxIKbz"},{"cell_type":"markdown","metadata":{"id":"BkxBmMG2IKbz"},"source":["---\n","\n","# üéâ ¬°ENTRENAMIENTO COMPLETADO!\n","\n","## üìä Resumen de Resultados\n","\n","Tu modelo ha sido entrenado exitosamente. Revisa:\n","\n","1. **M√©tricas de Test**: Accuracy, F1, Precision, Recall (macro, micro, weighted)\n","2. **Archivos Generados**: Todos los archivos est√°n en el directorio de salida\n","3. **README**: Instrucciones detalladas de uso\n","\n","## üöÄ Pr√≥ximos Pasos\n","\n","### Para entrenar otro modelo:\n","1. Cambia `MODEL_NAME` en `ModelConfig`\n","2. Ejecuta todas las celdas nuevamente\n","\n","### Para usar el modelo:\n","1. Usa las funciones de predicci√≥n en este notebook\n","2. O carga el modelo en un script nuevo (ver ejemplos arriba)\n","\n","### Para mejorar los resultados:\n","- Ajusta los hiperpar√°metros en `ModelConfig`\n","- Aumenta `NUM_EPOCHS`\n","- Experimenta con diferentes `LEARNING_RATE`\n","- Aumenta `MAX_LENGTH` si tus textos son largos\n","\n","---\n","\n","## üìö Modelos Soportados\n","\n","Este script funciona con:\n","- ‚úÖ `FacebookAI/xlm-roberta-base` (Multiling√ºe)\n","- ‚úÖ `dccuchile/bert-base-spanish-wwm-cased` (Espa√±ol)\n","- ‚úÖ Cualquier modelo de Hugging Face compatible con `AutoModelForSequenceClassification`\n","\n","---\n","\n","**¬øPreguntas o errores?** Revisa:\n","- El archivo de log en el directorio de salida\n","- Los mensajes de error detallados en cada celda\n","- La documentaci√≥n de transformers: https://huggingface.co/docs/transformers\n"],"id":"BkxBmMG2IKbz"}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.0"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"32bae97cace44aabb0dc03ad08588d09":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fc02c43bfbd141e6a757113b8ef4b6b4","IPY_MODEL_87db80cc1dff4f37bdcbcd3b45796290","IPY_MODEL_272882e7331f4da7be0230e599d9e867"],"layout":"IPY_MODEL_99fbb1306d30488c9307d4b5806ba6db"}},"fc02c43bfbd141e6a757113b8ef4b6b4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d2a3184597644764a7cc34a1df13a3fd","placeholder":"‚Äã","style":"IPY_MODEL_25bc6d6813954c3d8a3aa0d956cde4c3","value":"tokenizer_config.json:‚Äá100%"}},"87db80cc1dff4f37bdcbcd3b45796290":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a0be01901f9944b5a85223df2590cf9b","max":25,"min":0,"orientation":"horizontal","style":"IPY_MODEL_cb5c23760624453d982d0dffe7855f17","value":25}},"272882e7331f4da7be0230e599d9e867":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c3ecb479e8f2414090d688d54f540ef0","placeholder":"‚Äã","style":"IPY_MODEL_ae54ed7928ce47239ba7f5159461309e","value":"‚Äá25.0/25.0‚Äá[00:00&lt;00:00,‚Äá1.06kB/s]"}},"99fbb1306d30488c9307d4b5806ba6db":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d2a3184597644764a7cc34a1df13a3fd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"25bc6d6813954c3d8a3aa0d956cde4c3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a0be01901f9944b5a85223df2590cf9b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cb5c23760624453d982d0dffe7855f17":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c3ecb479e8f2414090d688d54f540ef0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ae54ed7928ce47239ba7f5159461309e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cad02f843ae7463f9416ab49ecd9f70c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_09bc69c015ce45b29aa1f729a75f48e1","IPY_MODEL_d4443d28a9cb492b98fb282695fef0d9","IPY_MODEL_97952aa0e7524bc1b2454126f168d8e4"],"layout":"IPY_MODEL_c5c5d604ca3343f8b36a8522d4f99da6"}},"09bc69c015ce45b29aa1f729a75f48e1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2fbeba450b864c779b47a69c3ad967b2","placeholder":"‚Äã","style":"IPY_MODEL_c41b53d575034f63aba6b519c7a51e8c","value":"config.json:‚Äá100%"}},"d4443d28a9cb492b98fb282695fef0d9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_42a8fbb19c964fa4b332eb97f40f2a2f","max":615,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f8cf6b9f78e245129b343c2d368af8b9","value":615}},"97952aa0e7524bc1b2454126f168d8e4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6241638fcb6f406498b5d65fc33a7362","placeholder":"‚Äã","style":"IPY_MODEL_f04e82680e45493e88988aec46103590","value":"‚Äá615/615‚Äá[00:00&lt;00:00,‚Äá27.1kB/s]"}},"c5c5d604ca3343f8b36a8522d4f99da6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2fbeba450b864c779b47a69c3ad967b2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c41b53d575034f63aba6b519c7a51e8c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"42a8fbb19c964fa4b332eb97f40f2a2f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f8cf6b9f78e245129b343c2d368af8b9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6241638fcb6f406498b5d65fc33a7362":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f04e82680e45493e88988aec46103590":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"91d50cdb9c77454eb1c9cdf7fbca2c25":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9558fbf395aa44209ac2318f7566ab54","IPY_MODEL_628642a94cd040c6b9580c800183b692","IPY_MODEL_728b9edd48df45879eefd69c0daf3bb0"],"layout":"IPY_MODEL_da9a944371c941a5b6a410e3f41dfe89"}},"9558fbf395aa44209ac2318f7566ab54":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5c7c89932a0d4544aea8f21c2c208de9","placeholder":"‚Äã","style":"IPY_MODEL_b220144bcb51405da3f607910e066328","value":"sentencepiece.bpe.model:‚Äá100%"}},"628642a94cd040c6b9580c800183b692":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_27d809132f5142f98655e2648da11dc6","max":5069051,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4b3192c8942d4fa4a642b7f4abfb8b24","value":5069051}},"728b9edd48df45879eefd69c0daf3bb0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9915a04f3ca946119ac3e5ead7689f8f","placeholder":"‚Äã","style":"IPY_MODEL_280ac7237b5d496d8501c40758c551f9","value":"‚Äá5.07M/5.07M‚Äá[00:00&lt;00:00,‚Äá49.5MB/s]"}},"da9a944371c941a5b6a410e3f41dfe89":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5c7c89932a0d4544aea8f21c2c208de9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b220144bcb51405da3f607910e066328":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"27d809132f5142f98655e2648da11dc6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4b3192c8942d4fa4a642b7f4abfb8b24":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9915a04f3ca946119ac3e5ead7689f8f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"280ac7237b5d496d8501c40758c551f9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"95a3574877904eb88b3d2c188c90fd59":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c1875c95a7ae42ad8bf3ff994f8f75d6","IPY_MODEL_83a5c3ce94f9457ea94da8e254dd998a","IPY_MODEL_16652eb12aaf4a1aac23ebc0b46c5322"],"layout":"IPY_MODEL_f67096bcd49d4ca0ad2649f1d7718b28"}},"c1875c95a7ae42ad8bf3ff994f8f75d6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cc842f1a529149d1b2251ae6a04b2bf8","placeholder":"‚Äã","style":"IPY_MODEL_dda99051c5dc48cbb17499e902175ccd","value":"tokenizer.json:‚Äá"}},"83a5c3ce94f9457ea94da8e254dd998a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_259bf166c2204b8ca98d8fefc92d55a2","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0d5b30eb06684c9ebfe928c8555fdfdc","value":1}},"16652eb12aaf4a1aac23ebc0b46c5322":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f6ef00970aeb49a18835153faf48bfd7","placeholder":"‚Äã","style":"IPY_MODEL_67e1072170a8418da3ebf0a8f770776b","value":"‚Äá9.10M/?‚Äá[00:00&lt;00:00,‚Äá40.5MB/s]"}},"f67096bcd49d4ca0ad2649f1d7718b28":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cc842f1a529149d1b2251ae6a04b2bf8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dda99051c5dc48cbb17499e902175ccd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"259bf166c2204b8ca98d8fefc92d55a2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"0d5b30eb06684c9ebfe928c8555fdfdc":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f6ef00970aeb49a18835153faf48bfd7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"67e1072170a8418da3ebf0a8f770776b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3209b1138d2146d9a1568529e3963592":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9ef71108f1314133b08835cb0f1ca859","IPY_MODEL_8c30fdb441514ab3aff6665be5d31c6b","IPY_MODEL_a2c438f121554f528a7b871f76179bc5"],"layout":"IPY_MODEL_0c951e26f6704ec6a684b6231f96ccac"}},"9ef71108f1314133b08835cb0f1ca859":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e6918e58440b453bb8b77e3e8e435650","placeholder":"‚Äã","style":"IPY_MODEL_45fe822eb2d14c06ba7cccf6bf5f82d7","value":"model.safetensors:‚Äá100%"}},"8c30fdb441514ab3aff6665be5d31c6b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_168b7e1435e7433c8411c1b26c349d5d","max":1115567652,"min":0,"orientation":"horizontal","style":"IPY_MODEL_95159ed217984eb7bc1f2fb1d66f6bc6","value":1115567652}},"a2c438f121554f528a7b871f76179bc5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_859104f788034bc2abd43f1869641d4d","placeholder":"‚Äã","style":"IPY_MODEL_158f7ea3dfed4e258fa382b134843c6b","value":"‚Äá1.12G/1.12G‚Äá[00:10&lt;00:00,‚Äá225MB/s]"}},"0c951e26f6704ec6a684b6231f96ccac":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e6918e58440b453bb8b77e3e8e435650":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"45fe822eb2d14c06ba7cccf6bf5f82d7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"168b7e1435e7433c8411c1b26c349d5d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"95159ed217984eb7bc1f2fb1d66f6bc6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"859104f788034bc2abd43f1869641d4d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"158f7ea3dfed4e258fa382b134843c6b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":5}