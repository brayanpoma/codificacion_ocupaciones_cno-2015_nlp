{"cells":[{"cell_type":"markdown","metadata":{"id":"HZsUKvPcIKbi"},"source":["# üöÄ Entrenamiento de Modelos Transformer para Clasificaci√≥n de Ocupaciones ENAHO\n","\n","---\n","\n","## üìã Descripci√≥n\n","Script robusto y universal para entrenar modelos de clasificaci√≥n de texto.\n","\n","### üéØ Modelos Soportados:\n","- **BETO**: `dccuchile/bert-base-spanish-wwm-cased` (Espa√±ol)\n","- **XLM-RoBERTa**: `FacebookAI/xlm-roberta-base` (Multiling√ºe)\n","\n","### ‚ú® Caracter√≠sticas:\n","- ‚úÖ Cambio de modelo con una sola variable\n","- ‚úÖ M√©tricas detalladas (macro, micro, weighted)\n","- ‚úÖ Manejo robusto de errores\n","- ‚úÖ Logging detallado para debugging\n","- ‚úÖ Validaci√≥n de datos en cada paso\n","- ‚úÖ Guardado completo de modelo y artefactos\n","- ‚úÖ Funciones de predicci√≥n e inferencia\n","\n","---\n","\n","**Autor**: Sistema de Clasificaci√≥n ENAHO  \n","**Fecha**: 2025  \n","**Entorno**: VSCode con Jupyter Notebook  \n"],"id":"HZsUKvPcIKbi"},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5jXhWE22Ii01","executionInfo":{"status":"ok","timestamp":1763733718310,"user_tz":300,"elapsed":2482,"user":{"displayName":"Brayan Poma Huaman","userId":"00419443262019466393"}},"outputId":"fbe3f86d-9687-42ca-a30a-36e38ac7a4b2"},"id":"5jXhWE22Ii01","execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9LksZDJXIKbq","executionInfo":{"status":"ok","timestamp":1763733718920,"user_tz":300,"elapsed":607,"user":{"displayName":"Brayan Poma Huaman","userId":"00419443262019466393"}},"outputId":"96c2a3cd-a7f2-4739-ff2a-42ec827a3bd6"},"source":["# ============================================================================\n","# INSTALACI√ìN DE DEPENDENCIAS (Ejecutar solo una vez)\n","# ============================================================================\n","\n","# Descomenta si necesitas instalar las librer√≠as\n","# !pip install transformers==4.36.0 datasets==2.15.0 scikit-learn==1.3.2\n","# !pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n","# !pip install accelerate sentencepiece\n","\n","print(\"‚úÖ Si las librer√≠as ya est√°n instaladas, puedes continuar\")\n"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["‚úÖ Si las librer√≠as ya est√°n instaladas, puedes continuar\n"]}],"id":"9LksZDJXIKbq"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YAmxPXboIKbr","executionInfo":{"status":"ok","timestamp":1763733765509,"user_tz":300,"elapsed":46566,"user":{"displayName":"Brayan Poma Huaman","userId":"00419443262019466393"}},"outputId":"5b17c28c-e48c-465d-c6d9-f616a28b3fa2"},"source":["# ============================================================================\n","# IMPORTACIONES Y VERIFICACI√ìN DEL ENTORNO\n","# ============================================================================\n","\n","import sys\n","import os\n","import warnings\n","import logging\n","from datetime import datetime\n","from pathlib import Path\n","\n","# Data & ML\n","import pandas as pd\n","import numpy as np\n","import torch\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import (\n","    accuracy_score,\n","    precision_recall_fscore_support,\n","    classification_report,\n","    confusion_matrix\n",")\n","\n","# Transformers\n","from transformers import (\n","    AutoTokenizer,\n","    AutoModelForSequenceClassification,\n","    TrainingArguments,\n","    Trainer,\n","    EarlyStoppingCallback\n",")\n","from torch.utils.data import Dataset\n","\n","# Utilities\n","from tqdm.auto import tqdm\n","import pickle\n","import json\n","\n","warnings.filterwarnings('ignore')\n","\n","# ============================================================================\n","# CONFIGURACI√ìN DE LOGGING\n","# ============================================================================\n","\n","def setup_logging(output_dir):\n","    \"\"\"Configura el sistema de logging para debugging\"\"\"\n","    os.makedirs(output_dir, exist_ok=True)\n","    log_file = os.path.join(output_dir, f'training_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.log')\n","\n","    logging.basicConfig(\n","        level=logging.INFO,\n","        format='%(asctime)s - %(levelname)s - %(message)s',\n","        handlers=[\n","            logging.FileHandler(log_file, encoding='utf-8'),\n","            logging.StreamHandler(sys.stdout)\n","        ]\n","    )\n","    return logging.getLogger(__name__)\n","\n","# ============================================================================\n","# VERIFICACI√ìN DE GPU\n","# ============================================================================\n","\n","print(\"\\n\" + \"=\"*80)\n","print(\"üîç VERIFICACI√ìN DEL ENTORNO\")\n","print(\"=\"*80)\n","\n","print(f\"\\nüì¶ Versiones:\")\n","print(f\"   Python: {sys.version.split()[0]}\")\n","print(f\"   PyTorch: {torch.__version__}\")\n","print(f\"   CUDA disponible: {torch.cuda.is_available()}\")\n","\n","if torch.cuda.is_available():\n","    print(f\"\\nüéÆ GPU Detectada:\")\n","    print(f\"   Dispositivo: {torch.cuda.get_device_name(0)}\")\n","    print(f\"   Memoria total: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n","    print(f\"   Memoria libre: {(torch.cuda.get_device_properties(0).total_memory - torch.cuda.memory_allocated(0)) / 1e9:.2f} GB\")\n","else:\n","    print(\"\\n‚ö†Ô∏è  GPU no detectada - El entrenamiento ser√° lento\")\n","    print(\"   Considera usar Google Colab o configurar CUDA\")\n","\n","print(\"\\n\" + \"=\"*80)\n","print(\"‚úÖ Importaciones completadas correctamente\")\n","print(\"=\"*80 + \"\\n\")\n"],"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","================================================================================\n","üîç VERIFICACI√ìN DEL ENTORNO\n","================================================================================\n","\n","üì¶ Versiones:\n","   Python: 3.12.12\n","   PyTorch: 2.8.0+cu126\n","   CUDA disponible: True\n","\n","üéÆ GPU Detectada:\n","   Dispositivo: Tesla T4\n","   Memoria total: 15.83 GB\n","   Memoria libre: 15.83 GB\n","\n","================================================================================\n","‚úÖ Importaciones completadas correctamente\n","================================================================================\n","\n"]}],"id":"YAmxPXboIKbr"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":628},"id":"xfu88qZ_IKbs","executionInfo":{"status":"ok","timestamp":1763733765919,"user_tz":300,"elapsed":407,"user":{"displayName":"Brayan Poma Huaman","userId":"00419443262019466393"}},"outputId":"f8557eb3-985e-4da1-e398-73ced347adc5"},"source":["# ============================================================================\n","# ‚öôÔ∏è  CONFIGURACI√ìN PRINCIPAL - MODIFICA AQU√ç\n","# ============================================================================\n","\n","class ModelConfig:\n","    \"\"\"\n","    Configuraci√≥n centralizada del modelo y entrenamiento\n","\n","    IMPORTANTE: Solo necesitas cambiar MODEL_NAME para entrenar un modelo diferente\n","    \"\"\"\n","\n","    # ========================================================================\n","    # üéØ SELECCI√ìN DEL MODELO - CAMBIA SOLO ESTA L√çNEA\n","    # ========================================================================\n","\n","    # MODEL_NAME = \"FacebookAI/xlm-roberta-base\"  # Opci√≥n 1: XLM-RoBERTa (multiling√ºe)\n","    MODEL_NAME = \"dccuchile/bert-base-spanish-wwm-cased\"  # Opci√≥n 2: BETO (espa√±ol)\n","    # MODEL_NAME = \"bertin-project/bertin-roberta-base-spanish\"\n","\n","    # ========================================================================\n","    # üìÇ RUTAS DE DATOS\n","    # ========================================================================\n","\n","    # Ruta al archivo de datos (ajusta seg√∫n tu ubicaci√≥n)\n","    DATA_PATH = \"/content/drive/MyDrive/classification_coding_open_ended_occupational_responses_ENAHO/CLEAN_DATA/BASE_LIMPIA_VF.parquet\"  # Cambia esta ruta\n","\n","    # Directorio base para outputs\n","    BASE_OUTPUT_DIR = \"/content/drive/MyDrive/classification_coding_open_ended_occupational_responses_ENAHO/results/beto_base\"\n","\n","    # ========================================================================\n","    # üìä COLUMNAS DEL DATASET\n","    # ========================================================================\n","\n","    TEXT_COLUMN = \"texto_final\"  # Columna con el texto\n","    TARGET_COLUMN = \"p505r4\"     # Columna objetivo (clase)\n","\n","    # ========================================================================\n","    # üéõÔ∏è  HIPERPAR√ÅMETROS DE ENTRENAMIENTO\n","    # ========================================================================\n","\n","    # Tokenizaci√≥n\n","    MAX_LENGTH = 128  # Longitud m√°xima de tokens\n","\n","    # Entrenamiento\n","    BATCH_SIZE = 16          # Ajusta seg√∫n tu GPU (16, 32, 64)\n","    LEARNING_RATE = 2e-5     # Tasa de aprendizaje\n","    NUM_EPOCHS = 3           # N√∫mero de √©pocas\n","    WARMUP_STEPS = 500       # Pasos de warmup\n","    WEIGHT_DECAY = 0.01      # Regularizaci√≥n\n","\n","    # Divisi√≥n de datos\n","    TEST_SIZE = 0.15         # 15% para test\n","    VAL_SIZE = 0.15          # 15% para validaci√≥n\n","    RANDOM_STATE = 2025      # Semilla para reproducibilidad\n","\n","    # Filtrado de clases raras\n","    MIN_SAMPLES_PER_CLASS = 10  # M√≠nimo de muestras por clase\n","\n","    # Early stopping\n","    EARLY_STOPPING_PATIENCE = 3\n","\n","    # ========================================================================\n","    # üîß CONFIGURACI√ìN AUTOM√ÅTICA (NO MODIFICAR)\n","    # ========================================================================\n","\n","    def __init__(self):\n","        \"\"\"Inicializa configuraci√≥n y crea directorios\"\"\"\n","        # Detectar tipo de modelo del nombre\n","        if \"roberta\" in self.MODEL_NAME.lower():\n","            self.model_type = \"xlm-roberta\"\n","        elif \"bert\" in self.MODEL_NAME.lower():\n","            self.model_type = \"bert\"\n","        else:\n","            self.model_type = \"transformer\"\n","\n","        # Crear nombre descriptivo para el experimento\n","        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n","        model_short_name = self.MODEL_NAME.split('/')[-1]\n","        self.experiment_name = f\"{model_short_name}_{timestamp}\"\n","\n","        # Configurar directorios\n","        self.OUTPUT_DIR = os.path.join(self.BASE_OUTPUT_DIR, self.experiment_name)\n","        self.MODEL_SAVE_DIR = os.path.join(self.OUTPUT_DIR, \"final_model\")\n","        self.CHECKPOINT_DIR = os.path.join(self.OUTPUT_DIR, \"checkpoints\")\n","\n","        # Crear directorios\n","        for dir_path in [self.OUTPUT_DIR, self.MODEL_SAVE_DIR, self.CHECKPOINT_DIR]:\n","            os.makedirs(dir_path, exist_ok=True)\n","\n","        # Device\n","        self.DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","\n","        # Configurar logging\n","        self.logger = setup_logging(self.OUTPUT_DIR)\n","        self.logger.info(f\"Experimento iniciado: {self.experiment_name}\")\n","        self.logger.info(f\"Modelo seleccionado: {self.MODEL_NAME}\")\n","        self.logger.info(f\"Dispositivo: {self.DEVICE}\")\n","\n","    def display_config(self):\n","        \"\"\"Muestra la configuraci√≥n actual\"\"\"\n","        print(\"\\n\" + \"=\"*80)\n","        print(\"‚öôÔ∏è  CONFIGURACI√ìN DEL MODELO\")\n","        print(\"=\"*80)\n","        print(f\"\\nü§ñ Modelo: {self.MODEL_NAME}\")\n","        print(f\"   Tipo: {self.model_type}\")\n","        print(f\"   Experimento: {self.experiment_name}\")\n","        print(f\"\\nüìÇ Rutas:\")\n","        print(f\"   Datos: {self.DATA_PATH}\")\n","        print(f\"   Output: {self.OUTPUT_DIR}\")\n","        print(f\"   Modelo final: {self.MODEL_SAVE_DIR}\")\n","        print(f\"\\nüìä Datos:\")\n","        print(f\"   Columna texto: {self.TEXT_COLUMN}\")\n","        print(f\"   Columna target: {self.TARGET_COLUMN}\")\n","        print(f\"   Max length: {self.MAX_LENGTH}\")\n","        print(f\"\\nüéõÔ∏è  Entrenamiento:\")\n","        print(f\"   Batch size: {self.BATCH_SIZE}\")\n","        print(f\"   Learning rate: {self.LEARNING_RATE}\")\n","        print(f\"   Epochs: {self.NUM_EPOCHS}\")\n","        print(f\"   Early stopping: {self.EARLY_STOPPING_PATIENCE} epochs\")\n","        print(f\"\\nüíæ Divisi√≥n de datos:\")\n","        print(f\"   Test: {self.TEST_SIZE*100:.0f}%\")\n","        print(f\"   Validaci√≥n: {self.VAL_SIZE*100:.0f}%\")\n","        print(f\"   Train: {(1-self.TEST_SIZE-self.VAL_SIZE)*100:.0f}%\")\n","        print(\"\\n\" + \"=\"*80 + \"\\n\")\n","\n","    def save_config(self):\n","        \"\"\"Guarda la configuraci√≥n en JSON\"\"\"\n","        config_dict = {\n","            'model_name': self.MODEL_NAME,\n","            'model_type': self.model_type,\n","            'experiment_name': self.experiment_name,\n","            'data_path': self.DATA_PATH,\n","            'text_column': self.TEXT_COLUMN,\n","            'target_column': self.TARGET_COLUMN,\n","            'max_length': self.MAX_LENGTH,\n","            'batch_size': self.BATCH_SIZE,\n","            'learning_rate': self.LEARNING_RATE,\n","            'num_epochs': self.NUM_EPOCHS,\n","            'test_size': self.TEST_SIZE,\n","            'val_size': self.VAL_SIZE,\n","            'random_state': self.RANDOM_STATE,\n","            'min_samples_per_class': self.MIN_SAMPLES_PER_CLASS,\n","            'device': self.DEVICE,\n","            'timestamp': datetime.now().isoformat()\n","        }\n","\n","        config_path = os.path.join(self.OUTPUT_DIR, 'config.json')\n","        with open(config_path, 'w', encoding='utf-8') as f:\n","            json.dump(config_dict, f, indent=2, ensure_ascii=False)\n","\n","        self.logger.info(f\"Configuraci√≥n guardada en: {config_path}\")\n","        return config_path\n","\n","\n","# Inicializar configuraci√≥n\n","config = ModelConfig()\n","config.display_config()\n","config.save_config()\n"],"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","================================================================================\n","‚öôÔ∏è  CONFIGURACI√ìN DEL MODELO\n","================================================================================\n","\n","ü§ñ Modelo: dccuchile/bert-base-spanish-wwm-cased\n","   Tipo: bert\n","   Experimento: bert-base-spanish-wwm-cased_20251121_140243\n","\n","üìÇ Rutas:\n","   Datos: /content/drive/MyDrive/classification_coding_open_ended_occupational_responses_ENAHO/CLEAN_DATA/BASE_LIMPIA_VF.parquet\n","   Output: /content/drive/MyDrive/classification_coding_open_ended_occupational_responses_ENAHO/results/beto_base/bert-base-spanish-wwm-cased_20251121_140243\n","   Modelo final: /content/drive/MyDrive/classification_coding_open_ended_occupational_responses_ENAHO/results/beto_base/bert-base-spanish-wwm-cased_20251121_140243/final_model\n","\n","üìä Datos:\n","   Columna texto: texto_final\n","   Columna target: p505r4\n","   Max length: 128\n","\n","üéõÔ∏è  Entrenamiento:\n","   Batch size: 16\n","   Learning rate: 2e-05\n","   Epochs: 3\n","   Early stopping: 3 epochs\n","\n","üíæ Divisi√≥n de datos:\n","   Test: 15%\n","   Validaci√≥n: 15%\n","   Train: 70%\n","\n","================================================================================\n","\n"]},{"output_type":"execute_result","data":{"text/plain":["'/content/drive/MyDrive/classification_coding_open_ended_occupational_responses_ENAHO/results/beto_base/bert-base-spanish-wwm-cased_20251121_140243/config.json'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":5}],"id":"xfu88qZ_IKbs"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qfG0DkcRIKbt","executionInfo":{"status":"ok","timestamp":1763733776221,"user_tz":300,"elapsed":10296,"user":{"displayName":"Brayan Poma Huaman","userId":"00419443262019466393"}},"outputId":"109f2cec-50dd-4dc8-fe3c-e29022fc6e7f"},"source":["# ============================================================================\n","# üìÇ CARGA Y VALIDACI√ìN DE DATOS\n","# ============================================================================\n","\n","class DataLoader:\n","    \"\"\"Cargador y validador de datos con manejo robusto de errores\"\"\"\n","\n","    def __init__(self, config):\n","        self.config = config\n","        self.logger = config.logger\n","\n","    def load_data(self):\n","        \"\"\"\n","        Carga datos desde archivo con validaci√≥n\n","\n","        Returns:\n","            pd.DataFrame: Datos cargados\n","        \"\"\"\n","        try:\n","            self.logger.info(f\"Cargando datos desde: {self.config.DATA_PATH}\")\n","\n","            # Verificar que el archivo existe\n","            if not os.path.exists(self.config.DATA_PATH):\n","                raise FileNotFoundError(\n","                    f\"‚ùå El archivo no existe: {self.config.DATA_PATH}\\n\"\n","                    f\"   Por favor, verifica la ruta en ModelConfig.DATA_PATH\"\n","                )\n","\n","            # Cargar seg√∫n extensi√≥n\n","            file_ext = os.path.splitext(self.config.DATA_PATH)[1].lower()\n","\n","            if file_ext == '.parquet':\n","                df = pd.read_parquet(self.config.DATA_PATH)\n","            elif file_ext == '.csv':\n","                df = pd.read_csv(self.config.DATA_PATH)\n","            elif file_ext in ['.xlsx', '.xls']:\n","                df = pd.read_excel(self.config.DATA_PATH)\n","            else:\n","                raise ValueError(\n","                    f\"‚ùå Formato no soportado: {file_ext}\\n\"\n","                    f\"   Formatos v√°lidos: .parquet, .csv, .xlsx, .xls\"\n","                )\n","\n","            self.logger.info(f\"‚úÖ Datos cargados: {df.shape[0]:,} filas x {df.shape[1]} columnas\")\n","\n","            return df\n","\n","        except Exception as e:\n","            self.logger.error(f\"‚ùå Error al cargar datos: {str(e)}\")\n","            raise\n","\n","    def validate_data(self, df):\n","        \"\"\"\n","        Valida que los datos tengan las columnas necesarias\n","\n","        Args:\n","            df: DataFrame a validar\n","\n","        Raises:\n","            ValueError: Si faltan columnas requeridas\n","        \"\"\"\n","        self.logger.info(\"Validando estructura de datos...\")\n","\n","        # Verificar columnas requeridas\n","        required_cols = [self.config.TEXT_COLUMN, self.config.TARGET_COLUMN]\n","        missing_cols = [col for col in required_cols if col not in df.columns]\n","\n","        if missing_cols:\n","            available_cols = list(df.columns)\n","            raise ValueError(\n","                f\"‚ùå Columnas faltantes: {missing_cols}\\n\"\n","                f\"   Columnas disponibles: {available_cols}\\n\"\n","                f\"   Verifica TEXT_COLUMN y TARGET_COLUMN en ModelConfig\"\n","            )\n","\n","        # Validar datos no nulos\n","        null_text = df[self.config.TEXT_COLUMN].isna().sum()\n","        null_target = df[self.config.TARGET_COLUMN].isna().sum()\n","\n","        self.logger.info(\n","            f\"   Valores nulos - Texto: {null_text:,}, Target: {null_target:,}\"\n","        )\n","\n","        # Validar textos vac√≠os\n","        empty_text = (df[self.config.TEXT_COLUMN].str.strip() == '').sum()\n","        if empty_text > 0:\n","            self.logger.warning(f\"   ‚ö†Ô∏è  Textos vac√≠os: {empty_text:,}\")\n","\n","        self.logger.info(\"‚úÖ Validaci√≥n completada\")\n","\n","    def filter_valid_records(self, df):\n","        \"\"\"\n","        Filtra registros v√°lidos (no nulos, no vac√≠os)\n","\n","        Args:\n","            df: DataFrame original\n","\n","        Returns:\n","            pd.DataFrame: DataFrame filtrado\n","        \"\"\"\n","        self.logger.info(\"Filtrando registros v√°lidos...\")\n","\n","        initial_count = len(df)\n","\n","        # Filtrar nulos y vac√≠os\n","        df_clean = df[\n","            df[self.config.TEXT_COLUMN].notna() &\n","            df[self.config.TARGET_COLUMN].notna() &\n","            (df[self.config.TEXT_COLUMN].str.strip() != '')\n","        ].copy()\n","\n","        final_count = len(df_clean)\n","        removed = initial_count - final_count\n","\n","        self.logger.info(\n","            f\"   Registros iniciales: {initial_count:,}\\n\"\n","            f\"   Registros v√°lidos: {final_count:,}\\n\"\n","            f\"   Removidos: {removed:,} ({removed/initial_count*100:.2f}%)\"\n","        )\n","\n","        if final_count == 0:\n","            raise ValueError(\n","                \"‚ùå No quedan registros v√°lidos despu√©s del filtrado\\n\"\n","                \"   Verifica la calidad de tus datos\"\n","            )\n","\n","        return df_clean\n","\n","    def filter_rare_classes(self, df):\n","        \"\"\"\n","        Filtra clases con pocas muestras\n","\n","        Args:\n","            df: DataFrame\n","\n","        Returns:\n","            pd.DataFrame: DataFrame filtrado\n","        \"\"\"\n","        self.logger.info(\n","            f\"Filtrando clases con < {self.config.MIN_SAMPLES_PER_CLASS} muestras...\"\n","        )\n","\n","        # Contar muestras por clase\n","        class_counts = df[self.config.TARGET_COLUMN].value_counts()\n","\n","        # Identificar clases v√°lidas\n","        valid_classes = class_counts[class_counts >= self.config.MIN_SAMPLES_PER_CLASS].index\n","        rare_classes = class_counts[class_counts < self.config.MIN_SAMPLES_PER_CLASS]\n","\n","        # Filtrar\n","        df_filtered = df[df[self.config.TARGET_COLUMN].isin(valid_classes)].copy()\n","\n","        self.logger.info(\n","            f\"   Clases originales: {len(class_counts):,}\\n\"\n","            f\"   Clases mantenidas: {len(valid_classes):,}\\n\"\n","            f\"   Clases removidas: {len(rare_classes):,}\\n\"\n","            f\"   Registros antes: {len(df):,}\\n\"\n","            f\"   Registros despu√©s: {len(df_filtered):,}\"\n","        )\n","\n","        if len(df_filtered) == 0:\n","            raise ValueError(\n","                f\"‚ùå No quedan registros despu√©s de filtrar clases raras\\n\"\n","                f\"   Considera reducir MIN_SAMPLES_PER_CLASS\"\n","            )\n","\n","        return df_filtered\n","\n","    def create_label_mapping(self, df):\n","        \"\"\"\n","        Crea mapeo de etiquetas a √≠ndices\n","\n","        Args:\n","            df: DataFrame\n","\n","        Returns:\n","            tuple: (df_with_labels, label2id, id2label)\n","        \"\"\"\n","        self.logger.info(\"Creando mapeo de etiquetas...\")\n","\n","        # Obtener clases √∫nicas ordenadas\n","        unique_labels = sorted(df[self.config.TARGET_COLUMN].unique())\n","\n","        # Crear mapeos\n","        label2id = {label: idx for idx, label in enumerate(unique_labels)}\n","        id2label = {idx: label for label, idx in label2id.items()}\n","\n","        # Agregar columna de √≠ndices num√©ricos\n","        df['label_id'] = df[self.config.TARGET_COLUMN].map(label2id)\n","\n","        # Verificar que no hay nulos (no deber√≠a pasar)\n","        if df['label_id'].isna().any():\n","            raise ValueError(\"‚ùå Error en el mapeo de etiquetas\")\n","\n","        self.logger.info(\n","            f\"‚úÖ Mapeo creado: {len(label2id)} clases (√≠ndices 0-{len(label2id)-1})\"\n","        )\n","\n","        # Mostrar distribuci√≥n de clases\n","        class_dist = df[self.config.TARGET_COLUMN].value_counts()\n","        self.logger.info(\n","            f\"   Clase m√°s frecuente: {class_dist.index[0]} ({class_dist.iloc[0]:,} muestras)\\n\"\n","            f\"   Clase menos frecuente: {class_dist.index[-1]} ({class_dist.iloc[-1]:,} muestras)\\n\"\n","            f\"   Promedio por clase: {class_dist.mean():.1f}\"\n","        )\n","\n","        return df, label2id, id2label\n","\n","    def split_data(self, df):\n","        \"\"\"\n","        Divide datos en train, validation y test con estratificaci√≥n\n","\n","        Args:\n","            df: DataFrame\n","\n","        Returns:\n","            tuple: (train_df, val_df, test_df)\n","        \"\"\"\n","        self.logger.info(\"Dividiendo datos...\")\n","\n","        try:\n","            # Primero separar test\n","            train_val, test = train_test_split(\n","                df,\n","                test_size=self.config.TEST_SIZE,\n","                random_state=self.config.RANDOM_STATE,\n","                stratify=df['label_id']\n","            )\n","\n","            # Luego separar train y validation\n","            val_size_adjusted = self.config.VAL_SIZE / (1 - self.config.TEST_SIZE)\n","            train, val = train_test_split(\n","                train_val,\n","                test_size=val_size_adjusted,\n","                random_state=self.config.RANDOM_STATE,\n","                stratify=train_val['label_id']\n","            )\n","\n","            self.logger.info(\n","                f\"‚úÖ Divisi√≥n completada:\\n\"\n","                f\"   Train: {len(train):,} ({len(train)/len(df)*100:.1f}%)\\n\"\n","                f\"   Validation: {len(val):,} ({len(val)/len(df)*100:.1f}%)\\n\"\n","                f\"   Test: {len(test):,} ({len(test)/len(df)*100:.1f}%)\"\n","            )\n","\n","            return train, val, test\n","\n","        except ValueError as e:\n","            self.logger.error(\n","                f\"‚ùå Error al dividir datos: {str(e)}\\n\"\n","                f\"   Puede ser que algunas clases tengan muy pocas muestras\\n\"\n","                f\"   Considera aumentar MIN_SAMPLES_PER_CLASS\"\n","            )\n","            raise\n","\n","\n","# ============================================================================\n","# EJECUTAR CARGA DE DATOS\n","# ============================================================================\n","\n","print(\"\\n\" + \"=\"*80)\n","print(\"üìÇ CARGANDO Y PREPARANDO DATOS\")\n","print(\"=\"*80 + \"\\n\")\n","\n","try:\n","    # Inicializar cargador\n","    data_loader = DataLoader(config)\n","\n","    # Cargar datos\n","    df_raw = data_loader.load_data()\n","\n","    # Validar estructura\n","    data_loader.validate_data(df_raw)\n","\n","    # Filtrar registros v√°lidos\n","    df_valid = data_loader.filter_valid_records(df_raw)\n","\n","    # Filtrar clases raras\n","    df_filtered = data_loader.filter_rare_classes(df_valid)\n","\n","    # Crear mapeo de etiquetas\n","    df_final, label2id, id2label = data_loader.create_label_mapping(df_filtered)\n","\n","    # Dividir datos\n","    train_df, val_df, test_df = data_loader.split_data(df_final)\n","\n","    print(\"\\n\" + \"=\"*80)\n","    print(\"‚úÖ DATOS PREPARADOS EXITOSAMENTE\")\n","    print(\"=\"*80 + \"\\n\")\n","\n","    # Guardar informaci√≥n de las clases\n","    class_info = {\n","        'num_classes': len(label2id),\n","        'label2id': label2id,\n","        'id2label': id2label,\n","        'class_distribution': df_final[config.TARGET_COLUMN].value_counts().to_dict()\n","    }\n","\n","    with open(os.path.join(config.OUTPUT_DIR, 'class_info.json'), 'w', encoding='utf-8') as f:\n","        json.dump(class_info, f, indent=2, ensure_ascii=False)\n","\n","except Exception as e:\n","    print(\"\\n\" + \"=\"*80)\n","    print(\"‚ùå ERROR EN LA CARGA DE DATOS\")\n","    print(\"=\"*80)\n","    print(f\"\\n{str(e)}\\n\")\n","    print(\"Por favor, revisa:\")\n","    print(\"1. La ruta del archivo en ModelConfig.DATA_PATH\")\n","    print(\"2. Los nombres de columnas en TEXT_COLUMN y TARGET_COLUMN\")\n","    print(\"3. La calidad de tus datos (nulos, vac√≠os, etc.)\")\n","    print(\"\\n\" + \"=\"*80 + \"\\n\")\n","    raise\n"],"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","================================================================================\n","üìÇ CARGANDO Y PREPARANDO DATOS\n","================================================================================\n","\n","\n","================================================================================\n","‚úÖ DATOS PREPARADOS EXITOSAMENTE\n","================================================================================\n","\n"]}],"id":"qfG0DkcRIKbt"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":576,"referenced_widgets":["ba7ce4dc95ff4efebaf34ad2750aaba5","fea70654d0924bbead2fb47828bc375d","01c7d926d3bb430eac3e6dc04c360879","990e95ffd72a48848d727df888b7696e","0e84dd46c53b4e10b1a7284431dac245","dfdbfaae225d4da7bd084541a1eb0021","2cf70107c12d43b18efe248cddf046c9","1d1a174492d84a78bfb3242b19a336c0","58c76a154d4349a8865a7545bd6ae275","4866bed5bada41189600e1cbe0ebfe69","b0f607899b7240968a954435297588d7","ebb98ae5ab844a449d808c53a9c0b904","719c9cf6461c4c24bad803c6380c7a61","2ba10e031aca4c759cef64416a79757d","f40b360ccf854c1dbc49a2144b7f65d2","42c57bfb89734170b3dff481fd0a8aa3","174a67ecee864fe295914d58d1ad0f75","8c1909822fa54af398574783565d3aa3","6e32b81e47d849cb8936e1773c0e0706","2de61fa70b5f43f5a77d6c31d5cce96f","934d14f09eda432b8af0aab03ea346d3","5af9f580716e4d1f8f4a85a2782269d3","4b7fdcb313244978be8808ac56bd2fae","0271494c1eb04ecd9d56056da0bc4549","f151b248d1134db8b233e754f2978283","ff438066ac0b47dfa5ab45a551280924","25d3c99c0a2a4d0a8c66c1d2f0a4e141","708c28d35839424e80dad6a0791e5c43","2504530a51f34ff79d629edf27dfe774","86f641ac27c545309238ff2ca87398ee","1547b0710a2944fa9f31fb64c9a420ea","d81717a212734c49979f337e09d890cd","40d4b8028d9d4052bb0b91d3bcf743bf","be24a7e8987846f7abd6b3e5dd83e142","5df6101530fc4326b5a03b45aafc887b","7a2f9970b5ff48368b1584c3154eb233","9ce4fbc5e0ed4164a273ad3145f3fd69","1def19526f854d698b1b7942f7861feb","00a6fd655d5c4d4aa85eea4bfed7f1b1","dc3f64cd875d4e0b97d6658beb6788e9","7dd80cd870d141b9b67744144e7389b3","9b0220ad63994a68b387ea627cf7afe2","39d95839367b44bea79321940795ee33","3129bd2bd4394cfc9d7b47df943985c3","59c05bb70a9842f2aa423d18e9478806","c14b15d3db3b410faac6d655558fc0c0","66096d761361486ab48925b197636734","639e754456f64389b2d612784757dc41","d6faddff42ea4fa9ba4efaa74c84abad","8083b38ef0cc4ea39bad3014bb30aa87","64b7f19e621a48cc8719afeaf6929239","12f14eaebda244ce81c5623bd2919624","0bcda67a069e41db8e791b11b1183fa0","cfc58da9aca447ca8d5afca79c6ddf8e","d5d1f11d3752426b91193eacd92de581"]},"id":"K4LnQZmXIKbv","executionInfo":{"status":"ok","timestamp":1763733781182,"user_tz":300,"elapsed":4957,"user":{"displayName":"Brayan Poma Huaman","userId":"00419443262019466393"}},"outputId":"09d47503-da78-4b8e-a783-27aaf505051d"},"source":["# ============================================================================\n","# üî§ DATASET Y TOKENIZACI√ìN\n","# ============================================================================\n","\n","class TextClassificationDataset(Dataset):\n","    \"\"\"\n","    Dataset personalizado para clasificaci√≥n de texto\n","    Compatible con cualquier modelo de Hugging Face\n","    \"\"\"\n","\n","    def __init__(self, texts, labels, tokenizer, max_length):\n","        \"\"\"\n","        Args:\n","            texts: Lista de textos\n","            labels: Lista de etiquetas (√≠ndices num√©ricos)\n","            tokenizer: Tokenizer de Hugging Face\n","            max_length: Longitud m√°xima de tokens\n","        \"\"\"\n","        self.texts = texts\n","        self.labels = labels\n","        self.tokenizer = tokenizer\n","        self.max_length = max_length\n","\n","    def __len__(self):\n","        return len(self.texts)\n","\n","    def __getitem__(self, idx):\n","        \"\"\"\n","        Obtiene un ejemplo tokenizado\n","\n","        Returns:\n","            dict: Diccionario con input_ids, attention_mask y labels\n","        \"\"\"\n","        text = str(self.texts[idx])\n","        label = int(self.labels[idx])\n","\n","        # Tokenizar\n","        encoding = self.tokenizer(\n","            text,\n","            max_length=self.max_length,\n","            padding='max_length',\n","            truncation=True,\n","            return_tensors='pt'\n","        )\n","\n","        return {\n","            'input_ids': encoding['input_ids'].flatten(),\n","            'attention_mask': encoding['attention_mask'].flatten(),\n","            'labels': torch.tensor(label, dtype=torch.long)\n","        }\n","\n","\n","# ============================================================================\n","# INICIALIZAR TOKENIZER Y DATASETS\n","# ============================================================================\n","\n","print(\"\\n\" + \"=\"*80)\n","print(\"üî§ INICIALIZANDO TOKENIZER Y DATASETS\")\n","print(\"=\"*80 + \"\\n\")\n","\n","try:\n","    # Cargar tokenizer\n","    config.logger.info(f\"Cargando tokenizer: {config.MODEL_NAME}\")\n","    tokenizer = AutoTokenizer.from_pretrained(config.MODEL_NAME)\n","\n","    print(f\"‚úÖ Tokenizer cargado: {config.MODEL_NAME}\")\n","    print(f\"   Vocabulario: {len(tokenizer):,} tokens\")\n","    print(f\"   Tipo: {tokenizer.__class__.__name__}\")\n","\n","    # Crear datasets\n","    config.logger.info(\"Creando datasets...\")\n","\n","    train_dataset = TextClassificationDataset(\n","        texts=train_df[config.TEXT_COLUMN].tolist(),\n","        labels=train_df['label_id'].tolist(),\n","        tokenizer=tokenizer,\n","        max_length=config.MAX_LENGTH\n","    )\n","\n","    val_dataset = TextClassificationDataset(\n","        texts=val_df[config.TEXT_COLUMN].tolist(),\n","        labels=val_df['label_id'].tolist(),\n","        tokenizer=tokenizer,\n","        max_length=config.MAX_LENGTH\n","    )\n","\n","    test_dataset = TextClassificationDataset(\n","        texts=test_df[config.TEXT_COLUMN].tolist(),\n","        labels=test_df['label_id'].tolist(),\n","        tokenizer=tokenizer,\n","        max_length=config.MAX_LENGTH\n","    )\n","\n","    print(f\"\\n‚úÖ Datasets creados:\")\n","    print(f\"   Train: {len(train_dataset):,} ejemplos\")\n","    print(f\"   Validation: {len(val_dataset):,} ejemplos\")\n","    print(f\"   Test: {len(test_dataset):,} ejemplos\")\n","\n","    # Verificar un ejemplo\n","    sample = train_dataset[0]\n","    print(f\"\\nüìù Ejemplo de muestra tokenizada:\")\n","    print(f\"   Input IDs shape: {sample['input_ids'].shape}\")\n","    print(f\"   Attention mask shape: {sample['attention_mask'].shape}\")\n","    print(f\"   Label: {sample['labels'].item()}\")\n","\n","    print(\"\\n\" + \"=\"*80)\n","    print(\"‚úÖ TOKENIZACI√ìN COMPLETADA\")\n","    print(\"=\"*80 + \"\\n\")\n","\n","except Exception as e:\n","    print(\"\\n\" + \"=\"*80)\n","    print(\"‚ùå ERROR EN LA TOKENIZACI√ìN\")\n","    print(\"=\"*80)\n","    print(f\"\\n{str(e)}\\n\")\n","    print(\"Posibles causas:\")\n","    print(\"1. El modelo no est√° disponible (verifica MODEL_NAME)\")\n","    print(\"2. No hay conexi√≥n a internet para descargar el tokenizer\")\n","    print(\"3. Problema con los datos de entrada\")\n","    print(\"\\n\" + \"=\"*80 + \"\\n\")\n","    raise\n"],"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","================================================================================\n","üî§ INICIALIZANDO TOKENIZER Y DATASETS\n","================================================================================\n","\n"]},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/364 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ba7ce4dc95ff4efebaf34ad2750aaba5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/648 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ebb98ae5ab844a449d808c53a9c0b904"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["vocab.txt: 0.00B [00:00, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4b7fdcb313244978be8808ac56bd2fae"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json: 0.00B [00:00, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"be24a7e8987846f7abd6b3e5dd83e142"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["special_tokens_map.json:   0%|          | 0.00/134 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"59c05bb70a9842f2aa423d18e9478806"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["‚úÖ Tokenizer cargado: dccuchile/bert-base-spanish-wwm-cased\n","   Vocabulario: 31,002 tokens\n","   Tipo: BertTokenizerFast\n","\n","‚úÖ Datasets creados:\n","   Train: 220,937 ejemplos\n","   Validation: 47,344 ejemplos\n","   Test: 47,344 ejemplos\n","\n","üìù Ejemplo de muestra tokenizada:\n","   Input IDs shape: torch.Size([128])\n","   Attention mask shape: torch.Size([128])\n","   Label: 356\n","\n","================================================================================\n","‚úÖ TOKENIZACI√ìN COMPLETADA\n","================================================================================\n","\n"]}],"id":"K4LnQZmXIKbv"},{"cell_type":"code","metadata":{"id":"EcEm9PKOIKbw","executionInfo":{"status":"ok","timestamp":1763733781237,"user_tz":300,"elapsed":53,"user":{"displayName":"Brayan Poma Huaman","userId":"00419443262019466393"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"286e3521-b610-43c6-e8ba-1e81865bfc90"},"source":["# ============================================================================\n","# üìä M√âTRICAS DETALLADAS\n","# ============================================================================\n","\n","def compute_detailed_metrics(eval_pred):\n","    \"\"\"\n","    Calcula m√©tricas detalladas: Accuracy, Precision, Recall, F1\n","    Con variantes: macro, micro y weighted\n","\n","    Args:\n","        eval_pred: Predicciones del modelo (predictions, label_ids)\n","\n","    Returns:\n","        dict: Diccionario con todas las m√©tricas\n","    \"\"\"\n","    predictions, labels = eval_pred\n","\n","    # Obtener predicciones (argmax si son logits)\n","    if predictions.ndim > 1:\n","        preds = np.argmax(predictions, axis=1)\n","    else:\n","        preds = predictions\n","\n","    # Accuracy\n","    accuracy = accuracy_score(labels, preds)\n","\n","    # Precision, Recall, F1 con diferentes promedios\n","    # Macro: promedio sin ponderar (todas las clases tienen el mismo peso)\n","    precision_macro, recall_macro, f1_macro, _ = precision_recall_fscore_support(\n","        labels, preds, average='macro', zero_division=0\n","    )\n","\n","    # Micro: agregado global (considera todas las muestras por igual)\n","    precision_micro, recall_micro, f1_micro, _ = precision_recall_fscore_support(\n","        labels, preds, average='micro', zero_division=0\n","    )\n","\n","    # Weighted: promedio ponderado por soporte de cada clase\n","    precision_weighted, recall_weighted, f1_weighted, _ = precision_recall_fscore_support(\n","        labels, preds, average='weighted', zero_division=0\n","    )\n","\n","    return {\n","        # Accuracy (solo una versi√≥n)\n","        'accuracy': accuracy,\n","\n","        # F1 Score\n","        'f1_macro': f1_macro,\n","        'f1_micro': f1_micro,\n","        'f1_weighted': f1_weighted,\n","\n","        # Precision\n","        'precision_macro': precision_macro,\n","        'precision_micro': precision_micro,\n","        'precision_weighted': precision_weighted,\n","\n","        # Recall\n","        'recall_macro': recall_macro,\n","        'recall_micro': recall_micro,\n","        'recall_weighted': recall_weighted,\n","    }\n","\n","\n","\n","def display_metrics(metrics, title=\"M√©tricas\"):\n","    \"\"\"Muestra las m√©tricas de forma organizada\"\"\"\n","    print(\"\\n\" + \"=\"*80)\n","    print(f\"üìä {title.upper()}\")\n","    print(\"=\"*80 + \"\\n\")\n","\n","    # Mostrar Loss si existe\n","    loss = (\n","        metrics.get('test_loss') or\n","        metrics.get('eval_loss') or\n","        metrics.get('loss', None)\n","    )\n","    if loss is not None:\n","        print(f\"üí• LOSS: {loss:.4f}\")\n","\n","    # Accuracy\n","    acc = (\n","        metrics.get('test_accuracy') or\n","        metrics.get('eval_accuracy') or\n","        metrics.get('accuracy', 0)\n","    )\n","    print(f\"üéØ ACCURACY: {acc:.4f}\")\n","    print(\"\\n\" + \"-\"*80)\n","\n","    # Tabla\n","    print(f\"\\n{'M√©trica':<20} {'Macro':>12} {'Micro':>12} {'Weighted':>12}\")\n","    print(\"-\"*60)\n","\n","    def get_m(name):\n","        return (\n","            metrics.get(f'test_{name}') or\n","            metrics.get(f'eval_{name}') or\n","            metrics.get(name, 0)\n","        )\n","\n","    print(f\"{'F1 Score':<20} {get_m('f1_macro'):>12.4f} {get_m('f1_micro'):>12.4f} {get_m('f1_weighted'):>12.4f}\")\n","    print(f\"{'Precision':<20} {get_m('precision_macro'):>12.4f} {get_m('precision_micro'):>12.4f} {get_m('precision_weighted'):>12.4f}\")\n","    print(f\"{'Recall':<20} {get_m('recall_macro'):>12.4f} {get_m('recall_micro'):>12.4f} {get_m('recall_weighted'):>12.4f}\")\n","\n","    print(\"\\n\" + \"=\"*80 + \"\\n\")\n","\n","\n","print(\"‚úÖ Funciones de m√©tricas cargadas (con loss incluido)\")\n"],"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["‚úÖ Funciones de m√©tricas cargadas (con loss incluido)\n"]}],"id":"EcEm9PKOIKbw"},{"cell_type":"code","metadata":{"id":"qXtQxEM-IKbw","executionInfo":{"status":"ok","timestamp":1763733782763,"user_tz":300,"elapsed":1532,"user":{"displayName":"Brayan Poma Huaman","userId":"00419443262019466393"}},"colab":{"base_uri":"https://localhost:8080/","height":399,"referenced_widgets":["7343da5b79e642f9b24960bf9ddef20b","e777724e095b42f9ace97e86de61c071","30334d3fbd98443988be7363b1e16868","604b946394264805bf5901c437ab6ae5","3cc1a697dfac4079a380fbb07a2400ec","7acafb6025e0489a81b22b03223f158d","14ecf234f44c4bc19241571a7ce92a6e","d33160b59abb4406aab05c507ad97fef","78844c33d4c14dbaa899f1b43c4b7ab2","25c5937bf9174c6e987d996ffdc98c0f","0f643d3252fd45419d18c10be49f32af"]},"outputId":"6ecda0d5-d014-4e89-dc07-3b71df60549d"},"source":["# ============================================================================\n","# ü§ñ INICIALIZACI√ìN DEL MODELO\n","# ============================================================================\n","\n","print(\"\\n\" + \"=\"*80)\n","print(\"ü§ñ INICIALIZANDO MODELO\")\n","print(\"=\"*80 + \"\\n\")\n","\n","try:\n","    config.logger.info(f\"Cargando modelo: {config.MODEL_NAME}\")\n","\n","    # Cargar modelo\n","    model = AutoModelForSequenceClassification.from_pretrained(\n","        config.MODEL_NAME,\n","        num_labels=len(label2id),\n","        id2label=id2label,\n","        label2id=label2id,\n","        problem_type=\"single_label_classification\"\n","    )\n","\n","    # Mover a GPU si est√° disponible\n","    model.to(config.DEVICE)\n","\n","    # Informaci√≥n del modelo\n","    num_params = sum(p.numel() for p in model.parameters())\n","    num_trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n","\n","    print(f\"‚úÖ Modelo cargado: {config.MODEL_NAME}\")\n","    print(f\"   Tipo: {model.__class__.__name__}\")\n","    print(f\"   N√∫mero de clases: {len(label2id)}\")\n","    print(f\"   Par√°metros totales: {num_params:,}\")\n","    print(f\"   Par√°metros entrenables: {num_trainable:,}\")\n","    print(f\"   Dispositivo: {config.DEVICE}\")\n","\n","    if torch.cuda.is_available():\n","        print(f\"   Memoria GPU asignada: {torch.cuda.memory_allocated(0) / 1e9:.2f} GB\")\n","\n","    config.logger.info(f\"Modelo inicializado con {num_params:,} par√°metros\")\n","\n","    print(\"\\n\" + \"=\"*80)\n","    print(\"‚úÖ MODELO LISTO PARA ENTRENAMIENTO\")\n","    print(\"=\"*80 + \"\\n\")\n","\n","except Exception as e:\n","    print(\"\\n\" + \"=\"*80)\n","    print(\"‚ùå ERROR AL CARGAR EL MODELO\")\n","    print(\"=\"*80)\n","    print(f\"\\n{str(e)}\\n\")\n","    print(\"Posibles causas:\")\n","    print(\"1. El nombre del modelo es incorrecto\")\n","    print(\"2. No hay conexi√≥n a internet para descargar el modelo\")\n","    print(\"3. No hay suficiente memoria GPU/RAM\")\n","    print(\"4. Incompatibilidad de versiones de transformers\")\n","    print(\"\\nModelos v√°lidos:\")\n","    print(\"- FacebookAI/xlm-roberta-base\")\n","    print(\"- dccuchile/bert-base-spanish-wwm-cased\")\n","    print(\"\\n\" + \"=\"*80 + \"\\n\")\n","    raise\n"],"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","================================================================================\n","ü§ñ INICIALIZANDO MODELO\n","================================================================================\n","\n"]},{"output_type":"display_data","data":{"text/plain":["pytorch_model.bin:   0%|          | 0.00/440M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7343da5b79e642f9b24960bf9ddef20b"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dccuchile/bert-base-spanish-wwm-cased and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["‚úÖ Modelo cargado: dccuchile/bert-base-spanish-wwm-cased\n","   Tipo: BertForSequenceClassification\n","   N√∫mero de clases: 357\n","   Par√°metros totales: 110,125,413\n","   Par√°metros entrenables: 110,125,413\n","   Dispositivo: cuda\n","   Memoria GPU asignada: 0.44 GB\n","\n","================================================================================\n","‚úÖ MODELO LISTO PARA ENTRENAMIENTO\n","================================================================================\n","\n"]}],"id":"qXtQxEM-IKbw"},{"cell_type":"code","metadata":{"id":"W_6d3qt-IKbx","executionInfo":{"status":"ok","timestamp":1763733783483,"user_tz":300,"elapsed":718,"user":{"displayName":"Brayan Poma Huaman","userId":"00419443262019466393"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"d7596a09-9cd7-4c59-ae58-09fa4d81405c"},"source":["# ============================================================================\n","# ‚öôÔ∏è  CONFIGURACI√ìN DEL ENTRENAMIENTO\n","# ============================================================================\n","\n","print(\"\\n\" + \"=\"*80)\n","print(\"‚öôÔ∏è  CONFIGURANDO ENTRENAMIENTO\")\n","print(\"=\"*80 + \"\\n\")\n","\n","# Configuraci√≥n de argumentos de entrenamiento\n","training_args = TrainingArguments(\n","    # Directorios\n","    output_dir=config.CHECKPOINT_DIR,\n","    logging_dir=os.path.join(config.OUTPUT_DIR, 'logs'),\n","\n","    # Hiperpar√°metros\n","    learning_rate=config.LEARNING_RATE,\n","    per_device_train_batch_size=config.BATCH_SIZE,\n","    per_device_eval_batch_size=config.BATCH_SIZE,\n","    num_train_epochs=config.NUM_EPOCHS,\n","    warmup_steps=config.WARMUP_STEPS,\n","    weight_decay=config.WEIGHT_DECAY,\n","\n","    # Evaluaci√≥n y guardado\n","    eval_strategy=\"epoch\",\n","    save_strategy=\"epoch\",\n","    load_best_model_at_end=True,\n","    metric_for_best_model=\"f1_weighted\",  # Usar F1 weighted como m√©trica principal\n","    greater_is_better=True,\n","\n","    # Logging\n","    logging_steps=100,\n","    logging_strategy=\"steps\",\n","\n","    # Optimizaci√≥n\n","    fp16=torch.cuda.is_available(),  # Precisi√≥n mixta si hay GPU\n","    gradient_accumulation_steps=1,\n","\n","    # Otros\n","    seed=config.RANDOM_STATE,\n","    report_to=\"none\",  # Desactivar reportes externos\n","    disable_tqdm=False,  # Mantener barra de progreso\n",")\n","\n","# Inicializar Trainer\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=train_dataset,\n","    eval_dataset=val_dataset,\n","    compute_metrics=compute_detailed_metrics,\n","    callbacks=[\n","        EarlyStoppingCallback(\n","            early_stopping_patience=config.EARLY_STOPPING_PATIENCE\n","        )\n","    ]\n",")\n","\n","print(\"‚úÖ Configuraci√≥n de entrenamiento:\")\n","print(f\"   Learning rate: {config.LEARNING_RATE}\")\n","print(f\"   Batch size: {config.BATCH_SIZE}\")\n","print(f\"   Epochs: {config.NUM_EPOCHS}\")\n","print(f\"   Warmup steps: {config.WARMUP_STEPS}\")\n","print(f\"   Early stopping: {config.EARLY_STOPPING_PATIENCE} epochs\")\n","print(f\"   FP16 (mixed precision): {training_args.fp16}\")\n","print(f\"   M√©trica principal: f1_weighted\")\n","\n","print(\"\\n\" + \"=\"*80)\n","print(\"‚úÖ TRAINER CONFIGURADO Y LISTO\")\n","print(\"=\"*80 + \"\\n\")\n","\n","config.logger.info(\"Trainer configurado correctamente\")\n"],"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","================================================================================\n","‚öôÔ∏è  CONFIGURANDO ENTRENAMIENTO\n","================================================================================\n","\n","‚úÖ Configuraci√≥n de entrenamiento:\n","   Learning rate: 2e-05\n","   Batch size: 16\n","   Epochs: 3\n","   Warmup steps: 500\n","   Early stopping: 3 epochs\n","   FP16 (mixed precision): True\n","   M√©trica principal: f1_weighted\n","\n","================================================================================\n","‚úÖ TRAINER CONFIGURADO Y LISTO\n","================================================================================\n","\n"]}],"id":"W_6d3qt-IKbx"},{"cell_type":"code","metadata":{"id":"Xk-wOW2lIKbx","executionInfo":{"status":"ok","timestamp":1763739213996,"user_tz":300,"elapsed":5430511,"user":{"displayName":"Brayan Poma Huaman","userId":"00419443262019466393"}},"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["5df444a907ac4ab0812883dec894d9ec","9d1aca998f274b39ac468d0d0339a2bd","53e082c5256c416882440c64ee0fe0ad","eb63af6a711d490d97965757c7e20b35","41dc41c42e1a49f0ba6069279d4dfe6b","2fe3d736e1eb4d93943b3350df97a892","44544b132c374cb8bb59c67b1b8514a5","b2d91b3663b74025a8802b30e3ebbc3a","b866a90b6de04739b33fae56f53cc965","7f1260fb12da464c85cc24829967b467","5c46f9af56b2484aa47304a62f72672e"]},"outputId":"fb3375fd-8758-445b-cfef-eff8f8d4d44b"},"source":["# ============================================================================\n","# üöÄ ENTRENAMIENTO DEL MODELO\n","# ============================================================================\n","\n","print(\"\\n\" + \"=\"*80)\n","print(\"üöÄ INICIANDO ENTRENAMIENTO\")\n","print(\"=\"*80)\n","print(f\"\\nModelo: {config.MODEL_NAME}\")\n","print(f\"Datos de entrenamiento: {len(train_dataset):,} ejemplos\")\n","print(f\"Datos de validaci√≥n: {len(val_dataset):,} ejemplos\")\n","print(f\"\\nEsto puede tomar varios minutos/horas dependiendo de:\")\n","print(\"  - Tama√±o del dataset\")\n","print(\"  - N√∫mero de √©pocas\")\n","print(\"  - Hardware disponible (GPU/CPU)\")\n","print(\"\\n\" + \"=\"*80 + \"\\n\")\n","\n","try:\n","    # Registrar inicio\n","    start_time = datetime.now()\n","    config.logger.info(\"Iniciando entrenamiento...\")\n","\n","    # ENTRENAR\n","    train_result = trainer.train()\n","\n","    # Registrar finalizaci√≥n\n","    end_time = datetime.now()\n","    training_time = end_time - start_time\n","\n","    config.logger.info(f\"Entrenamiento completado en {training_time}\")\n","\n","    print(\"\\n\" + \"=\"*80)\n","    print(\"‚úÖ ENTRENAMIENTO COMPLETADO\")\n","    print(\"=\"*80)\n","    print(f\"\\nTiempo total: {training_time}\")\n","    print(f\"Mejor modelo guardado en: {config.CHECKPOINT_DIR}\")\n","\n","    # Mostrar m√©tricas finales de entrenamiento\n","    print(f\"\\nüìä M√©tricas finales de entrenamiento:\")\n","    print(f\"   Training loss: {train_result.training_loss:.4f}\")\n","\n","    # Evaluar en validation set\n","    print(\"\\n\" + \"-\"*80)\n","    print(\"üìä Evaluando en conjunto de validaci√≥n...\")\n","    val_metrics = trainer.evaluate()\n","    display_metrics(val_metrics, \"M√©tricas de Validaci√≥n\")\n","\n","    print(\"=\"*80 + \"\\n\")\n","\n","except KeyboardInterrupt:\n","    print(\"\\n\" + \"=\"*80)\n","    print(\"‚ö†Ô∏è  ENTRENAMIENTO INTERRUMPIDO POR EL USUARIO\")\n","    print(\"=\"*80)\n","    print(\"\\nEl modelo puede haber sido parcialmente entrenado.\")\n","    print(\"Los checkpoints guardados est√°n disponibles en:\")\n","    print(f\"  {config.CHECKPOINT_DIR}\")\n","    print(\"\\n\" + \"=\"*80 + \"\\n\")\n","    raise\n","\n","except Exception as e:\n","    print(\"\\n\" + \"=\"*80)\n","    print(\"‚ùå ERROR DURANTE EL ENTRENAMIENTO\")\n","    print(\"=\"*80)\n","    print(f\"\\n{str(e)}\\n\")\n","    print(\"Posibles causas:\")\n","    print(\"1. Memoria insuficiente (GPU/RAM)\")\n","    print(\"   Soluci√≥n: Reduce BATCH_SIZE en ModelConfig\")\n","    print(\"2. Datos corruptos o formato incorrecto\")\n","    print(\"3. Incompatibilidad de versiones\")\n","    print(\"\\nRevisa el archivo de log para m√°s detalles:\")\n","    print(f\"  {os.path.join(config.OUTPUT_DIR, 'training_*.log')}\")\n","    print(\"\\n\" + \"=\"*80 + \"\\n\")\n","    config.logger.error(f\"Error en entrenamiento: {str(e)}\", exc_info=True)\n","    raise\n"],"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","================================================================================\n","üöÄ INICIANDO ENTRENAMIENTO\n","================================================================================\n","\n","Modelo: dccuchile/bert-base-spanish-wwm-cased\n","Datos de entrenamiento: 220,937 ejemplos\n","Datos de validaci√≥n: 47,344 ejemplos\n","\n","Esto puede tomar varios minutos/horas dependiendo de:\n","  - Tama√±o del dataset\n","  - N√∫mero de √©pocas\n","  - Hardware disponible (GPU/CPU)\n","\n","================================================================================\n","\n"]},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5df444a907ac4ab0812883dec894d9ec"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='41427' max='41427' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [41427/41427 1:28:48, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1 Macro</th>\n","      <th>F1 Micro</th>\n","      <th>F1 Weighted</th>\n","      <th>Precision Macro</th>\n","      <th>Precision Micro</th>\n","      <th>Precision Weighted</th>\n","      <th>Recall Macro</th>\n","      <th>Recall Micro</th>\n","      <th>Recall Weighted</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.284800</td>\n","      <td>0.319179</td>\n","      <td>0.929790</td>\n","      <td>0.505106</td>\n","      <td>0.929790</td>\n","      <td>0.923398</td>\n","      <td>0.525101</td>\n","      <td>0.929790</td>\n","      <td>0.921823</td>\n","      <td>0.515998</td>\n","      <td>0.929790</td>\n","      <td>0.929790</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.269700</td>\n","      <td>0.274763</td>\n","      <td>0.939507</td>\n","      <td>0.581959</td>\n","      <td>0.939507</td>\n","      <td>0.935552</td>\n","      <td>0.595829</td>\n","      <td>0.939507</td>\n","      <td>0.934159</td>\n","      <td>0.592926</td>\n","      <td>0.939507</td>\n","      <td>0.939507</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.224400</td>\n","      <td>0.270986</td>\n","      <td>0.941851</td>\n","      <td>0.617512</td>\n","      <td>0.941851</td>\n","      <td>0.938728</td>\n","      <td>0.645245</td>\n","      <td>0.941851</td>\n","      <td>0.937884</td>\n","      <td>0.619159</td>\n","      <td>0.941851</td>\n","      <td>0.941851</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","================================================================================\n","‚úÖ ENTRENAMIENTO COMPLETADO\n","================================================================================\n","\n","Tiempo total: 1:28:50.450630\n","Mejor modelo guardado en: /content/drive/MyDrive/classification_coding_open_ended_occupational_responses_ENAHO/results/beto_base/bert-base-spanish-wwm-cased_20251121_140243/checkpoints\n","\n","üìä M√©tricas finales de entrenamiento:\n","   Training loss: 0.3603\n","\n","--------------------------------------------------------------------------------\n","üìä Evaluando en conjunto de validaci√≥n...\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='2959' max='2959' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2959/2959 01:40]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","================================================================================\n","üìä M√âTRICAS DE VALIDACI√ìN\n","================================================================================\n","\n","üí• LOSS: 0.2710\n","üéØ ACCURACY: 0.9419\n","\n","--------------------------------------------------------------------------------\n","\n","M√©trica                     Macro        Micro     Weighted\n","------------------------------------------------------------\n","F1 Score                   0.6175       0.9419       0.9387\n","Precision                  0.6452       0.9419       0.9379\n","Recall                     0.6192       0.9419       0.9419\n","\n","================================================================================\n","\n","================================================================================\n","\n"]}],"id":"Xk-wOW2lIKbx"},{"cell_type":"code","metadata":{"id":"IzyrUTD6IKby","executionInfo":{"status":"ok","timestamp":1763739316576,"user_tz":300,"elapsed":102566,"user":{"displayName":"Brayan Poma Huaman","userId":"00419443262019466393"}},"colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"59362cfa-ccd2-4538-a0c0-6c360054e613"},"source":["# ============================================================================\n","# üß™ EVALUACI√ìN EN TEST SET\n","# ============================================================================\n","\n","print(\"\\n\" + \"=\"*80)\n","print(\"üß™ EVALUACI√ìN EN TEST SET\")\n","print(\"=\"*80 + \"\\n\")\n","\n","try:\n","    config.logger.info(\"Evaluando en test set...\")\n","\n","    # Obtener predicciones en test set\n","    test_predictions = trainer.predict(test_dataset)\n","\n","    # Extraer m√©tricas\n","    test_metrics = test_predictions.metrics\n","\n","    # Mostrar m√©tricas\n","    display_metrics(test_metrics, \"M√©tricas de Test (Evaluaci√≥n Final)\")\n","\n","    # Guardar m√©tricas en archivo\n","    metrics_file = os.path.join(config.OUTPUT_DIR, 'test_metrics.json')\n","    with open(metrics_file, 'w', encoding='utf-8') as f:\n","        json.dump(test_metrics, f, indent=2)\n","\n","    config.logger.info(f\"M√©tricas de test guardadas en: {metrics_file}\")\n","\n","    # ========================================================================\n","    # AN√ÅLISIS DETALLADO\n","    # ========================================================================\n","\n","    print(\"\\n\" + \"=\"*80)\n","    print(\"üìà AN√ÅLISIS DETALLADO\")\n","    print(\"=\"*80 + \"\\n\")\n","\n","    # Obtener predicciones y etiquetas verdaderas\n","    y_pred = np.argmax(test_predictions.predictions, axis=1)\n","    y_true = test_predictions.label_ids\n","\n","    # Reporte de clasificaci√≥n por clase\n","    print(\"üìä Reporte de Clasificaci√≥n por Clase:\\n\")\n","\n","    # Crear reporte con nombres de clases\n","    target_names = [id2label[i] for i in range(len(id2label))]\n","    class_report = classification_report(\n","        y_true,\n","        y_pred,\n","        target_names=target_names,\n","        zero_division=0,\n","        digits=4\n","    )\n","    print(class_report)\n","\n","    # Guardar reporte completo\n","    report_file = os.path.join(config.OUTPUT_DIR, 'classification_report.txt')\n","    with open(report_file, 'w', encoding='utf-8') as f:\n","        f.write(\"REPORTE DE CLASIFICACI√ìN - TEST SET\\n\")\n","        f.write(\"=\"*80 + \"\\n\\n\")\n","        f.write(f\"Modelo: {config.MODEL_NAME}\\n\")\n","        f.write(f\"Fecha: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n","        f.write(f\"Dataset: {config.DATA_PATH}\\n\")\n","        f.write(\"\\n\" + \"=\"*80 + \"\\n\\n\")\n","        f.write(class_report)\n","\n","    print(f\"\\n‚úÖ Reporte completo guardado en: {report_file}\")\n","\n","    # ========================================================================\n","    # AN√ÅLISIS DE ERRORES\n","    # ========================================================================\n","\n","    print(\"\\n\" + \"=\"*80)\n","    print(\"üîç AN√ÅLISIS DE ERRORES\")\n","    print(\"=\"*80 + \"\\n\")\n","\n","    # Identificar predicciones incorrectas\n","    incorrect_mask = y_pred != y_true\n","    num_incorrect = incorrect_mask.sum()\n","    error_rate = num_incorrect / len(y_true) * 100\n","\n","    print(f\"Total de predicciones: {len(y_true):,}\")\n","    print(f\"Predicciones correctas: {(~incorrect_mask).sum():,}\")\n","    print(f\"Predicciones incorrectas: {num_incorrect:,}\")\n","    print(f\"Tasa de error: {error_rate:.2f}%\")\n","\n","    # Crear DataFrame con errores\n","    errors_df = test_df[incorrect_mask].copy()\n","    errors_df['predicted_label'] = [id2label[pred] for pred in y_pred[incorrect_mask]]\n","    errors_df['true_label'] = [id2label[true] for true in y_true[incorrect_mask]]\n","    errors_df['predicted_id'] = y_pred[incorrect_mask]\n","    errors_df['true_id'] = y_true[incorrect_mask]\n","\n","    # Agregar probabilidades\n","    probs = torch.nn.functional.softmax(torch.tensor(test_predictions.predictions), dim=-1)\n","    max_probs = probs.max(dim=-1).values.numpy()\n","    errors_df['confidence'] = max_probs[incorrect_mask]\n","\n","    # Guardar an√°lisis de errores\n","    errors_file = os.path.join(config.OUTPUT_DIR, 'error_analysis.csv')\n","    errors_df.to_csv(errors_file, index=False, encoding='utf-8')\n","\n","    print(f\"\\n‚úÖ An√°lisis de errores guardado en: {errors_file}\")\n","\n","    # Mostrar clases con m√°s errores\n","    if len(errors_df) > 0:\n","        print(\"\\nüìä Top 10 clases con m√°s errores de predicci√≥n:\")\n","        error_by_class = errors_df['true_label'].value_counts().head(10)\n","        for idx, (clase, count) in enumerate(error_by_class.items(), 1):\n","            print(f\"   {idx}. {clase}: {count} errores\")\n","\n","    print(\"\\n\" + \"=\"*80 + \"\\n\")\n","\n","    config.logger.info(\"Evaluaci√≥n en test completada\")\n","\n","except Exception as e:\n","    print(\"\\n\" + \"=\"*80)\n","    print(\"‚ùå ERROR EN LA EVALUACI√ìN\")\n","    print(\"=\"*80)\n","    print(f\"\\n{str(e)}\\n\")\n","    config.logger.error(f\"Error en evaluaci√≥n: {str(e)}\", exc_info=True)\n","    raise\n"],"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","================================================================================\n","üß™ EVALUACI√ìN EN TEST SET\n","================================================================================\n","\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","================================================================================\n","üìä M√âTRICAS DE TEST (EVALUACI√ìN FINAL)\n","================================================================================\n","\n","üí• LOSS: 0.2685\n","üéØ ACCURACY: 0.9413\n","\n","--------------------------------------------------------------------------------\n","\n","M√©trica                     Macro        Micro     Weighted\n","------------------------------------------------------------\n","F1 Score                   0.6087       0.9413       0.9380\n","Precision                  0.6256       0.9413       0.9371\n","Recall                     0.6168       0.9413       0.9413\n","\n","================================================================================\n","\n","\n","================================================================================\n","üìà AN√ÅLISIS DETALLADO\n","================================================================================\n","\n","üìä Reporte de Clasificaci√≥n por Clase:\n","\n","              precision    recall  f1-score   support\n","\n","        0111     1.0000    1.0000    1.0000         3\n","        0112     0.0000    0.0000    0.0000         2\n","        0120     0.9000    1.0000    0.9474         9\n","        0211     1.0000    1.0000    1.0000         9\n","        0212     0.5556    1.0000    0.7143         5\n","        0213     1.0000    0.5000    0.6667         2\n","        0220     1.0000    0.9931    0.9965       145\n","        0311     1.0000    1.0000    1.0000         6\n","        0312     1.0000    0.8750    0.9333         8\n","        0313     0.7500    0.7500    0.7500         4\n","        1111     0.7692    0.9091    0.8333        11\n","        1113     1.0000    0.6667    0.8000         3\n","        1114     0.6842    0.8966    0.7761        29\n","        1131     0.0000    0.0000    0.0000         2\n","        1133     1.0000    0.6667    0.8000         3\n","        1143     0.0000    0.0000    0.0000         1\n","        1166     0.0000    0.0000    0.0000         3\n","        1167     0.0000    0.0000    0.0000         1\n","        1169     0.0000    0.0000    0.0000         2\n","        1211     0.0000    0.0000    0.0000         2\n","        1221     0.0000    0.0000    0.0000         4\n","        1321     0.0000    0.0000    0.0000         2\n","        1323     0.0000    0.0000    0.0000         2\n","        1341     0.0000    0.0000    0.0000         2\n","        1345     0.9091    0.9859    0.9459        71\n","        1346     1.0000    1.0000    1.0000         3\n","        1422     0.2143    1.0000    0.3529         6\n","        1499     0.0000    0.0000    0.0000         2\n","        2113     0.0000    0.0000    0.0000         3\n","        2114     0.9000    1.0000    0.9474         9\n","        2120     0.0000    0.0000    0.0000         2\n","        2131     0.9286    0.8125    0.8667        16\n","        2132     0.8163    0.9524    0.8791        42\n","        2141     1.0000    0.7826    0.8780        23\n","        2142     0.9890    0.9474    0.9677        95\n","        2143     0.7619    0.7619    0.7619        21\n","        2144     0.7333    0.7333    0.7333        15\n","        2145     0.7273    1.0000    0.8421         8\n","        2146     0.8000    1.0000    0.8889        12\n","        2149     0.7143    0.6667    0.6897        15\n","        2151     0.7273    0.8000    0.7619        10\n","        2152     1.0000    0.9000    0.9474        10\n","        2161     0.6200    0.9688    0.7561        32\n","        2162     0.0000    0.0000    0.0000        15\n","        2163     0.7500    0.3750    0.5000         8\n","        2166     0.8310    0.9365    0.8806        63\n","        2211     0.9630    0.9455    0.9541        55\n","        2212     0.8000    0.8889    0.8421        45\n","        2221     0.8639    1.0000    0.9270       146\n","        2222     0.9792    0.9592    0.9691        49\n","        2240     1.0000    1.0000    1.0000        18\n","        2251     0.9444    0.9444    0.9444        54\n","        2252     0.8500    1.0000    0.9189        17\n","        2254     0.0000    0.0000    0.0000         5\n","        2255     0.6667    1.0000    0.8000         8\n","        2256     0.0000    0.0000    0.0000         1\n","        2257     0.0000    0.0000    0.0000         1\n","        2311     0.9850    0.9704    0.9776       135\n","        2312     0.7273    0.7273    0.7273        11\n","        2320     0.0000    0.0000    0.0000         5\n","        2330     0.9594    0.9767    0.9680       387\n","        2341     0.9879    0.9800    0.9840       501\n","        2342     0.9674    0.9727    0.9700       183\n","        2351     0.8000    0.4444    0.5714         9\n","        2352     0.8000    0.8000    0.8000         5\n","        2353     0.7143    0.7143    0.7143         7\n","        2359     0.7630    0.7863    0.7744       131\n","        2411     0.9167    0.9565    0.9362       161\n","        2412     0.0000    0.0000    0.0000         8\n","        2421     0.6522    0.4167    0.5085        72\n","        2422     0.0000    0.0000    0.0000        11\n","        2431     0.0000    0.0000    0.0000         4\n","        2432     0.7500    1.0000    0.8571         3\n","        2511     0.6875    0.8980    0.7788        49\n","        2512     0.0000    0.0000    0.0000         9\n","        2513     0.0000    0.0000    0.0000         3\n","        2521     0.0000    0.0000    0.0000         4\n","        2611     0.9881    0.9822    0.9852       169\n","        2619     0.7241    0.7241    0.7241        29\n","        2631     0.7619    1.0000    0.8649        16\n","        2632     0.8571    1.0000    0.9231         6\n","        2634     0.9661    0.9828    0.9744        58\n","        2635     0.9375    0.9375    0.9375        16\n","        2636     0.0000    0.0000    0.0000         2\n","        2641     0.0000    0.0000    0.0000         2\n","        2642     0.7000    0.8235    0.7568        17\n","        2643     0.3333    0.5000    0.4000         2\n","        2651     0.6000    0.6667    0.6316         9\n","        2656     0.0000    0.0000    0.0000         2\n","        3111     0.3333    0.2500    0.2857         8\n","        3112     0.7333    0.8594    0.7914        64\n","        3113     0.8675    0.8000    0.8324        90\n","        3114     0.7273    0.6957    0.7111        23\n","        3115     0.9219    0.8252    0.8708       143\n","        3117     1.0000    0.2500    0.4000         4\n","        3118     0.6957    0.8889    0.7805        18\n","        3119     0.0000    0.0000    0.0000         4\n","        3121     0.3333    0.4000    0.3636        10\n","        3122     0.5424    0.7619    0.6337        42\n","        3123     0.6667    0.8000    0.7273        30\n","        3124     0.6719    0.6825    0.6772       126\n","        3125     0.0000    0.0000    0.0000         8\n","        3126     0.0000    0.0000    0.0000         5\n","        3129     0.3158    0.2400    0.2727        25\n","        3131     0.0000    0.0000    0.0000         1\n","        3132     0.0000    0.0000    0.0000         9\n","        3141     0.0000    0.0000    0.0000         5\n","        3142     0.0000    0.0000    0.0000         9\n","        3143     0.0000    0.0000    0.0000         2\n","        3145     0.0000    0.0000    0.0000         2\n","        3149     0.0000    0.0000    0.0000        23\n","        3151     0.0000    0.0000    0.0000         2\n","        3152     0.8571    0.9375    0.8955        32\n","        3153     0.0000    0.0000    0.0000         1\n","        3211     1.0000    0.2500    0.4000         4\n","        3212     0.7436    0.9667    0.8406        30\n","        3213     1.0000    0.9020    0.9485        51\n","        3215     0.0000    0.0000    0.0000         4\n","        3221     0.9745    0.8884    0.9294       215\n","        3230     0.9565    0.9565    0.9565        23\n","        3240     0.6364    0.8750    0.7368         8\n","        3251     0.5714    0.7500    0.6486        16\n","        3253     0.0000    0.0000    0.0000         1\n","        3255     0.6216    0.9583    0.7541        24\n","        3256     0.3333    0.1667    0.2222         6\n","        3257     0.4600    0.6970    0.5542        33\n","        3258     1.0000    0.5000    0.6667         2\n","        3259     0.0000    0.0000    0.0000         4\n","        3313     0.7931    0.6765    0.7302        34\n","        3314     0.8805    0.9466    0.9124       506\n","        3315     0.0000    0.0000    0.0000         4\n","        3316     0.0000    0.0000    0.0000         2\n","        3317     0.5625    0.7500    0.6429        12\n","        3321     0.8333    0.9375    0.8824        16\n","        3322     0.8897    0.8643    0.8768       140\n","        3323     0.8000    0.6667    0.7273         6\n","        3331     0.6250    0.7143    0.6667         7\n","        3332     0.5000    0.4286    0.4615         7\n","        3334     0.9545    0.9545    0.9545        22\n","        3339     0.6250    0.3333    0.4348        15\n","        3341     1.0000    0.6667    0.8000         3\n","        3411     0.7105    0.6923    0.7013        39\n","        3412     0.0000    0.0000    0.0000         2\n","        3413     0.7500    1.0000    0.8571        15\n","        3421     1.0000    1.0000    1.0000        10\n","        3422     0.8421    0.8889    0.8649        36\n","        3423     0.0000    0.0000    0.0000         2\n","        3431     0.8421    0.8889    0.8649        18\n","        3432     1.0000    0.7778    0.8750         9\n","        3434     0.8000    0.5714    0.6667         7\n","        3439     0.9104    1.0000    0.9531        61\n","        3511     0.2857    0.3125    0.2985        32\n","        3512     0.0000    0.0000    0.0000        11\n","        3513     0.4510    0.6053    0.5169        38\n","        3514     0.4000    0.3333    0.3636         6\n","        3521     0.7143    0.7692    0.7407        26\n","        3522     0.0000    0.0000    0.0000         2\n","        3523     0.5455    0.8571    0.6667         7\n","        4110     0.9161    0.9066    0.9113       289\n","        4120     0.9892    0.9946    0.9919       184\n","        4131     0.8235    0.8235    0.8235        17\n","        4132     0.9697    0.9412    0.9552        34\n","        4211     0.7273    0.7442    0.7356        43\n","        4212     0.0000    0.0000    0.0000         5\n","        4213     1.0000    1.0000    1.0000         7\n","        4214     0.8929    0.8929    0.8929        28\n","        4221     1.0000    0.2222    0.3636         9\n","        4222     0.8750    0.9545    0.9130        66\n","        4223     0.8947    0.6800    0.7727        25\n","        4224     0.8990    0.9468    0.9223        94\n","        4225     0.8824    0.7500    0.8108        20\n","        4229     0.0000    0.0000    0.0000         4\n","        4311     0.6154    0.6154    0.6154        13\n","        4312     0.9134    0.9508    0.9317       122\n","        4313     0.0000    0.0000    0.0000         3\n","        4321     0.9495    0.9495    0.9495       218\n","        4323     0.5217    0.6667    0.5854        18\n","        4411     0.9286    1.0000    0.9630        13\n","        4412     1.0000    0.4000    0.5714        10\n","        4414     0.0000    0.0000    0.0000         3\n","        4415     0.7500    0.7500    0.7500         8\n","        4416     0.8571    0.8000    0.8276        15\n","        4417     0.7664    0.8750    0.8171       120\n","        4419     0.9474    0.9269    0.9370       602\n","        5111     0.0000    0.0000    0.0000         2\n","        5112     0.5000    0.5000    0.5000         4\n","        5113     0.9286    1.0000    0.9630        13\n","        5120     0.9642    0.9663    0.9652      1365\n","        5131     0.9970    0.9851    0.9910       336\n","        5132     0.6667    1.0000    0.8000        12\n","        5141     0.9405    0.7822    0.8541       101\n","        5142     0.7921    0.9412    0.8602        85\n","        5211     0.9216    0.9104    0.9160       413\n","        5212     0.9716    0.9816    0.9766      3588\n","        5213     0.9700    0.9618    0.9659      1074\n","        5221     0.5263    0.7692    0.6250        13\n","        5222     0.0000    0.0000    0.0000         7\n","        5223     0.0000    0.0000    0.0000         5\n","        5230     0.9712    0.9375    0.9541       144\n","        5241     0.8571    0.7059    0.7742        34\n","        5243     0.8372    0.9000    0.8675        80\n","        5244     0.7708    0.7551    0.7629        49\n","        5245     0.7593    0.8723    0.8119        47\n","        5311     0.8167    0.8305    0.8235        59\n","        5312     0.8850    0.9804    0.9302       102\n","        5321     0.0000    0.0000    0.0000         2\n","        5322     0.6364    0.8750    0.7368        24\n","        5329     0.8000    0.7742    0.7869        31\n","        5412     0.8810    0.9867    0.9308        75\n","        5413     1.0000    0.8750    0.9333         8\n","        5414     0.7913    0.8922    0.8387       102\n","        5419     0.0000    0.0000    0.0000         8\n","        6111     0.9864    0.9667    0.9764       600\n","        6112     0.9695    0.9867    0.9780       451\n","        6113     1.0000    0.3333    0.5000         3\n","        6114     0.9991    1.0000    0.9995      6563\n","        6121     0.9833    0.9807    0.9820       779\n","        6122     0.9324    0.9673    0.9495       214\n","        6123     1.0000    1.0000    1.0000         4\n","        6210     0.8056    0.8529    0.8286        34\n","        6221     0.8750    0.7778    0.8235         9\n","        6222     0.9101    0.9609    0.9348       179\n","        6223     0.6667    0.4211    0.5161        19\n","        6224     1.0000    0.7500    0.8571         4\n","        6310     0.0000    0.0000    0.0000         2\n","        6320     0.0000    0.0000    0.0000         5\n","        7111     0.9341    0.9307    0.9324       274\n","        7112     0.0000    0.0000    0.0000         6\n","        7113     0.8807    0.9057    0.8930       106\n","        7119     0.8750    0.9032    0.8889       155\n","        7121     1.0000    0.3333    0.5000         3\n","        7122     0.0000    0.0000    0.0000         1\n","        7123     1.0000    0.6364    0.7778        11\n","        7125     0.0000    0.0000    0.0000         2\n","        7126     0.9474    0.9474    0.9474        19\n","        7127     0.9344    0.9828    0.9580        58\n","        7128     0.9542    0.9921    0.9728       126\n","        7129     0.9091    0.8108    0.8571        37\n","        7212     0.8595    0.9353    0.8958       170\n","        7213     0.0000    0.0000    0.0000         3\n","        7214     0.0000    0.0000    0.0000         7\n","        7221     0.7778    0.8317    0.8038       101\n","        7222     1.0000    0.3889    0.5600        18\n","        7223     0.5000    0.6875    0.5789        16\n","        7224     1.0000    0.5000    0.6667         4\n","        7231     0.8750    0.9333    0.9032       240\n","        7233     0.8333    0.8333    0.8333         6\n","        7234     0.5610    0.6571    0.6053        35\n","        7235     1.0000    0.8571    0.9231         7\n","        7311     0.8333    0.7143    0.7692         7\n","        7312     0.9455    0.9811    0.9630        53\n","        7313     0.9286    0.8966    0.9123        29\n","        7321     0.0000    0.0000    0.0000         1\n","        7322     0.9573    0.9345    0.9458       168\n","        7331     0.0000    0.0000    0.0000         4\n","        7332     0.7500    0.8000    0.7742        15\n","        7333     0.0000    0.0000    0.0000         3\n","        7341     0.9583    0.7188    0.8214        32\n","        7342     0.5294    0.9000    0.6667        10\n","        7351     0.8849    0.8814    0.8832       253\n","        7352     0.8095    0.8293    0.8193       164\n","        7353     1.0000    0.2000    0.3333         5\n","        7354     0.8075    0.8152    0.8113       211\n","        7355     0.6719    0.9149    0.7748        47\n","        7356     0.8000    0.8889    0.8421         9\n","        7361     0.5333    0.5714    0.5517        14\n","        7362     0.8529    0.9508    0.8992        61\n","        7391     0.0000    0.0000    0.0000         7\n","        7392     0.0000    0.0000    0.0000         4\n","        7399     0.7204    0.9054    0.8024        74\n","        7411     0.8211    0.8860    0.8523       114\n","        7412     0.0000    0.0000    0.0000         5\n","        7421     0.7629    0.8506    0.8043        87\n","        7422     0.7619    0.6667    0.7111        24\n","        7431     0.0000    0.0000    0.0000         5\n","        7432     0.0000    0.0000    0.0000         2\n","        7511     0.7647    0.7647    0.7647        34\n","        7512     0.8000    0.7273    0.7619        11\n","        7513     0.9296    0.9763    0.9524       338\n","        7514     0.9118    0.9118    0.9118        34\n","        7515     0.5833    0.6364    0.6087        33\n","        7517     1.0000    1.0000    1.0000         3\n","        7518     0.8824    0.9524    0.9160        63\n","        7519     0.7231    0.7460    0.7344        63\n","        8111     0.8400    0.7925    0.8155        53\n","        8112     0.3750    0.4286    0.4000        14\n","        8113     0.0000    0.0000    0.0000         2\n","        8114     0.0000    0.0000    0.0000         4\n","        8121     0.0000    0.0000    0.0000         3\n","        8131     0.7857    0.6875    0.7333        16\n","        8141     0.8710    0.8710    0.8710        31\n","        8142     0.6087    0.8235    0.7000        17\n","        8151     1.0000    0.5000    0.6667         4\n","        8152     1.0000    0.1111    0.2000         9\n","        8153     0.6667    0.3077    0.4211        13\n","        8154     0.0000    0.0000    0.0000         3\n","        8156     0.0000    0.0000    0.0000         7\n","        8159     0.0000    0.0000    0.0000         5\n","        8160     0.4118    0.5385    0.4667        13\n","        8171     0.6452    0.9524    0.7692        21\n","        8173     0.0000    0.0000    0.0000         3\n","        8181     0.7273    0.8000    0.7619        10\n","        8183     0.0000    0.0000    0.0000         4\n","        8189     0.5429    0.8261    0.6552        23\n","        8321     0.9862    0.9915    0.9889       940\n","        8322     0.9801    0.9523    0.9660       776\n","        8331     0.8832    0.9310    0.9065       203\n","        8332     0.9206    0.9469    0.9336       245\n","        8341     0.9714    0.8718    0.9189        39\n","        8342     0.6579    0.8197    0.7299        61\n","        8343     0.7700    0.7130    0.7404       108\n","        8351     0.0000    0.0000    0.0000         2\n","        8352     0.9268    1.0000    0.9620        38\n","        9111     0.9844    0.9986    0.9914       695\n","        9112     0.9361    0.9396    0.9378       546\n","        9121     0.9950    0.9803    0.9876       203\n","        9122     0.8718    0.9714    0.9189        35\n","        9124     1.0000    1.0000    1.0000         3\n","        9129     0.7143    0.6250    0.6667        16\n","        9211     0.9984    0.9981    0.9982      9856\n","        9212     0.5556    0.3846    0.4545        13\n","        9213     0.7317    0.8571    0.7895        35\n","        9214     0.8571    0.7500    0.8000        24\n","        9311     0.9118    0.9538    0.9323       130\n","        9312     0.9753    0.9240    0.9489       171\n","        9313     0.9823    0.9823    0.9823      1242\n","        9321     0.8333    0.8621    0.8475        87\n","        9329     1.0000    0.3333    0.5000         9\n","        9331     0.7800    0.8478    0.8125        46\n","        9332     0.0000    0.0000    0.0000         2\n","        9333     0.9430    0.9342    0.9386       319\n","        9334     0.9818    0.9818    0.9818        55\n","        9411     0.8914    0.8530    0.8718       279\n","        9412     0.9364    0.9328    0.9346       774\n","        9511     0.8958    0.8600    0.8776       150\n","        9512     0.6400    0.9412    0.7619        17\n","        9521     0.9355    0.9355    0.9355       155\n","        9522     0.5652    0.6500    0.6047        20\n","        9523     0.9655    0.8750    0.9180        32\n","        9524     0.8000    0.8372    0.8182        43\n","        9531     0.8684    0.8250    0.8462        40\n","        9533     0.9500    0.9532    0.9516       299\n","        9534     1.0000    0.3333    0.5000         6\n","        9535     0.9137    0.9045    0.9091       199\n","        9536     0.8462    0.9167    0.8800        12\n","        9537     0.7500    0.8571    0.8000         7\n","        9541     0.7188    0.6970    0.7077        33\n","        9542     0.0000    0.0000    0.0000         3\n","        9549     0.7500    0.7419    0.7459        93\n","        9611     0.6667    0.6667    0.6667        15\n","        9612     0.9020    0.9684    0.9340        95\n","        9613     0.7838    0.8406    0.8112        69\n","        9621     0.8889    0.9160    0.9023       131\n","        9622     0.9499    0.9424    0.9461       382\n","        9623     0.7500    1.0000    0.8571         3\n","        9624     0.0000    0.0000    0.0000         3\n","        9629     0.7362    0.6751    0.7043       951\n","\n","    accuracy                         0.9413     47344\n","   macro avg     0.6256    0.6168    0.6087     47344\n","weighted avg     0.9371    0.9413    0.9380     47344\n","\n","\n","‚úÖ Reporte completo guardado en: /content/drive/MyDrive/classification_coding_open_ended_occupational_responses_ENAHO/results/beto_base/bert-base-spanish-wwm-cased_20251121_140243/classification_report.txt\n","\n","================================================================================\n","üîç AN√ÅLISIS DE ERRORES\n","================================================================================\n","\n","Total de predicciones: 47,344\n","Predicciones correctas: 44,566\n","Predicciones incorrectas: 2,778\n","Tasa de error: 5.87%\n","\n","‚úÖ An√°lisis de errores guardado en: /content/drive/MyDrive/classification_coding_open_ended_occupational_responses_ENAHO/results/beto_base/bert-base-spanish-wwm-cased_20251121_140243/error_analysis.csv\n","\n","üìä Top 10 clases con m√°s errores de predicci√≥n:\n","   1. 9629: 309 errores\n","   2. 5212: 66 errores\n","   3. 9412: 52 errores\n","   4. 5120: 46 errores\n","   5. 4419: 44 errores\n","   6. 2421: 42 errores\n","   7. 9411: 41 errores\n","   8. 5213: 41 errores\n","   9. 3124: 40 errores\n","   10. 7354: 39 errores\n","\n","================================================================================\n","\n"]}],"id":"IzyrUTD6IKby"},{"cell_type":"code","metadata":{"id":"P_SQR_giIKby","executionInfo":{"status":"ok","timestamp":1763739318439,"user_tz":300,"elapsed":1852,"user":{"displayName":"Brayan Poma Huaman","userId":"00419443262019466393"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"52cc0266-cadf-41fe-9268-e634a1b2a9d2"},"source":["# ============================================================================\n","# üíæ GUARDADO COMPLETO DEL MODELO Y ARTEFACTOS\n","# ============================================================================\n","\n","print(\"\\n\" + \"=\"*80)\n","print(\"üíæ GUARDANDO MODELO Y ARTEFACTOS\")\n","print(\"=\"*80 + \"\\n\")\n","\n","try:\n","    config.logger.info(\"Guardando modelo final...\")\n","\n","    # 1. Guardar modelo y tokenizer\n","    trainer.save_model(config.MODEL_SAVE_DIR)\n","    tokenizer.save_pretrained(config.MODEL_SAVE_DIR)\n","\n","    print(f\"‚úÖ Modelo y tokenizer guardados en: {config.MODEL_SAVE_DIR}\")\n","    config.logger.info(f\"Modelo guardado en: {config.MODEL_SAVE_DIR}\")\n","\n","    # 2. Guardar artefactos (mapeos, configuraci√≥n, m√©tricas)\n","    artifacts = {\n","        'label2id': label2id,\n","        'id2label': id2label,\n","        'num_labels': len(label2id),\n","        'target_column': config.TARGET_COLUMN,\n","        'text_column': config.TEXT_COLUMN,\n","        'max_length': config.MAX_LENGTH,\n","        'model_name': config.MODEL_NAME,\n","        'model_type': config.model_type,\n","        'experiment_name': config.experiment_name,\n","        'training_date': datetime.now().isoformat(),\n","        'test_metrics': test_metrics,\n","        'val_metrics': val_metrics if 'val_metrics' in locals() else None,\n","        'training_time': str(training_time) if 'training_time' in locals() else None,\n","        'device': config.DEVICE,\n","    }\n","\n","    artifacts_file = os.path.join(config.OUTPUT_DIR, 'artifacts.pkl')\n","    with open(artifacts_file, 'wb') as f:\n","        pickle.dump(artifacts, f)\n","\n","    print(f\"‚úÖ Artefactos guardados en: {artifacts_file}\")\n","    config.logger.info(f\"Artefactos guardados en: {artifacts_file}\")\n","\n","    # 3. Guardar resumen en JSON (legible)\n","    summary = {\n","        'experiment_name': config.experiment_name,\n","        'model_name': config.MODEL_NAME,\n","        'model_type': config.model_type,\n","        'num_classes': len(label2id),\n","        'training_date': datetime.now().isoformat(),\n","        'data_path': config.DATA_PATH,\n","        'max_length': config.MAX_LENGTH,\n","        'batch_size': config.BATCH_SIZE,\n","        'learning_rate': config.LEARNING_RATE,\n","        'num_epochs': config.NUM_EPOCHS,\n","        'test_accuracy': test_metrics.get('test_accuracy', test_metrics.get('eval_accuracy', 0)),\n","        'test_f1_macro': test_metrics.get('test_f1_macro', test_metrics.get('eval_f1_macro', 0)),\n","        'test_f1_weighted': test_metrics.get('test_f1_weighted', test_metrics.get('eval_f1_weighted', 0)),\n","        'device_used': config.DEVICE,\n","    }\n","\n","    summary_file = os.path.join(config.OUTPUT_DIR, 'experiment_summary.json')\n","    with open(summary_file, 'w', encoding='utf-8') as f:\n","        json.dump(summary, f, indent=2, ensure_ascii=False)\n","\n","    print(f\"‚úÖ Resumen guardado en: {summary_file}\")\n","\n","    # 4. Crear archivo README\n","    readme_content = f\"\"\"# Experimento: {config.experiment_name}\n","\n","## Informaci√≥n del Modelo\n","- **Modelo Base**: {config.MODEL_NAME}\n","- **Tipo**: {config.model_type}\n","- **N√∫mero de Clases**: {len(label2id)}\n","- **Fecha de Entrenamiento**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n","\n","## Resultados (Test Set)\n","- **Accuracy**: {test_metrics.get('test_accuracy', test_metrics.get('eval_accuracy', 0)):.4f}\n","- **F1 Macro**: {test_metrics.get('test_f1_macro', test_metrics.get('eval_f1_macro', 0)):.4f}\n","- **F1 Weighted**: {test_metrics.get('test_f1_weighted', test_metrics.get('eval_f1_weighted', 0)):.4f}\n","- **Precision Weighted**: {test_metrics.get('test_precision_weighted', test_metrics.get('eval_precision_weighted', 0)):.4f}\n","- **Recall Weighted**: {test_metrics.get('test_recall_weighted', test_metrics.get('eval_recall_weighted', 0)):.4f}\n","\n","## Archivos Generados\n","- `final_model/`: Modelo entrenado y tokenizer\n","- `artifacts.pkl`: Mapeos y metadata\n","- `config.json`: Configuraci√≥n del entrenamiento\n","- `test_metrics.json`: M√©tricas completas de test\n","- `classification_report.txt`: Reporte detallado por clase\n","- `error_analysis.csv`: An√°lisis de errores\n","- `experiment_summary.json`: Resumen del experimento\n","\n","## C√≥mo Usar el Modelo\n","\n","```python\n","from transformers import AutoTokenizer, AutoModelForSequenceClassification\n","import pickle\n","\n","# Cargar modelo y tokenizer\n","model_path = \"{config.MODEL_SAVE_DIR}\"\n","model = AutoModelForSequenceClassification.from_pretrained(model_path)\n","tokenizer = AutoTokenizer.from_pretrained(model_path)\n","\n","# Cargar artefactos\n","with open('{artifacts_file}', 'rb') as f:\n","    artifacts = pickle.load(f)\n","\n","id2label = artifacts['id2label']\n","\n","# Hacer predicci√≥n\n","text = \"Tu texto aqu√≠\"\n","inputs = tokenizer(text, return_tensors='pt', max_length={config.MAX_LENGTH},\n","                   padding='max_length', truncation=True)\n","outputs = model(**inputs)\n","predicted_class = outputs.logits.argmax().item()\n","predicted_label = id2label[predicted_class]\n","print(f\"Predicci√≥n: {{predicted_label}}\")\n","```\n","\"\"\"\n","\n","    readme_file = os.path.join(config.OUTPUT_DIR, 'README.md')\n","    with open(readme_file, 'w', encoding='utf-8') as f:\n","        f.write(readme_content)\n","\n","    print(f\"‚úÖ README creado en: {readme_file}\")\n","\n","    # 5. Listar todos los archivos generados\n","    print(\"\\n\" + \"=\"*80)\n","    print(\"üìÅ ARCHIVOS GENERADOS\")\n","    print(\"=\"*80 + \"\\n\")\n","\n","    all_files = [\n","        ('Modelo final', config.MODEL_SAVE_DIR),\n","        ('Artefactos', artifacts_file),\n","        ('Configuraci√≥n', os.path.join(config.OUTPUT_DIR, 'config.json')),\n","        ('M√©tricas de test', os.path.join(config.OUTPUT_DIR, 'test_metrics.json')),\n","        ('Reporte de clasificaci√≥n', report_file),\n","        ('An√°lisis de errores', errors_file),\n","        ('Resumen del experimento', summary_file),\n","        ('README', readme_file),\n","        ('Info de clases', os.path.join(config.OUTPUT_DIR, 'class_info.json')),\n","    ]\n","\n","    for name, path in all_files:\n","        if os.path.exists(path):\n","            if os.path.isdir(path):\n","                print(f\"‚úÖ {name:.<40} {path}\")\n","            else:\n","                size = os.path.getsize(path) / 1024\n","                print(f\"‚úÖ {name:.<40} {path} ({size:.1f} KB)\")\n","\n","    print(\"\\n\" + \"=\"*80 + \"\\n\")\n","\n","    config.logger.info(\"Todos los archivos guardados exitosamente\")\n","\n","except Exception as e:\n","    print(\"\\n\" + \"=\"*80)\n","    print(\"‚ùå ERROR AL GUARDAR ARCHIVOS\")\n","    print(\"=\"*80)\n","    print(f\"\\n{str(e)}\\n\")\n","    config.logger.error(f\"Error al guardar: {str(e)}\", exc_info=True)\n","    raise\n"],"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","================================================================================\n","üíæ GUARDANDO MODELO Y ARTEFACTOS\n","================================================================================\n","\n","‚úÖ Modelo y tokenizer guardados en: /content/drive/MyDrive/classification_coding_open_ended_occupational_responses_ENAHO/results/beto_base/bert-base-spanish-wwm-cased_20251121_140243/final_model\n","‚úÖ Artefactos guardados en: /content/drive/MyDrive/classification_coding_open_ended_occupational_responses_ENAHO/results/beto_base/bert-base-spanish-wwm-cased_20251121_140243/artifacts.pkl\n","‚úÖ Resumen guardado en: /content/drive/MyDrive/classification_coding_open_ended_occupational_responses_ENAHO/results/beto_base/bert-base-spanish-wwm-cased_20251121_140243/experiment_summary.json\n","‚úÖ README creado en: /content/drive/MyDrive/classification_coding_open_ended_occupational_responses_ENAHO/results/beto_base/bert-base-spanish-wwm-cased_20251121_140243/README.md\n","\n","================================================================================\n","üìÅ ARCHIVOS GENERADOS\n","================================================================================\n","\n","‚úÖ Modelo final............................ /content/drive/MyDrive/classification_coding_open_ended_occupational_responses_ENAHO/results/beto_base/bert-base-spanish-wwm-cased_20251121_140243/final_model\n","‚úÖ Artefactos.............................. /content/drive/MyDrive/classification_coding_open_ended_occupational_responses_ENAHO/results/beto_base/bert-base-spanish-wwm-cased_20251121_140243/artifacts.pkl (6.2 KB)\n","‚úÖ Configuraci√≥n........................... /content/drive/MyDrive/classification_coding_open_ended_occupational_responses_ENAHO/results/beto_base/bert-base-spanish-wwm-cased_20251121_140243/config.json (0.6 KB)\n","‚úÖ M√©tricas de test........................ /content/drive/MyDrive/classification_coding_open_ended_occupational_responses_ENAHO/results/beto_base/bert-base-spanish-wwm-cased_20251121_140243/test_metrics.json (0.6 KB)\n","‚úÖ Reporte de clasificaci√≥n................ /content/drive/MyDrive/classification_coding_open_ended_occupational_responses_ENAHO/results/beto_base/bert-base-spanish-wwm-cased_20251121_140243/classification_report.txt (19.4 KB)\n","‚úÖ An√°lisis de errores..................... /content/drive/MyDrive/classification_coding_open_ended_occupational_responses_ENAHO/results/beto_base/bert-base-spanish-wwm-cased_20251121_140243/error_analysis.csv (1649.1 KB)\n","‚úÖ Resumen del experimento................. /content/drive/MyDrive/classification_coding_open_ended_occupational_responses_ENAHO/results/beto_base/bert-base-spanish-wwm-cased_20251121_140243/experiment_summary.json (0.6 KB)\n","‚úÖ README.................................. /content/drive/MyDrive/classification_coding_open_ended_occupational_responses_ENAHO/results/beto_base/bert-base-spanish-wwm-cased_20251121_140243/README.md (1.8 KB)\n","‚úÖ Info de clases.......................... /content/drive/MyDrive/classification_coding_open_ended_occupational_responses_ENAHO/results/beto_base/bert-base-spanish-wwm-cased_20251121_140243/class_info.json (19.6 KB)\n","\n","================================================================================\n","\n"]}],"id":"P_SQR_giIKby"},{"cell_type":"code","metadata":{"id":"u4rxwj65IKby","executionInfo":{"status":"ok","timestamp":1763739318494,"user_tz":300,"elapsed":46,"user":{"displayName":"Brayan Poma Huaman","userId":"00419443262019466393"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"6dc7436a-30e4-4f44-e94b-102e792e2a0b"},"source":["# ============================================================================\n","# üîÆ FUNCIONES DE PREDICCI√ìN E INFERENCIA\n","# ============================================================================\n","\n","def load_trained_model_for_inference(model_dir, artifacts_path, device=None):\n","    \"\"\"\n","    Carga el modelo entrenado para hacer predicciones\n","\n","    Args:\n","        model_dir: Directorio del modelo guardado\n","        artifacts_path: Ruta al archivo de artefactos\n","        device: Dispositivo ('cuda' o 'cpu'), None para auto-detectar\n","\n","    Returns:\n","        tuple: (model, tokenizer, artifacts)\n","    \"\"\"\n","    import torch\n","    from transformers import AutoTokenizer, AutoModelForSequenceClassification\n","    import pickle\n","\n","    if device is None:\n","        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","\n","    print(\"\\n\" + \"=\"*80)\n","    print(\"üìÇ CARGANDO MODELO PARA INFERENCIA\")\n","    print(\"=\"*80 + \"\\n\")\n","\n","    # Cargar tokenizer\n","    tokenizer = AutoTokenizer.from_pretrained(model_dir)\n","    print(f\"‚úÖ Tokenizer cargado\")\n","\n","    # Cargar modelo\n","    model = AutoModelForSequenceClassification.from_pretrained(model_dir)\n","    model.to(device)\n","    model.eval()  # Modo evaluaci√≥n\n","    print(f\"‚úÖ Modelo cargado en: {device}\")\n","\n","    # Cargar artefactos\n","    with open(artifacts_path, 'rb') as f:\n","        artifacts = pickle.load(f)\n","    print(f\"‚úÖ Artefactos cargados\")\n","    print(f\"   N√∫mero de clases: {artifacts['num_labels']}\")\n","\n","    print(\"\\n\" + \"=\"*80 + \"\\n\")\n","\n","    return model, tokenizer, artifacts\n","\n","\n","def predict_single(text, model, tokenizer, artifacts, device=None, top_k=5):\n","    \"\"\"\n","    Predice la clase de un texto individual\n","\n","    Args:\n","        text: Texto a clasificar\n","        model: Modelo entrenado\n","        tokenizer: Tokenizer\n","        artifacts: Diccionario de artefactos\n","        device: Dispositivo\n","        top_k: N√∫mero de predicciones principales a retornar\n","\n","    Returns:\n","        dict: Resultados de la predicci√≥n\n","    \"\"\"\n","    import torch\n","    import torch.nn.functional as F\n","\n","    if device is None:\n","        device = next(model.parameters()).device\n","\n","    # Tokenizar\n","    inputs = tokenizer(\n","        text,\n","        max_length=artifacts['max_length'],\n","        padding='max_length',\n","        truncation=True,\n","        return_tensors='pt'\n","    )\n","    inputs = {k: v.to(device) for k, v in inputs.items()}\n","\n","    # Predicci√≥n\n","    with torch.no_grad():\n","        outputs = model(**inputs)\n","        logits = outputs.logits\n","        probs = F.softmax(logits, dim=-1)\n","\n","    # Predicci√≥n principal\n","    predicted_idx = torch.argmax(probs, dim=-1).item()\n","    predicted_prob = probs[0][predicted_idx].item()\n","    predicted_label = artifacts['id2label'][str(predicted_idx)]\n","\n","    # Top-K predicciones\n","    top_probs, top_indices = torch.topk(probs[0], k=min(top_k, len(artifacts['id2label'])))\n","    top_predictions = [\n","        {\n","            'label': artifacts['id2label'][str(idx.item())],\n","            'probability': prob.item()\n","        }\n","        for prob, idx in zip(top_probs, top_indices)\n","    ]\n","\n","    return {\n","        'text': text,\n","        'predicted_label': predicted_label,\n","        'predicted_probability': predicted_prob,\n","        'top_predictions': top_predictions\n","    }\n","\n","\n","def predict_batch(texts, model, tokenizer, artifacts, device=None, batch_size=32):\n","    \"\"\"\n","    Predice las clases de m√∫ltiples textos\n","\n","    Args:\n","        texts: Lista de textos\n","        model: Modelo entrenado\n","        tokenizer: Tokenizer\n","        artifacts: Diccionario de artefactos\n","        device: Dispositivo\n","        batch_size: Tama√±o del lote\n","\n","    Returns:\n","        list: Lista de predicciones\n","    \"\"\"\n","    import torch\n","    import torch.nn.functional as F\n","    from tqdm.auto import tqdm\n","\n","    if device is None:\n","        device = next(model.parameters()).device\n","\n","    model.eval()\n","    predictions = []\n","\n","    # Procesar en lotes\n","    for i in tqdm(range(0, len(texts), batch_size), desc=\"Prediciendo\"):\n","        batch_texts = texts[i:i+batch_size]\n","\n","        # Tokenizar\n","        inputs = tokenizer(\n","            batch_texts,\n","            max_length=artifacts['max_length'],\n","            padding='max_length',\n","            truncation=True,\n","            return_tensors='pt'\n","        )\n","        inputs = {k: v.to(device) for k, v in inputs.items()}\n","\n","        # Predicci√≥n\n","        with torch.no_grad():\n","            outputs = model(**inputs)\n","            logits = outputs.logits\n","            probs = F.softmax(logits, dim=-1)\n","\n","        # Extraer predicciones\n","        predicted_indices = torch.argmax(probs, dim=-1).cpu().numpy()\n","        predicted_probs = torch.max(probs, dim=-1)[0].cpu().numpy()\n","\n","        for idx, prob in zip(predicted_indices, predicted_probs):\n","            predictions.append({\n","                'predicted_label': artifacts['id2label'][str(idx)],\n","                'probability': float(prob)\n","            })\n","\n","    return predictions\n","\n","\n","def interactive_prediction_mode(model, tokenizer, artifacts, device=None):\n","    \"\"\"\n","    Modo interactivo para probar el modelo\n","\n","    Args:\n","        model: Modelo entrenado\n","        tokenizer: Tokenizer\n","        artifacts: Diccionario de artefactos\n","        device: Dispositivo\n","    \"\"\"\n","    print(\"\\n\" + \"=\"*80)\n","    print(\"üß™ MODO DE PRUEBA INTERACTIVO\")\n","    print(\"=\"*80)\n","    print(\"\\nEscribe un texto para clasificar (o 'salir' para terminar)\")\n","    print(\"Comandos especiales: 'salir', 'exit', 'quit', 'q'\\n\")\n","\n","    while True:\n","        print(\"-\" * 80)\n","        text = input(\"\\nüìù Texto: \").strip()\n","\n","        if text.lower() in ['salir', 'exit', 'quit', 'q']:\n","            print(\"\\nüëã ¬°Hasta luego!\\n\")\n","            break\n","\n","        if not text:\n","            print(\"‚ö†Ô∏è  Por favor, ingresa un texto v√°lido\")\n","            continue\n","\n","        # Realizar predicci√≥n\n","        result = predict_single(text, model, tokenizer, artifacts, device)\n","\n","        # Mostrar resultados\n","        print(\"\\nüìä RESULTADO:\")\n","        print(f\"   üéØ Clase predicha: {result['predicted_label']}\")\n","        print(f\"   üìà Confianza: {result['predicted_probability']:.2%}\")\n","        print(f\"\\n   üîù Top 5 predicciones:\")\n","        for i, pred in enumerate(result['top_predictions'], 1):\n","            bar = \"‚ñà\" * int(pred['probability'] * 20)\n","            print(f\"      {i}. {pred['label']:<15} {pred['probability']:>6.2%} {bar}\")\n","        print()\n","\n","\n","print(\"‚úÖ Funciones de predicci√≥n cargadas\")\n"],"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["‚úÖ Funciones de predicci√≥n cargadas\n"]}],"id":"u4rxwj65IKby"},{"cell_type":"code","metadata":{"id":"HDavsX-dIKbz","executionInfo":{"status":"error","timestamp":1763739318582,"user_tz":300,"elapsed":86,"user":{"displayName":"Brayan Poma Huaman","userId":"00419443262019466393"}},"colab":{"base_uri":"https://localhost:8080/","height":488},"outputId":"89656b84-70d9-4229-b6ae-7ecb26b3e313"},"source":["# ============================================================================\n","# üí° EJEMPLO DE USO - PREDICCI√ìN CON EL MODELO ENTRENADO\n","# ============================================================================\n","\n","# Este c√≥digo muestra c√≥mo usar el modelo despu√©s del entrenamiento\n","# Puedes ejecutarlo en este notebook o en uno nuevo\n","\n","print(\"\\n\" + \"=\"*80)\n","print(\"üí° EJEMPLOS DE USO\")\n","print(\"=\"*80 + \"\\n\")\n","\n","# ============================================================================\n","# OPCI√ìN 1: Usar el modelo reci√©n entrenado (en este notebook)\n","# ============================================================================\n","\n","print(\"üìù OPCI√ìN 1: Predicci√≥n individual con modelo actual\\n\")\n","\n","# Ejemplo de textos para probar\n","ejemplos_texto = [\n","    \"vendedor de abarrotes en bodega\",\n","    \"profesor de matem√°ticas en colegio secundario\",\n","    \"conductor de taxi\"\n","]\n","\n","print(\"Ejemplos de predicci√≥n:\\n\")\n","for texto in ejemplos_texto:\n","    result = predict_single(texto, model, tokenizer, artifacts, config.DEVICE)\n","    print(f\"Texto: {texto}\")\n","    print(f\"Predicci√≥n: {result['predicted_label']} (confianza: {result['predicted_probability']:.2%})\\n\")\n","\n","print(\"-\" * 80 + \"\\n\")\n","\n","# ============================================================================\n","# OPCI√ìN 2: Cargar modelo guardado (en una nueva sesi√≥n)\n","# ============================================================================\n","\n","print(\"üìù OPCI√ìN 2: C√≥digo para cargar el modelo en una nueva sesi√≥n\\n\")\n","\n","codigo_ejemplo = f'''\n","# C√≥digo para usar en un notebook/script nuevo:\n","\n","# 1. Cargar el modelo\n","model_inference, tokenizer_inference, artifacts_inference = load_trained_model_for_inference(\n","    model_dir=\"{config.MODEL_SAVE_DIR}\",\n","    artifacts_path=\"{os.path.join(config.OUTPUT_DIR, 'artifacts.pkl')}\"\n",")\n","\n","# 2. Hacer predicci√≥n individual\n","texto = \"alba√±il de construcci√≥n\"\n","result = predict_single(\n","    text=texto,\n","    model=model_inference,\n","    tokenizer=tokenizer_inference,\n","    artifacts=artifacts_inference\n",")\n","print(f\"Predicci√≥n: {{result['predicted_label']}}\")\n","print(f\"Confianza: {{result['predicted_probability']:.2%}}\")\n","\n","# 3. Hacer predicci√≥n por lotes\n","textos = [\"texto 1\", \"texto 2\", \"texto 3\"]\n","predictions = predict_batch(\n","    texts=textos,\n","    model=model_inference,\n","    tokenizer=tokenizer_inference,\n","    artifacts=artifacts_inference,\n","    batch_size=32\n",")\n","\n","# 4. Modo interactivo\n","interactive_prediction_mode(\n","    model=model_inference,\n","    tokenizer=tokenizer_inference,\n","    artifacts=artifacts_inference\n",")\n","'''\n","\n","print(codigo_ejemplo)\n","\n","print(\"=\" * 80 + \"\\n\")\n"],"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","================================================================================\n","üí° EJEMPLOS DE USO\n","================================================================================\n","\n","üìù OPCI√ìN 1: Predicci√≥n individual con modelo actual\n","\n","Ejemplos de predicci√≥n:\n","\n"]},{"output_type":"error","ename":"KeyError","evalue":"'193'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-3118623678.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Ejemplos de predicci√≥n:\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtexto\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mejemplos_texto\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_single\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0martifacts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Texto: {texto}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Predicci√≥n: {result['predicted_label']} (confianza: {result['predicted_probability']:.2%})\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipython-input-925818954.py\u001b[0m in \u001b[0;36mpredict_single\u001b[0;34m(text, model, tokenizer, artifacts, device, top_k)\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0mpredicted_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0mpredicted_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpredicted_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m     \u001b[0mpredicted_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0martifacts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id2label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;31m# Top-K predicciones\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: '193'"]}],"id":"HDavsX-dIKbz"},{"cell_type":"code","metadata":{"id":"IwaxuCtxIKbz","executionInfo":{"status":"aborted","timestamp":1763739318871,"user_tz":300,"elapsed":2,"user":{"displayName":"Brayan Poma Huaman","userId":"00419443262019466393"}}},"source":["# ============================================================================\n","# üéÆ MODO INTERACTIVO - PROBAR EL MODELO\n","# ============================================================================\n","\n","# Descomenta y ejecuta esta celda para probar el modelo interactivamente\n","\n","# interactive_prediction_mode(\n","#     model=model,\n","#     tokenizer=tokenizer,\n","#     artifacts=artifacts,\n","#     device=config.DEVICE\n","# )\n","\n","print(\"\\nüí° Descomenta el c√≥digo arriba para activar el modo interactivo\\n\")\n"],"execution_count":null,"outputs":[],"id":"IwaxuCtxIKbz"},{"cell_type":"markdown","metadata":{"id":"BkxBmMG2IKbz"},"source":["---\n","\n","# üéâ ¬°ENTRENAMIENTO COMPLETADO!\n","\n","## üìä Resumen de Resultados\n","\n","Tu modelo ha sido entrenado exitosamente. Revisa:\n","\n","1. **M√©tricas de Test**: Accuracy, F1, Precision, Recall (macro, micro, weighted)\n","2. **Archivos Generados**: Todos los archivos est√°n en el directorio de salida\n","3. **README**: Instrucciones detalladas de uso\n","\n","## üöÄ Pr√≥ximos Pasos\n","\n","### Para entrenar otro modelo:\n","1. Cambia `MODEL_NAME` en `ModelConfig`\n","2. Ejecuta todas las celdas nuevamente\n","\n","### Para usar el modelo:\n","1. Usa las funciones de predicci√≥n en este notebook\n","2. O carga el modelo en un script nuevo (ver ejemplos arriba)\n","\n","### Para mejorar los resultados:\n","- Ajusta los hiperpar√°metros en `ModelConfig`\n","- Aumenta `NUM_EPOCHS`\n","- Experimenta con diferentes `LEARNING_RATE`\n","- Aumenta `MAX_LENGTH` si tus textos son largos\n","\n","---\n","\n","## üìö Modelos Soportados\n","\n","Este script funciona con:\n","- ‚úÖ `FacebookAI/xlm-roberta-base` (Multiling√ºe)\n","- ‚úÖ `dccuchile/bert-base-spanish-wwm-cased` (Espa√±ol)\n","- ‚úÖ Cualquier modelo de Hugging Face compatible con `AutoModelForSequenceClassification`\n","\n","---\n","\n","**¬øPreguntas o errores?** Revisa:\n","- El archivo de log en el directorio de salida\n","- Los mensajes de error detallados en cada celda\n","- La documentaci√≥n de transformers: https://huggingface.co/docs/transformers\n"],"id":"BkxBmMG2IKbz"}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.0"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"ba7ce4dc95ff4efebaf34ad2750aaba5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fea70654d0924bbead2fb47828bc375d","IPY_MODEL_01c7d926d3bb430eac3e6dc04c360879","IPY_MODEL_990e95ffd72a48848d727df888b7696e"],"layout":"IPY_MODEL_0e84dd46c53b4e10b1a7284431dac245"}},"fea70654d0924bbead2fb47828bc375d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dfdbfaae225d4da7bd084541a1eb0021","placeholder":"‚Äã","style":"IPY_MODEL_2cf70107c12d43b18efe248cddf046c9","value":"tokenizer_config.json:‚Äá100%"}},"01c7d926d3bb430eac3e6dc04c360879":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1d1a174492d84a78bfb3242b19a336c0","max":364,"min":0,"orientation":"horizontal","style":"IPY_MODEL_58c76a154d4349a8865a7545bd6ae275","value":364}},"990e95ffd72a48848d727df888b7696e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4866bed5bada41189600e1cbe0ebfe69","placeholder":"‚Äã","style":"IPY_MODEL_b0f607899b7240968a954435297588d7","value":"‚Äá364/364‚Äá[00:00&lt;00:00,‚Äá35.0kB/s]"}},"0e84dd46c53b4e10b1a7284431dac245":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dfdbfaae225d4da7bd084541a1eb0021":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2cf70107c12d43b18efe248cddf046c9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1d1a174492d84a78bfb3242b19a336c0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"58c76a154d4349a8865a7545bd6ae275":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4866bed5bada41189600e1cbe0ebfe69":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b0f607899b7240968a954435297588d7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ebb98ae5ab844a449d808c53a9c0b904":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_719c9cf6461c4c24bad803c6380c7a61","IPY_MODEL_2ba10e031aca4c759cef64416a79757d","IPY_MODEL_f40b360ccf854c1dbc49a2144b7f65d2"],"layout":"IPY_MODEL_42c57bfb89734170b3dff481fd0a8aa3"}},"719c9cf6461c4c24bad803c6380c7a61":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_174a67ecee864fe295914d58d1ad0f75","placeholder":"‚Äã","style":"IPY_MODEL_8c1909822fa54af398574783565d3aa3","value":"config.json:‚Äá100%"}},"2ba10e031aca4c759cef64416a79757d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6e32b81e47d849cb8936e1773c0e0706","max":648,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2de61fa70b5f43f5a77d6c31d5cce96f","value":648}},"f40b360ccf854c1dbc49a2144b7f65d2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_934d14f09eda432b8af0aab03ea346d3","placeholder":"‚Äã","style":"IPY_MODEL_5af9f580716e4d1f8f4a85a2782269d3","value":"‚Äá648/648‚Äá[00:00&lt;00:00,‚Äá78.4kB/s]"}},"42c57bfb89734170b3dff481fd0a8aa3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"174a67ecee864fe295914d58d1ad0f75":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8c1909822fa54af398574783565d3aa3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6e32b81e47d849cb8936e1773c0e0706":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2de61fa70b5f43f5a77d6c31d5cce96f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"934d14f09eda432b8af0aab03ea346d3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5af9f580716e4d1f8f4a85a2782269d3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4b7fdcb313244978be8808ac56bd2fae":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0271494c1eb04ecd9d56056da0bc4549","IPY_MODEL_f151b248d1134db8b233e754f2978283","IPY_MODEL_ff438066ac0b47dfa5ab45a551280924"],"layout":"IPY_MODEL_25d3c99c0a2a4d0a8c66c1d2f0a4e141"}},"0271494c1eb04ecd9d56056da0bc4549":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_708c28d35839424e80dad6a0791e5c43","placeholder":"‚Äã","style":"IPY_MODEL_2504530a51f34ff79d629edf27dfe774","value":"vocab.txt:‚Äá"}},"f151b248d1134db8b233e754f2978283":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_86f641ac27c545309238ff2ca87398ee","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1547b0710a2944fa9f31fb64c9a420ea","value":1}},"ff438066ac0b47dfa5ab45a551280924":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d81717a212734c49979f337e09d890cd","placeholder":"‚Äã","style":"IPY_MODEL_40d4b8028d9d4052bb0b91d3bcf743bf","value":"‚Äá242k/?‚Äá[00:00&lt;00:00,‚Äá9.27MB/s]"}},"25d3c99c0a2a4d0a8c66c1d2f0a4e141":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"708c28d35839424e80dad6a0791e5c43":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2504530a51f34ff79d629edf27dfe774":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"86f641ac27c545309238ff2ca87398ee":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"1547b0710a2944fa9f31fb64c9a420ea":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d81717a212734c49979f337e09d890cd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"40d4b8028d9d4052bb0b91d3bcf743bf":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"be24a7e8987846f7abd6b3e5dd83e142":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5df6101530fc4326b5a03b45aafc887b","IPY_MODEL_7a2f9970b5ff48368b1584c3154eb233","IPY_MODEL_9ce4fbc5e0ed4164a273ad3145f3fd69"],"layout":"IPY_MODEL_1def19526f854d698b1b7942f7861feb"}},"5df6101530fc4326b5a03b45aafc887b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_00a6fd655d5c4d4aa85eea4bfed7f1b1","placeholder":"‚Äã","style":"IPY_MODEL_dc3f64cd875d4e0b97d6658beb6788e9","value":"tokenizer.json:‚Äá"}},"7a2f9970b5ff48368b1584c3154eb233":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7dd80cd870d141b9b67744144e7389b3","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9b0220ad63994a68b387ea627cf7afe2","value":1}},"9ce4fbc5e0ed4164a273ad3145f3fd69":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_39d95839367b44bea79321940795ee33","placeholder":"‚Äã","style":"IPY_MODEL_3129bd2bd4394cfc9d7b47df943985c3","value":"‚Äá480k/?‚Äá[00:00&lt;00:00,‚Äá27.4MB/s]"}},"1def19526f854d698b1b7942f7861feb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"00a6fd655d5c4d4aa85eea4bfed7f1b1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dc3f64cd875d4e0b97d6658beb6788e9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7dd80cd870d141b9b67744144e7389b3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"9b0220ad63994a68b387ea627cf7afe2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"39d95839367b44bea79321940795ee33":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3129bd2bd4394cfc9d7b47df943985c3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"59c05bb70a9842f2aa423d18e9478806":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c14b15d3db3b410faac6d655558fc0c0","IPY_MODEL_66096d761361486ab48925b197636734","IPY_MODEL_639e754456f64389b2d612784757dc41"],"layout":"IPY_MODEL_d6faddff42ea4fa9ba4efaa74c84abad"}},"c14b15d3db3b410faac6d655558fc0c0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8083b38ef0cc4ea39bad3014bb30aa87","placeholder":"‚Äã","style":"IPY_MODEL_64b7f19e621a48cc8719afeaf6929239","value":"special_tokens_map.json:‚Äá100%"}},"66096d761361486ab48925b197636734":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_12f14eaebda244ce81c5623bd2919624","max":134,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0bcda67a069e41db8e791b11b1183fa0","value":134}},"639e754456f64389b2d612784757dc41":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cfc58da9aca447ca8d5afca79c6ddf8e","placeholder":"‚Äã","style":"IPY_MODEL_d5d1f11d3752426b91193eacd92de581","value":"‚Äá134/134‚Äá[00:00&lt;00:00,‚Äá16.0kB/s]"}},"d6faddff42ea4fa9ba4efaa74c84abad":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8083b38ef0cc4ea39bad3014bb30aa87":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"64b7f19e621a48cc8719afeaf6929239":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"12f14eaebda244ce81c5623bd2919624":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0bcda67a069e41db8e791b11b1183fa0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"cfc58da9aca447ca8d5afca79c6ddf8e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d5d1f11d3752426b91193eacd92de581":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7343da5b79e642f9b24960bf9ddef20b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e777724e095b42f9ace97e86de61c071","IPY_MODEL_30334d3fbd98443988be7363b1e16868","IPY_MODEL_604b946394264805bf5901c437ab6ae5"],"layout":"IPY_MODEL_3cc1a697dfac4079a380fbb07a2400ec"}},"e777724e095b42f9ace97e86de61c071":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7acafb6025e0489a81b22b03223f158d","placeholder":"‚Äã","style":"IPY_MODEL_14ecf234f44c4bc19241571a7ce92a6e","value":"pytorch_model.bin:‚Äá100%"}},"30334d3fbd98443988be7363b1e16868":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d33160b59abb4406aab05c507ad97fef","max":439621341,"min":0,"orientation":"horizontal","style":"IPY_MODEL_78844c33d4c14dbaa899f1b43c4b7ab2","value":439621341}},"604b946394264805bf5901c437ab6ae5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_25c5937bf9174c6e987d996ffdc98c0f","placeholder":"‚Äã","style":"IPY_MODEL_0f643d3252fd45419d18c10be49f32af","value":"‚Äá440M/440M‚Äá[00:03&lt;00:00,‚Äá229MB/s]"}},"3cc1a697dfac4079a380fbb07a2400ec":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7acafb6025e0489a81b22b03223f158d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"14ecf234f44c4bc19241571a7ce92a6e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d33160b59abb4406aab05c507ad97fef":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"78844c33d4c14dbaa899f1b43c4b7ab2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"25c5937bf9174c6e987d996ffdc98c0f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0f643d3252fd45419d18c10be49f32af":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5df444a907ac4ab0812883dec894d9ec":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9d1aca998f274b39ac468d0d0339a2bd","IPY_MODEL_53e082c5256c416882440c64ee0fe0ad","IPY_MODEL_eb63af6a711d490d97965757c7e20b35"],"layout":"IPY_MODEL_41dc41c42e1a49f0ba6069279d4dfe6b"}},"9d1aca998f274b39ac468d0d0339a2bd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2fe3d736e1eb4d93943b3350df97a892","placeholder":"‚Äã","style":"IPY_MODEL_44544b132c374cb8bb59c67b1b8514a5","value":"model.safetensors:‚Äá100%"}},"53e082c5256c416882440c64ee0fe0ad":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b2d91b3663b74025a8802b30e3ebbc3a","max":439561688,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b866a90b6de04739b33fae56f53cc965","value":439561688}},"eb63af6a711d490d97965757c7e20b35":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7f1260fb12da464c85cc24829967b467","placeholder":"‚Äã","style":"IPY_MODEL_5c46f9af56b2484aa47304a62f72672e","value":"‚Äá440M/440M‚Äá[00:03&lt;00:00,‚Äá240MB/s]"}},"41dc41c42e1a49f0ba6069279d4dfe6b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2fe3d736e1eb4d93943b3350df97a892":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"44544b132c374cb8bb59c67b1b8514a5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b2d91b3663b74025a8802b30e3ebbc3a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b866a90b6de04739b33fae56f53cc965":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7f1260fb12da464c85cc24829967b467":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5c46f9af56b2484aa47304a62f72672e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":5}